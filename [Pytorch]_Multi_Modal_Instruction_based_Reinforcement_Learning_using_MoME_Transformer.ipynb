{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Pytorch] Multi Modal Instruction based Reinforcement Learning using MoME Transformer",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies Installation"
      ],
      "metadata": {
        "id": "g-UH-zaXiH5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install to use Lunar Lander Environment\n",
        "!pip3 install Box2D\n",
        "!pip3 install box2d-py\n",
        "!pip3 install gym[all]\n",
        "!pip3 install gym[Box_2D]"
      ],
      "metadata": {
        "id": "z-s_p76FoOQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9276362-62b7-44f8-95a6-86658ed9e581"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Box2D\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Box2D\n",
            "Successfully installed Box2D-2.3.10\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.8\n",
            "Requirement already satisfied: gym[all] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.21.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[all]) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[all]) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.4.1)\n",
            "Requirement already satisfied: box2d-py~=2.3.5 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (2.3.8)\n",
            "Collecting mujoco-py<2.0,>=1.50\n",
            "  Downloading mujoco-py-1.50.1.68.tar.gz (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[all]) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[all]) (1.15.0)\n",
            "Collecting glfw>=1.4.0\n",
            "  Downloading glfw-2.5.1-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 23.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython>=0.27.2 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (0.29.28)\n",
            "Requirement already satisfied: cffi>=1.10 in /usr/local/lib/python3.7/dist-packages (from mujoco-py<2.0,>=1.50->gym[all]) (1.15.0)\n",
            "Collecting lockfile>=0.12.2\n",
            "  Downloading lockfile-0.12.2-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.10->mujoco-py<2.0,>=1.50->gym[all]) (2.21)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[all]) (0.16.0)\n",
            "Building wheels for collected packages: mujoco-py\n",
            "  Building wheel for mujoco-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for mujoco-py\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for mujoco-py\n",
            "Failed to build mujoco-py\n",
            "Installing collected packages: lockfile, glfw, mujoco-py\n",
            "    Running setup.py install for mujoco-py ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-l13oe969/mujoco-py_52c380b79ba14c9cbf52ef67105f9823/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-l13oe969/mujoco-py_52c380b79ba14c9cbf52ef67105f9823/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-lsr_05nw/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/mujoco-py Check the logs for full command output.\u001b[0m\n",
            "Requirement already satisfied: gym[Box_2D] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "\u001b[33mWARNING: gym 0.17.3 does not provide the extra 'box_2d'\u001b[0m\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[Box_2D]) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[Box_2D]) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Colab dislay drivers\n",
        "#Install xvfb & other dependencies\n",
        "!apt-get install x11-utils > /dev/null 2>&1 \n",
        "!pip install pyglet > /dev/null 2>&1 \n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "#As well as pyvirtual display:\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "OLlBQVpGp1xh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing ROMs for atari games\n",
        "! wget http://www.atarimania.com/roms/Roms.rar\n",
        "! mkdir /content/ROM/\n",
        "! unrar e /content/Roms.rar /content/ROM/\n",
        "! python -m atari_py.import_roms /content/ROM/"
      ],
      "metadata": {
        "id": "SAENTHHjlGtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37095596-65c4-4cf5-ba8e-80d91c988d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-23 01:30:36--  http://www.atarimania.com/roms/Roms.rar\n",
            "Resolving www.atarimania.com (www.atarimania.com)... 195.154.81.199\n",
            "Connecting to www.atarimania.com (www.atarimania.com)|195.154.81.199|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11128004 (11M) [application/x-rar-compressed]\n",
            "Saving to: ‘Roms.rar’\n",
            "\n",
            "Roms.rar            100%[===================>]  10.61M   261KB/s    in 44s     \n",
            "\n",
            "2022-03-23 01:31:21 (246 KB/s) - ‘Roms.rar’ saved [11128004/11128004]\n",
            "\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/Roms.rar\n",
            "\n",
            "Extracting  /content/ROM/HC ROMS.zip                                     \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  /content/ROM/ROMS.zip                                        \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "copying adventure.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Adventure (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Air Raid (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Alien.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying crazy_climber.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Crazy Climber.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying elevator_action.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Elevator Action (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying gravitar.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Gravitar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying keystone_kapers.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Keystone Kapers (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from HC ROMS/BY ALPHABET (PAL)/H-R/King Kong (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying laser_gates.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Laser Gates (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying mr_do.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Mr. Do! (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying pacman.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Pac-Man (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying jamesbond.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/James Bond 007.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying koolaid.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Kool-Aid Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Krull.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying montezuma_revenge.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Montezuma's Revenge - Featuring Panama Joe.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying star_gunner.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Stargunner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying time_pilot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Time Pilot.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying up_n_down.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Up 'n Down.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying sir_lancelot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/Sir Lancelot (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying amidar.bin from HC ROMS/BY ALPHABET/A-G/Amidar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying asteroids.bin from HC ROMS/BY ALPHABET/A-G/Asteroids [no copyright].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from HC ROMS/BY ALPHABET/A-G/Atlantis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from HC ROMS/BY ALPHABET/A-G/Bank Heist.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from HC ROMS/BY ALPHABET/A-G/Battlezone.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from HC ROMS/BY ALPHABET/A-G/Beamrider.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from HC ROMS/BY ALPHABET/A-G/Berzerk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from HC ROMS/BY ALPHABET/A-G/Bowling.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from HC ROMS/BY ALPHABET/A-G/Boxing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from HC ROMS/BY ALPHABET/A-G/Breakout - Breakaway IV.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from HC ROMS/BY ALPHABET/A-G/Carnival.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from HC ROMS/BY ALPHABET/A-G/Centipede.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from HC ROMS/BY ALPHABET/A-G/Chopper Command.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying defender.bin from HC ROMS/BY ALPHABET/A-G/Defender.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from HC ROMS/BY ALPHABET/A-G/Demon Attack.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from HC ROMS/BY ALPHABET/A-G/Donkey Kong.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from HC ROMS/BY ALPHABET/A-G/Double Dunk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying enduro.bin from HC ROMS/BY ALPHABET/A-G/Enduro.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from HC ROMS/BY ALPHABET/A-G/Fishing Derby.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from HC ROMS/BY ALPHABET/A-G/Freeway.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from HC ROMS/BY ALPHABET/A-G/Frogger.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from HC ROMS/BY ALPHABET/A-G/Frostbite.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from HC ROMS/BY ALPHABET/A-G/Galaxian.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from HC ROMS/BY ALPHABET/A-G/Gopher.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying hero.bin from HC ROMS/BY ALPHABET/H-R/H.E.R.O..bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from HC ROMS/BY ALPHABET/H-R/Ice Hockey.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying journey_escape.bin from HC ROMS/BY ALPHABET/H-R/Journey Escape.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from HC ROMS/BY ALPHABET/H-R/Kaboom!.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from HC ROMS/BY ALPHABET/H-R/Kangaroo.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying kung_fu_master.bin from HC ROMS/BY ALPHABET/H-R/Kung-Fu Master.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying lost_luggage.bin from HC ROMS/BY ALPHABET/H-R/Lost Luggage [no opening scene].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying ms_pacman.bin from HC ROMS/BY ALPHABET/H-R/Ms. Pac-Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from HC ROMS/BY ALPHABET/H-R/Name This Game.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying phoenix.bin from HC ROMS/BY ALPHABET/H-R/Phoenix.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying pitfall.bin from HC ROMS/BY ALPHABET/H-R/Pitfall! - Pitfall Harry's Jungle Adventure.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from HC ROMS/BY ALPHABET/H-R/Pooyan.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from HC ROMS/BY ALPHABET/H-R/Private Eye.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from HC ROMS/BY ALPHABET/H-R/Q-bert.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from HC ROMS/BY ALPHABET/H-R/River Raid.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of HC ROMS/BY ALPHABET/H-R/Road Runner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from HC ROMS/BY ALPHABET/H-R/Robot Tank.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from HC ROMS/BY ALPHABET/S-Z/Seaquest.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying skiing.bin from HC ROMS/BY ALPHABET/S-Z/Skiing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from HC ROMS/BY ALPHABET/S-Z/Solaris.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from HC ROMS/BY ALPHABET/S-Z/Space Invaders.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying surround.bin from HC ROMS/BY ALPHABET/S-Z/Surround - Chase.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from HC ROMS/BY ALPHABET/S-Z/Tennis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying trondead.bin from HC ROMS/BY ALPHABET/S-Z/TRON - Deadly Discs.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from HC ROMS/BY ALPHABET/S-Z/Tutankham.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying venture.bin from HC ROMS/BY ALPHABET/S-Z/Venture.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from HC ROMS/BY ALPHABET/S-Z/Video Olympics - Pong Sports.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying video_pinball.bin from HC ROMS/BY ALPHABET/S-Z/Video Pinball - Arcade Pinball.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying wizard_of_wor.bin from HC ROMS/BY ALPHABET/S-Z/Wizard of Wor.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from HC ROMS/BY ALPHABET/S-Z/Yars' Revenge.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from HC ROMS/BY ALPHABET/S-Z/Zaxxon.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n",
            "copying assault.bin from HC ROMS/NTSC VERSIONS OF PAL ORIGINALS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn5WTFePh6uQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d908b61f-af4a-4080-b8b5-c2c0d461211c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 535 kB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.63.0)\n",
            "Collecting alembic\n",
            "  Downloading alembic-1.7.7-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.32)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 77.4 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.2.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=9b77c9370a62b698c1ad5b30bd2dda1cf181b535cab0eb62a77e39a840aedfd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.7.7 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n",
            "Collecting torchtext==0.8.0\n",
            "  Downloading torchtext-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9 MB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.10.0+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.63.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.8.0) (3.10.0.2)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed torchtext-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pygame\n",
        "!pip install optuna\n",
        "!pip install einops\n",
        "!pip install -U torchtext==0.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Imports"
      ],
      "metadata": {
        "id": "_tsA3W-fiOYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, os.path\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import copy"
      ],
      "metadata": {
        "id": "kzHEqP6giQGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import pygame\n",
        "import cv2\n",
        "from google.colab import output\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "drive.mount('/content/drive/')\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1igr-VyJHFU",
        "outputId": "61024623-df51-44fb-ee66-87faa19f8710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Mounted at /content/drive/\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "id": "UDi30Osap7JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyvirtualdisplay import Display\n",
        "# display = Display(visible=0, size=(400, 300))\n",
        "# display.start()"
      ],
      "metadata": {
        "id": "IH2ENjx4p8eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import torch.nn.functional as F\n",
        "from math import log\n"
      ],
      "metadata": {
        "id": "-RrqYduxp_vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.preprocessing import MinMaxScaler,OneHotEncoder\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score,classification_report\n"
      ],
      "metadata": {
        "id": "R4Yw9k65eCWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "3HSrWwVhDC9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field\n",
        "from torchtext.vocab import GloVe\n",
        "embedding_glove = GloVe(name='6B', dim=100)"
      ],
      "metadata": {
        "id": "lsGgaTQ0k-hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16327625-e95e-45e3-d223-dda9ea31de21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.30MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:14<00:00, 27133.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models as torchvision_models\n",
        "import torchvision\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "d-_u3UQOnD16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configurations"
      ],
      "metadata": {
        "id": "pzBgZXR1iqwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Configurations (Pong)"
      ],
      "metadata": {
        "id": "c10AU-p2itgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9k0nWHTBisae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configurations"
      ],
      "metadata": {
        "id": "Qu9rKct1jkJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This part will move the network to the NVIDIA GPU if you have one\n",
        "device = T.device(\"cuda:0\" if T.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pretrained_weight_path = \"model-2fc.pt\""
      ],
      "metadata": {
        "id": "qTojpH_Sjr9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Configurations (Custom Environment)"
      ],
      "metadata": {
        "id": "6QNeu46wiwng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Environments"
      ],
      "metadata": {
        "id": "mDQAk3VEiXeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Project Environment"
      ],
      "metadata": {
        "id": "zsGuDlLMidBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kjvse9Fj3kbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "window_width, window_height = 250, 80\n",
        "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "class CustomEnv(gym.Env):\n",
        "    def __init__(self,env_config={},n_objects=2,max_steps=30,debug=False):\n",
        "      self.n_objects = n_objects\n",
        "      self.corpus = {\n",
        "      0 : 'zero',\n",
        "      1 : 'one',\n",
        "      2 : 'two',\n",
        "      3 : 'three',\n",
        "      4 : 'four',\n",
        "      5 : 'five',\n",
        "      6 : 'six',\n",
        "      7 : 'seven',\n",
        "      8 : 'eight',\n",
        "      9 : 'nine', \n",
        "      }\n",
        "      self.max_steps = max_steps\n",
        "      self.sprites_to_train = 2\n",
        "      self.action_space = gym.spaces.Discrete(4)\n",
        "      self.observation_space = gym.spaces.Box(\n",
        "      low=0, high=255, shape=(window_height,window_width), dtype=np.float16)\n",
        "      (self.trainx, self.trainy), (self.testx, self.testy) = self.loadDataset('mnist')\n",
        "      self.classes = set(trainy)\n",
        "      self.classes_len = len(self.classes)\n",
        "      self.debug = debug\n",
        "      # summarize loaded dataset\n",
        "      if self.debug == True:\n",
        "        print(\"|------------------ Dataset -----------------|\")\n",
        "        print(f'Train: X={self.trainx.shape}, y={self.trainy.shape}')\n",
        "        print(f'Test: X={self.testx.shape}, y={self.testy.shape}')\n",
        "        print(f'Classes: Unique={self.classes}, len={self.classes_len}')\n",
        "        print(\"|--------------------------------------------|\")\n",
        "      self.reset()\n",
        "    def loadDataset(self,dataset_name):\n",
        "      if dataset_name == 'mnist':\n",
        "        return mnist.load_data()\n",
        "\n",
        "    def generate_unique_random(self,prev,corpus):\n",
        "        \n",
        "        input = random.choice(list(corpus.keys()))\n",
        "        if (input in prev):\n",
        "          while (input in prev):\n",
        "            input = random.choice(list(corpus.keys()))\n",
        "        return input\n",
        "\n",
        "    def get_image_from_label(self,data,label):\n",
        "        #get all indexes for given label from data and select an image as random \n",
        "        indexes = []\n",
        "        for i in range(len(data[1])):\n",
        "          if label == data[1][i]:\n",
        "            indexes.append(i)        \n",
        "        image_pixel= np.array(data[0][random.choice(indexes)]).T\n",
        "        #img = Image.fromarray(image_pixel)\n",
        "        return image_pixel\n",
        "\n",
        "    def reset(self):\n",
        "        \n",
        "        self.n_steps = 0\n",
        "        pygame.init()\n",
        "        pygame.font.init()\n",
        "        self.window = pygame.display.set_mode((window_width, window_height))\n",
        "        #self.myfont = pygame.font.SysFont(random.choice(sys_font_list), 15)\n",
        "        self.myfont = pygame.font.SysFont(\"Arial\", 15)\n",
        "        self.clock = pygame.time.Clock()\n",
        "        self.window.fill(0)\n",
        "        self.objects = []\n",
        "        self.instruction_pane_width = 90\n",
        "        self.instruction_pane_height = window_height\n",
        "        self.instruction_pane_x = window_width - self.instruction_pane_width\n",
        "        self.instruction_pane_y = 0\n",
        "        #Create agent\n",
        "        self.action_space = []\n",
        "        self.inputs_choosen = []\n",
        "        self.init_sprite(\"agent_0\",0,0,15,15,path=\"./drive/MyDrive/Final Project/assets/mouse.png\")  \n",
        "        for i in range(self.sprites_to_train):\n",
        "          #ensure same input is not choosen again\n",
        "          input_label = self.generate_unique_random(self.inputs_choosen,self.corpus)\n",
        "          sprite_iamge = self.get_image_from_label((self.trainx,self.trainy),input_label)\n",
        "          #display inputs chosen\n",
        "          # pyplot.imshow(sprite_iamge, cmap=pyplot.get_cmap('gray'))\n",
        "          # pyplot.show()\n",
        "          self.init_sprite(\"sprite_\"+str(i),(i*45)+10,10,42,42,label_class = input_label,image = sprite_iamge,label=input_label,label_text=self.corpus[input_label],augmentation=True)\n",
        "          self.inputs_choosen.append(input_label)\n",
        "        if self.debug == True:\n",
        "          print(f\"Env Objects: {self.objects}\")\n",
        "        self.selected_instruction =random.choice(self.inputs_choosen)\n",
        "        if self.debug == True:\n",
        "          print(f\"self.inputs_choosen: {self.inputs_choosen} self.selected_instruction {self.selected_instruction}\")\n",
        "        self.done = False\n",
        "        return [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"]\n",
        "\n",
        "    def random_augmentation(self,sprite):\n",
        "        #implement code for random augmentation here\n",
        "        return sprite\n",
        "\n",
        "    def init_sprite(self,id,x,y,width,height,label_class=None,path=None,image=None,label = None,label_text = None,augmentation=False):\n",
        "        if path != None:\n",
        "          sprite = pygame.transform.scale(pygame.image.load(path).convert_alpha(), (width,height)) \n",
        "        else:\n",
        "          sprite = pygame.transform.scale(pygame.surfarray.make_surface(image), (width,height))\n",
        "        if augmentation == True:\n",
        "          sprite = self.random_augmentation(sprite) \n",
        "        color = (255,255,255)\n",
        "        \n",
        "        if label == None:\n",
        "          self.objects.append(\n",
        "            {\n",
        "                \"id\" : id,\n",
        "                \"sprite\" : sprite,\n",
        "                \"collision_box\" : sprite.get_rect(x=(window_width - self.instruction_pane_width)/2, y=(window_height)/2),\n",
        "                \"color\" : color,\n",
        "                \"path\" : path,\n",
        "            }\n",
        "          )\n",
        "        else:\n",
        "          if id == \"sprite_0\":\n",
        "            self.objects.append(\n",
        "                {\n",
        "                    \"id\" : id,\n",
        "                    \"sprite\" : sprite,\n",
        "                    \"collision_box\" : sprite.get_rect(x=0, y=y),\n",
        "                    \"label_text\" : label_text,\n",
        "                    \"label\" : self.myfont.render(label_text, False, color),\n",
        "                    \"label_position\" : (x,y+height+5),\n",
        "                    \"label_class\": label_class,\n",
        "                    \"color\" : color,\n",
        "                    \"path\" : path,\n",
        "                }\n",
        "            )\n",
        "          if id == \"sprite_1\":\n",
        "            self.objects.append(\n",
        "                {\n",
        "                    \"id\" : id,\n",
        "                    \"sprite\" : sprite,\n",
        "                    \"collision_box\" : sprite.get_rect(x=window_width - self.instruction_pane_width-width, y=y),\n",
        "                    \"label_text\" : label_text,\n",
        "                    \"label\" : self.myfont.render(label_text, False, color),\n",
        "                    \"label_position\" : (window_width - self.instruction_pane_width-width,y+height+5),\n",
        "                    \"label_class\": label_class,\n",
        "                    \"color\" : color,                 \n",
        "                    \"path\" : path,\n",
        "                }\n",
        "            )\n",
        "    def check_agent_collision(self):\n",
        "      sprite_collision_boxes = []\n",
        "      for i in range(len(self.objects)):\n",
        "        if self.objects[i][\"id\"] == \"agent_0\":\n",
        "          agent_collision_box = self.objects[i][\"collision_box\"]\n",
        "        else:\n",
        "          sprite_collision_boxes.append(self.objects[i][\"collision_box\"])\n",
        "      for i in range(len(sprite_collision_boxes)):\n",
        "        if sprite_collision_boxes[i].colliderect(agent_collision_box):\n",
        "          #print(f\"Collision Detected between agent_0 and sprite_{i}\")\n",
        "          return True,\"sprite_\"+str(i)\n",
        "      return False,None\n",
        "    def move_sprite(self,id,x,y):\n",
        "      for i in range(len(self.objects)):\n",
        "        if self.objects[i][\"id\"] == id:\n",
        "          collision_box = self.objects[i][\"collision_box\"]\n",
        "          \n",
        "          self.objects[i][\"collision_box\"] = self.objects[i][\"sprite\"].get_rect(x=collision_box.x+x, y=collision_box.y+y)\n",
        "          collision_box = self.objects[i][\"collision_box\"]\n",
        "\n",
        "        if collision_box.x >= window_width - self.instruction_pane_width or collision_box.x < 0 or collision_box.y >= window_height or collision_box.y < 0:\n",
        "          self.done = True\n",
        "    def step(self, action=np.zeros((1),dtype=np.int32)):\n",
        "        if action == 0:  # Right\n",
        "          self.move_sprite(\"agent_0\",10,0)\n",
        "        if action == 1:  # Left\n",
        "          self.move_sprite(\"agent_0\",-10,0)\n",
        "        if action == 2:  # Up\n",
        "          self.move_sprite(\"agent_0\",0,-10)\n",
        "        if action == 3:  # Down\n",
        "          self.move_sprite(\"agent_0\",0,10)\n",
        "        collision,id = self.check_agent_collision() \n",
        "        if collision:\n",
        "          for i in range(len(self.objects)):\n",
        "            if self.objects[i][\"id\"] == id and self.objects[i][\"label_class\"] == self.selected_instruction:\n",
        "              self.reset()\n",
        "              observation, reward, done, info = [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"], 2, self.done, {}\n",
        "              break\n",
        "              \n",
        "            else:\n",
        "\n",
        "              observation, reward, done, info = [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"], -1, True, {}\n",
        "\n",
        "        else:\n",
        "          if self.done == True:\n",
        "            observation, reward, done, info = [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"], 0, self.done, {}\n",
        "          else:\n",
        "            observation, reward, done, info = [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"],-0.01, self.done, {}\n",
        "        if self.n_steps > self.max_steps: \n",
        "          observation, reward, done, info = [self.observation_to_img(),self.inputs_choosen,self.selected_instruction,f\"Where is {self.corpus[self.selected_instruction]} ?\"], -1, True, {}\n",
        "\n",
        "        self.n_steps += 1\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def observation_to_img(self):\n",
        "        self.window.fill(0)\n",
        "        # draw orientation\n",
        "        # p1 = (self.x - 10 * np.cos(self.ang),self.y + 10 * np.sin(self.ang))\n",
        "        # p2 = (self.x + 15 * np.cos(self.ang),self.y - 15 * np.sin(self.ang))\n",
        "        # pygame.draw.line(self.window,(0,100,100),p1,p2,2)\n",
        "        self.render_instructions()\n",
        "        for elem in self.objects:\n",
        "          self.window.blit(elem[\"sprite\"], elem[\"collision_box\"])\n",
        "          if \"label\" in elem.keys():\n",
        "            self.window.blit(elem[\"label\"],elem[\"label_position\"])\n",
        "        #Display image, clear cell every 0.5 seconds\n",
        "        \n",
        "        pygame.display.update()\n",
        "        #convert image so it can be displayed in OpenCV\n",
        "        view = pygame.surfarray.array3d(self.window)\n",
        "        #  convert from (width, height, channel) to (height, width, channel)\n",
        "        view = view.transpose([1, 0, 2])\n",
        "        #  convert from rgb to bgr\n",
        "        img_bgr = cv2.cvtColor(view, cv2.COLOR_RGB2GRAY)\n",
        "        return img_bgr\n",
        "\n",
        "    def render_instructions(self):\n",
        "        pygame.draw.rect(self.window, (0, 0,0), (self.instruction_pane_x,self.instruction_pane_y,self.instruction_pane_width,self.instruction_pane_height))\n",
        "        title = self.myfont.render('Instructions:', False, (255, 255, 255))\n",
        "        self.window.blit(title,(self.instruction_pane_x+20,20))\n",
        "        instruction_1 = self.myfont.render(f'Find {self.corpus[self.selected_instruction]}', False, (255, 255, 255))\n",
        "        self.window.blit(instruction_1,(self.instruction_pane_x+20,40))\n",
        "\n",
        "    #def render_screen(self):\n",
        "        \n",
        "    def render(self):\n",
        "        \n",
        "        cv2_imshow(self.observation_to_img())\n",
        "        time.sleep(0.1)\n",
        "        output.clear()\n",
        "\n",
        "cust_env = CustomEnv()\n"
      ],
      "metadata": {
        "id": "g8HOk2HOZdcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Random agent driver code\n",
        "# env = CustomEnv()\n",
        "# running_reward = 0\n",
        "# while reward < 200:\n",
        "#   done = False\n",
        "#   observation = env.reset()\n",
        "#   running_reward = 0\n",
        "#   while not done:\n",
        "#       observation = observation\n",
        "#       action = 1#np.random.choice([0,1,2,3])\n",
        "#       #print(f\"action {action}\")\n",
        "#       observation_, reward, done, info = env.step(action)\n",
        "#       running_reward += reward\n",
        "#       print(running_reward)\n",
        "#       env.render()\n",
        "#   print(\"Episode Done\")\n",
        "  "
      ],
      "metadata": {
        "id": "G5MwocLMIh_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Utils"
      ],
      "metadata": {
        "id": "JDTyydLaaOfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Learning"
      ],
      "metadata": {
        "id": "9ZSU3Z_SaRjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLearning(x, scores, epsilons, filename, lines=None):\n",
        "    fig=plt.figure()\n",
        "    ax=fig.add_subplot(111, label=\"1\")\n",
        "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
        "\n",
        "    ax.plot(x, epsilons, color=\"C0\")\n",
        "    ax.set_xlabel(\"Game\", color=\"C0\")\n",
        "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
        "    ax.tick_params(axis='x', colors=\"C0\")\n",
        "    ax.tick_params(axis='y', colors=\"C0\")\n",
        "\n",
        "    N = len(scores)\n",
        "    running_avg = np.empty(N)\n",
        "    for t in range(N):\n",
        "\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
        "\n",
        "    ax2.scatter(x, running_avg, color=\"C1\")\n",
        "    #ax2.xaxis.tick_top()\n",
        "    ax2.axes.get_xaxis().set_visible(False)\n",
        "    ax2.yaxis.tick_right()\n",
        "    #ax2.set_xlabel('x label 2', color=\"C1\")\n",
        "    ax2.set_ylabel('Score', color=\"C1\")\n",
        "    #ax2.xaxis.set_label_position('top')\n",
        "    ax2.yaxis.set_label_position('right')\n",
        "    #ax2.tick_params(axis='x', colors=\"C1\")\n",
        "    ax2.tick_params(axis='y', colors=\"C1\")\n",
        "\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            plt.axvline(x=line)\n",
        "\n",
        "    plt.savefig(filename)"
      ],
      "metadata": {
        "id": "umWguX2saQFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trunc Normal"
      ],
      "metadata": {
        "id": "z5tVROnHMF-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
        "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
        "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
        "    def norm_cdf(x):\n",
        "        # Computes standard normal cumulative distribution function\n",
        "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
        "\n",
        "    with T.no_grad():\n",
        "        # Values are generated by using a truncated uniform distribution and\n",
        "        # then using the inverse CDF for the normal distribution.\n",
        "        # Get upper and lower cdf values\n",
        "        l = norm_cdf((a - mean) / std)\n",
        "        u = norm_cdf((b - mean) / std)\n",
        "\n",
        "        # Uniformly fill tensor with values from [l, u], then translate to\n",
        "        # [2l-1, 2u-1].\n",
        "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
        "\n",
        "        # Use inverse cdf transform for normal distribution to get truncated\n",
        "        # standard normal\n",
        "        tensor.erfinv_()\n",
        "\n",
        "        # Transform to proper mean, std\n",
        "        tensor.mul_(std * math.sqrt(2.))\n",
        "        tensor.add_(mean)\n",
        "\n",
        "        # Clamp to ensure it's in the proper range\n",
        "        tensor.clamp_(min=a, max=b)\n",
        "        return tensor\n",
        "\n",
        "\n",
        "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
        "    # type: (Tensor, float, float, float, float) -> Tensor\n",
        "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)"
      ],
      "metadata": {
        "id": "2aZKGrv6MH2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pong Model & Agent"
      ],
      "metadata": {
        "id": "bmW4DlD7qFt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "JuaYVw9gqIRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepQNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self,n_actions):\n",
        "        super(DeepQNetwork,self).__init__()\n",
        "        # self.resnet18 = models.resnet18(pretrained=True)\n",
        "        # self.resnet18.conv1 = torch.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
        "        # #summary(resnet18,(1,224,224))\n",
        "        # for param in self.resnet18.parameters():\n",
        "        #   param.requires_grad = False\n",
        "        self.layers = nn.Sequential(\n",
        "          nn.Conv2d(3, 8, kernel_size=3),\n",
        "          nn.MaxPool2d( kernel_size=2, stride=2),\n",
        "          nn.Conv2d(8, 16, kernel_size=3),\n",
        "          nn.MaxPool2d( kernel_size=3),\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(13600, 512),\n",
        "          #nn.BatchNorm1d(2048),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(512, 128),\n",
        "          #nn.BatchNorm1d(1024),\n",
        "          nn.ReLU(),\n",
        "          # nn.Linear(1024, 512),\n",
        "          # #nn.BatchNorm1d(512),\n",
        "          # nn.ReLU(),\n",
        "          # nn.Linear(512, 128),\n",
        "          # nn.ReLU(),\n",
        "          nn.Linear(128, n_actions)\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        actions = self.layers(x.type(T.cuda.FloatTensor))\n",
        "        return actions\n"
      ],
      "metadata": {
        "id": "qgeEwqNIqKn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "ifPn-mXfTc4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random agent driver code\n",
        "# for episode in range(3):\n",
        "#   done = False\n",
        "#   observation = env.reset()\n",
        "#   while not done:\n",
        "#       observation = observation\n",
        "#       action = np.random.choice([0,1,2,3])\n",
        "#       print(f\"action {action}\")\n",
        "#       observation_, reward, done, info = env.step(action)\n",
        "#       env.render()\n",
        "#   print(\"Episode Done\")\n",
        "#   print(reward)"
      ],
      "metadata": {
        "id": "tz5LtPsrypb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    def __init__(self,model, input_dims, batch_size, n_actions,\n",
        "                 max_mem_size=100000, eps_end=0.01, eps_dec=5e-4,update_target_network_frequency = 100, epsilon=1.00,gamma=0.99):\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_min = eps_end\n",
        "        self.eps_dec = eps_dec\n",
        "        self.action_space = [i for i in range(n_actions)]\n",
        "        self.mem_size = max_mem_size\n",
        "        self.batch_size = batch_size\n",
        "        self.mem_cntr = 0\n",
        "        self.iter_cntr = 0\n",
        "\n",
        "        self.Q_eval = model\n",
        "        self.target_network = copy.deepcopy(self.Q_eval)\n",
        "        self.update_target_network_frequency = update_target_network_frequency\n",
        "        self.state_memory = np.zeros((self.mem_size, *input_dims),\n",
        "                                     dtype=np.float32)\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *input_dims),\n",
        "                                         dtype=np.float32)\n",
        "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
        "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
        "\n",
        "    def store_transition(self, state, action, reward, state_, terminal):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        self.state_memory[index] = state\n",
        "        self.new_state_memory[index] = state_\n",
        "        self.reward_memory[index] = reward\n",
        "        self.action_memory[index] = action\n",
        "        self.terminal_memory[index] = terminal\n",
        "\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def choose_action(self, observation):\n",
        "        if np.random.random() > self.epsilon:\n",
        "            state = T.tensor([observation]).to(device)\n",
        "            actions = self.Q_eval.forward(state)\n",
        "            action = T.argmax(actions).item()\n",
        "        else:\n",
        "            action = np.random.choice(self.action_space)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def learn(self,criterion,optimizer):\n",
        "        if self.mem_cntr < self.batch_size:\n",
        "            return\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
        "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
        "\n",
        "        state_batch = T.tensor(self.state_memory[batch])\n",
        "        new_state_batch = T.tensor(\n",
        "                self.new_state_memory[batch])\n",
        "        action_batch = self.action_memory[batch]\n",
        "        reward_batch = T.tensor(\n",
        "                self.reward_memory[batch])\n",
        "        terminal_batch = T.tensor(\n",
        "                self.terminal_memory[batch])\n",
        "        \n",
        "        q_eval = self.Q_eval.forward(state_batch.to(device))[batch_index, action_batch]\n",
        "        q_next = self.target_network(new_state_batch.to(device))\n",
        "        q_next[terminal_batch] = 0.0\n",
        "\n",
        "        q_target = reward_batch.to(device) + self.gamma*T.max(q_next, dim=1)[0]\n",
        "        #print(f\"q_target {q_target} q_eval {q_eval}\")\n",
        "        loss = criterion(q_target, q_eval)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if self.iter_cntr % self.update_target_network_frequency == 0:\n",
        "          self.target_network = copy.deepcopy(self.Q_eval)\n",
        "        self.iter_cntr += 1\n",
        "        self.epsilon = self.epsilon - self.eps_dec \\\n",
        "            if self.epsilon > self.eps_min else self.eps_min"
      ],
      "metadata": {
        "id": "QJDO3h9pTeUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train one episode"
      ],
      "metadata": {
        "id": "61PS3BOUqLBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ping_pong_agent(env,agent,model,episodes,criterion,optimizer,input_dims, n_actions):\n",
        "  scores, eps_history = [], []\n",
        "\n",
        "  for i in range(episodes):\n",
        "      score = 0\n",
        "      done = False\n",
        "      observation = env.reset()\n",
        "      time_per_episode = time.time()\n",
        "      while not done:\n",
        "          observation = observation.reshape(input_dims)\n",
        "          action = agent.choose_action(observation)\n",
        "          #print(f\"action {action}\")\n",
        "          observation_, reward, done, info = env.step(action)\n",
        "          score += reward\n",
        "          observation_ = observation_.reshape(input_dims)\n",
        "          agent.store_transition(observation, action, reward, \n",
        "                                  observation_, done)\n",
        "          agent.learn(criterion,optimizer)\n",
        "          observation = observation_\n",
        "      scores.append(score)\n",
        "      eps_history.append(agent.epsilon)\n",
        "\n",
        "      avg_score = np.mean(scores[-100:])\n",
        "\n",
        "      print(f\"episode {i} score {score} average score {avg_score} epsilon {agent.epsilon} time {(time.time() - time_per_episode)} seconds\")\n",
        "      T.save(model.state_dict(), pretrained_weight_path)\n",
        "\n",
        "  x = [i+1 for i in range(episodes)]\n",
        "  filename = 'ping_pong.png'\n",
        "  plotLearning(x, scores, eps_history, filename)"
      ],
      "metadata": {
        "id": "y6OjdiLmqYjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Method"
      ],
      "metadata": {
        "id": "_zLAY1n9qY4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# env = gym.make(\"Pong-v0\")\n",
        "# episodes_to_train = 1000\n",
        "# pretrained_weight_path = \"model-2fc.pt\"\n",
        "# batch_size = 64\n",
        "# lr = 1e-4\n",
        "# n_actions=env.action_space.n\n",
        "# input_dims_shape = env.observation_space.shape\n",
        "# input_dims= (input_dims_shape[2],input_dims_shape[1],input_dims_shape[0])\n",
        "# print(f\"No of actions {n_actions} input_dims {input_dims} \")\n",
        "\n",
        "\n",
        "\n",
        "# model = DeepQNetwork(env.action_space.n)\n",
        "# model  = model.to(device)\n",
        "# if os.path.isfile(pretrained_weight_path):\n",
        "#      model.load_state_dict(T.load(pretrained_weight_path))\n",
        "# optimizer = T.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "# loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "# agent = Agent(model,input_dims=input_dims, batch_size=batch_size, n_actions=n_actions,max_mem_size=10000,update_target_network_frequency = 1000)\n",
        "# train_ping_pong_agent(env,agent,model,episodes_to_train,criterion=loss,optimizer=optimizer,input_dims=input_dims, n_actions=n_actions)\n"
      ],
      "metadata": {
        "id": "gOy2FZ1kqb2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vision Transformer"
      ],
      "metadata": {
        "id": "XX3Wq3xrya0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sddNsB5Qcaaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mnist"
      ],
      "metadata": {
        "id": "xL9TCzRslrYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Dataloader"
      ],
      "metadata": {
        "id": "ZPY7Odg7yjFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistDatasetTrainClass(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "      self.label =[]\n",
        "      self.images = []\n",
        "      self.label_dict = {}\n",
        "      start_time = time.time()\n",
        "      (self.trainX, self.trainy), (self.testX, self.testy) = mnist.load_data()\n",
        "      self.width,self.height  = width,height\n",
        "      print(\"|------Loaded Mnist Dataset------|\")\n",
        "      print('Train: X=%s, y=%s' % (self.trainX.shape, self.trainy.shape))\n",
        "      print('Test: X=%s, y=%s' % (self.testX.shape, self.testy.shape))\n",
        "      for i,label in enumerate(self.trainy):\n",
        "        if label in self.label_dict:\n",
        "          self.label_dict[label].append(i) \n",
        "        else: \n",
        "          self.label_dict[label] = [i]\n",
        "      self.num_samples = num_samples\n",
        "      print(\"|------Test Dataset Generated------|\")\n",
        "      print(f\"Total Labels {len(self.label_dict)} Time to load: {time.time() - start_time} seconds\")\n",
        "\n",
        "    def detach_cropped_area(self,im):\n",
        "        image = Image.fromarray(im)\n",
        "        newimage = image.resize((self.width,self.height))\n",
        "        scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        scaler.fit(newimage)\n",
        "        newimage = scaler.transform(newimage)\n",
        "        \n",
        "        return T.tensor(np.array(newimage), dtype=T.float32)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        clas = np.random.randint(0,10)\n",
        "        idx_1 = np.random.randint(0,len(self.label_dict[clas])) \n",
        "        img_1_idx = self.label_dict[clas][idx_1]\n",
        "        img1 = self.detach_cropped_area(self.trainX[img_1_idx]).reshape(1,self.width,self.height)\n",
        "        # img2 = self.detach_cropped_area(self.trainX[img_2_idx]).reshape(1,self.width,self.height)\n",
        "        y1 = clas\n",
        "        \n",
        "        # clas2 = np.random.randint(0,10)\n",
        "        # while clas2 == clas:\n",
        "        #     clas2 = np.random.randint(0,10)\n",
        "\n",
        "        # if clas2 == clas:\n",
        "        #   print(\"Same  positive and negative labels detected\")\n",
        "        # idx_3 = np.random.randint(0,len(self.label_dict[clas])) \n",
        "        # idx_4 = np.random.randint(0,len(self.label_dict[clas2])) \n",
        "        # img_3_idx,img_4_idx = self.label_dict[clas][idx_3],self.label_dict[clas2][idx_4]\n",
        "        # img3 = self.detach_cropped_area(self.trainX[img_3_idx]).reshape(1,self.width,self.height)\n",
        "        # img4 = self.detach_cropped_area(self.trainX[img_4_idx]).reshape(1,self.width,self.height)\n",
        "        # y2 = torch.tensor(np.zeros(1,dtype=np.float32),dtype=torch.float32)\n",
        "\n",
        "        return  img1, y1\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return self.num_samples\n",
        "MnistDatasetTrain = MnistDatasetTrainClass(60000,width=224,height=224)\n",
        "# train_dataloader_mnist = DataLoader(MnistDatasetTrain, shuffle=True, batch_size= 4,num_workers=1)\n",
        "# for count_idx,data in enumerate(train_dataloader_mnist):\n",
        "#   img1, y1 = data\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(f\"------------img1 {y1}-------------\")\n",
        "#   print(img1.shape)\n",
        "#   im = pyplot.imshow(img1[0].numpy().reshape(224,224))\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img2-------------\")\n",
        "#   im = pyplot.imshow(img2[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img3-------------\")\n",
        "#   im = pyplot.imshow(img3[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------img4-------------\")\n",
        "#   im = pyplot.imshow(img4[0].numpy())\n",
        "#   pyplot.show()\n",
        "#   print(\"------------y1-------------\")\n",
        "#   print(y1)\n",
        "#   print(\"------------y2-------------\")\n",
        "#   print(y2)\n",
        "#   print(\"-------------------------------\")\n",
        "#   print(\"-------------------------------\")\n",
        "#   break"
      ],
      "metadata": {
        "id": "Hxu2vsa-_4Zy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bb5ca7-2e52-4324-aef8-4f3f386f9f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|------Loaded Mnist Dataset------|\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n",
            "|------Test Dataset Generated------|\n",
            "Total Labels 10 Time to load: 0.3094635009765625 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision Transformer Network"
      ],
      "metadata": {
        "id": "sgOCShgjy-gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x)\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
        "\n",
        "        dots = T.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, float('-inf'))\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = T.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, mlp_dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask=mask)\n",
        "            x = ff(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "GmDOIdU9LRv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Reference Link https://towardsdatascience.com/a-demonstration-of-using-vision-transformers-in-pytorch-mnist-handwritten-digit-recognition-407eafbc15b0\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    \"\"\" Vision Transformer \"\"\"\n",
        "    def __init__(self, image_size=224, patch_size=8, in_channels=1, num_classes=10, embed_dim=64, depth=2,\n",
        "                 heads=8, mlp_ratio=2, qkv_bias=False, qk_scale=None, norm_layer=nn.LayerNorm, **kwargs):\n",
        "        super().__init__()\n",
        "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = in_channels * patch_size ** 2\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.pos_embedding = nn.Parameter(T.randn(1, num_patches + 2, embed_dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, embed_dim)\n",
        "        self.cls_token = nn.Parameter(T.randn(1, 1, embed_dim))\n",
        "        self.sep_token = nn.Parameter(T.randn(1, 1, embed_dim))\n",
        "        self.transformer = Transformer(embed_dim, depth, heads,embed_dim * mlp_ratio)\n",
        "\n",
        "        self.to_cls_token = nn.Identity()\n",
        "        self.to_sep_token = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim * mlp_ratio, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, input, mask=None):\n",
        "        p = self.patch_size\n",
        "\n",
        "        x = rearrange(input, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = p, p2 = p)\n",
        "        x = self.patch_to_embedding(x)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(input.shape[0], -1, -1)\n",
        "        sep_tokens = self.sep_token.expand(input.shape[0], -1, -1)\n",
        "        x = T.cat((cls_tokens, x,sep_tokens ), dim=1)\n",
        "        x += self.pos_embedding\n",
        "        x = self.transformer(x, mask)\n",
        "\n",
        "        #x = self.to_cls_token(x[:, 0])\n",
        "        x = self.to_sep_token(x[:, -1])\n",
        "        return self.mlp_head(x)\n"
      ],
      "metadata": {
        "id": "IiSwZYm7zB1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train One Epoch"
      ],
      "metadata": {
        "id": "b0yi-Kj4y3w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_visionTransformer(model,batch_size, num_epochs, Criterion,Optimizer):\n",
        "    train_losses = []\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    train_dataloader_mnist = DataLoader(MnistDatasetTrain, shuffle=True, batch_size= batch_size,num_workers=1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        correct_batch_prediction_count = 0\n",
        "        start_time = time.time()\n",
        "        for count_idx,data in enumerate(train_dataloader_mnist):\n",
        "          # if (epoch+1) % 1 == 0:\n",
        "          #   validationAccuracy(model)\n",
        "          img1,label1 = data\n",
        "          Optimizer.zero_grad()\n",
        "\n",
        "          # here we obtain the positive pairs' loss as well as the negative pairs' loss\n",
        "          #print(np.array(img1.shape))\n",
        "          output1 = model(img1.to(device))\n",
        "          loss_pos = Criterion( T.nn.functional.log_softmax(output1, dim=1),label1.to(device))\n",
        "          loss_pos.backward()\n",
        "          running_loss += loss_pos.item()\n",
        "          Optimizer.step()\n",
        "\n",
        "          \n",
        "          \n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_train_loss} Time: {time.time() - start_time}')\n",
        "        \n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        T.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/transformer2.pth\")\n",
        " \n",
        "    return train_losses"
      ],
      "metadata": {
        "id": "Mawt-17ky3G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Method"
      ],
      "metadata": {
        "id": "Muy3YkISy1zw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://towardsdatascience.com/how-to-code-the-transformer-in-pytorch-24db27c8f9ec"
      ],
      "metadata": {
        "id": "4mjB4m6rOXU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VisionTransformer()\n",
        "\n",
        "# model = model.to(device)\n",
        "# pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/transformer2.pth\"\n",
        "# # if os.path.isfile(pretrained_weight_path):\n",
        "# #model.load_state_dict(T.load(pretrained_weight_path))\n",
        "# params = model.parameters()\n",
        "# loss = T.nn.functional.nll_loss#ContrastiveLoss()#\n",
        "# optimizer = T.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "# train_visionTransformer(model,16,500,loss,optimizer)"
      ],
      "metadata": {
        "id": "Z5Up7iXf4ECz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Environment"
      ],
      "metadata": {
        "id": "h4pN4TeOlemU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Dataloader"
      ],
      "metadata": {
        "id": "ZXg9wCjrlkBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetTrainClass(Dataset):\n",
        "    \n",
        "    def __init__(self,num_samples,verbose=False,width=224,height=224):\n",
        "        self.verbose = verbose\n",
        "        start_time = time.time()\n",
        "        # imgs = []\n",
        "        # self.label = []\n",
        "        # path = \"/content/drive/MyDrive/Final Project/dataset/train/\"\n",
        "        # valid_images = [\".jpg\"]\n",
        "        # count =0 \n",
        "        # for f in os.listdir(path):\n",
        "        #     ext = os.path.splitext(f)[1]\n",
        "        #     if ext.lower() not in valid_images:\n",
        "        #         continue\n",
        "        #     if self.verbose:\n",
        "        #       print(f\"Loaded {count}\")\n",
        "        #     imgs.append(np.array(Image.open(os.path.join(path,f))))\n",
        "        #     self.label.append(f[-5])\n",
        "        #     count = count + 1\n",
        "        #     if count >= num_samples:\n",
        "        #       break\n",
        "        # self.images = np.array(imgs)\n",
        "        self.num_samples = num_samples\n",
        "        self.label =[]\n",
        "        self.images = []\n",
        "        self.instructions = []\n",
        "        self.img_width,self.img_height = width,height\n",
        "        start_time = time.time()\n",
        "        for i in range(num_samples):\n",
        "          if (i + 1)  % 1000 == 0:\n",
        "            print(f\"1000 samples generated Time to load: {time.time() - start_time}\")\n",
        "          observation = cust_env.reset()\n",
        "          self.images.append(observation[0])\n",
        "          self.instructions.append(observation[-1])\n",
        "          temp_label = observation[1].index(observation[2])\n",
        "          if temp_label == 0:\n",
        "            self.label.append([1,0])\n",
        "          else:\n",
        "            self.label.append([0,1])\n",
        "        print(\"|------Train Dataset Generated------|\")\n",
        "        print(f\"Total Images {np.array(self.images).shape} Labels {np.array(self.label).shape} Instructions {np.array(self.instructions).shape} Time to load: {time.time() - start_time} seconds\")\n",
        "        # print(\"|------Dataset Loaded------|\")\n",
        "        # print(f\"Total Images {self.images.shape} Labels {len(self.label)} Time to load: {time.time() - start_time} seconds\")\n",
        "    def detach_cropped_area(self,im):\n",
        "        image = Image.fromarray(im).crop((0, 0, 130, 80))\n",
        "        newimage = image.resize((self.img_width,self.img_height))\n",
        "        scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        scaler.fit(newimage)\n",
        "        newimage = scaler.transform(newimage)\n",
        "        \n",
        "        return T.tensor(np.array(newimage), dtype=T.float32)\n",
        "    def tokenize_instruction(self,instruction):\n",
        "        tokenized_instruction = []\n",
        "        for word in instruction.split():\n",
        "          tokenized_instruction.append(embedding_glove[word.lower()].numpy())\n",
        "        return np.array(tokenized_instruction).reshape(len(instruction.split()),-1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        im = self.detach_cropped_area(self.images[idx])\n",
        "        instruction = self.tokenize_instruction(self.instructions[idx])\n",
        "        return  np.array(im),instruction,self.label[idx]\n",
        "            \n",
        "    def __len__(self):\n",
        "        \n",
        "        # here I gave a smaller length than the real dataset's length so that the training can be faster\n",
        "            \n",
        "        return self.num_samples\n",
        "\n",
        "# CustomDatasetTrain = CustomDatasetTrainClass(2000)\n",
        "# train_dataloader_custom_dataset = DataLoader(CustomDatasetTrain, shuffle=True, batch_size= 2,num_workers=1)\n",
        "# for count_idx,data in enumerate(train_dataloader_custom_dataset):\n",
        "#   imgs,instructions,labels = data\n",
        "#   print(\"-----------------------Start-------------------------------\")\n",
        "#   print(f\"------------img1 {imgs[0].shape} instruction {instructions.shape} label {labels[0]}-------------\")\n",
        "#   print(instructions[0])\n",
        "#   im = plt.imshow(imgs[0])\n",
        "#   plt.show()\n",
        "#   print(\"-------------------------End-----------------------------\")\n"
      ],
      "metadata": {
        "id": "NHAXOPOLlpTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CustomDatasetTest = CustomDatasetTrainClass(500)\n"
      ],
      "metadata": {
        "id": "DxsdJYsaMFgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def return_label(x):\n",
        "  prediction = []\n",
        "  for data in x:\n",
        "    prediction.append(data.argmax())\n",
        "  return prediction\n",
        "def validationAccuracy_custom(trained_model):\n",
        "  \n",
        "  test_dataloader = DataLoader(CustomDatasetTest, shuffle=True, batch_size=5,num_workers=4)\n",
        "  with T.no_grad():\n",
        "    model.eval()\n",
        "    t_label = []\n",
        "    p_labels = []\n",
        "    for itr,data in enumerate(test_dataloader):\n",
        "        imgs,instructions,labels = data\n",
        "        logits = model(imgs.reshape(-1,1,224,224).to(device),instructions.to(device)).reshape(-1).cpu().numpy()\n",
        "\n",
        "        # print(f\"------------instructions: {instructions} logits {logits.cpu()[0]} labels {labels}-------------\")\n",
        "        # im = plt.imshow(imgs[0].numpy().reshape(224,224))\n",
        "        # plt.show()\n",
        "        # here we obtain the positive pairs' loss as well as the negative pairs' loss\n",
        "        #print(np.array(img1.shape))\n",
        "        logits = model(imgs.reshape(-1,1,224,224).to(device),instructions.to(device))\n",
        "        new_labels = []\n",
        "        for label in labels:\n",
        "          new_labels.append(label.numpy())\n",
        "        p_label = return_label( logits.cpu())\n",
        "        target_label = return_label( T.tensor(np.array(new_labels).reshape(-1,2)).type(T.float32))\n",
        "        #logits = [i.argmax() for i in T.sigmoid(logits) ]\n",
        "        t_label.append(target_label)\n",
        "        p_labels.append(p_label)\n",
        "    t_label = np.array(t_label).reshape(500)\n",
        "    print(t_label)\n",
        "    p_labels = np.array(p_labels).reshape(500)\n",
        "    print(p_labels)\n",
        "  print(f\"Validation accuracy: {classification_report(t_label,p_labels, target_names=['class 0','class 1'])}\")"
      ],
      "metadata": {
        "id": "oGPVRHL3Xww4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vision & Language Transformer (VLMo)"
      ],
      "metadata": {
        "id": "y0hK5jT_vJNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x)\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
        "\n",
        "        dots = T.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, float('-inf'))\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = T.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net_vision = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_language = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_common= nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_vision.apply(self.init_weights)\n",
        "        self.net_language.apply(self.init_weights)\n",
        "        self.net_common.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self,m):\n",
        "      if isinstance(m, nn.Linear):\n",
        "          T.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)\n",
        "    def forward(self, x,data_type=None):\n",
        "      if data_type == \"vision\":\n",
        "        return self.net_vision(x)\n",
        "      if data_type == \"language\":\n",
        "        return self.net_language(x)\n",
        "      if data_type == None:\n",
        "        return self.net_common(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, mlp_dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        \n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, mask=None,data_type=None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask=mask)\n",
        "            x = ff(x,data_type=data_type)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QIhSct_TvNSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VLMo(nn.Module):\n",
        "    \"\"\" VLMo \"\"\"\n",
        "    def __init__(self, image_size=224, patch_size=8,instruction_size = 4,instruction_dim =100, in_channels=1, num_classes=2, embed_dim=128, depth=4,\n",
        "                 heads=8, mlp_ratio=2, qkv_bias=False, qk_scale=None, norm_layer=nn.LayerNorm, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        #Vision patching\n",
        "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        patch_dim = in_channels * patch_size ** 2\n",
        "\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.pos_embedding_image = nn.Parameter(T.randn(1, num_patches + 1, embed_dim))\n",
        "        self.patch_to_embedding = nn.Linear(patch_dim, embed_dim)\n",
        "\n",
        "        #Instruction Embedding\n",
        "        self.instruction_size = instruction_size\n",
        "        self.instruction_dim = instruction_dim\n",
        "        self.pos_embedding_instruction = nn.Parameter(T.randn(1, self.instruction_size + 1, embed_dim))\n",
        "        self.instruction_to_embedding = nn.Linear(self.instruction_dim, embed_dim)\n",
        "\n",
        "\n",
        "\n",
        "        #Common for vision and language\n",
        "        self.cls_token = nn.Parameter(T.randn(1, 1, embed_dim))\n",
        "        self.transformer = Transformer(embed_dim, depth, heads,embed_dim * mlp_ratio)\n",
        "        self.transformer_common = Transformer(embed_dim, depth, heads,embed_dim * mlp_ratio)\n",
        "        self.to_cls_token = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim * mlp_ratio, num_classes)\n",
        "        )\n",
        "        #.transformer.apply(self.init_weights)\n",
        "        self.mlp_head.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self,m):\n",
        "      if isinstance(m, nn.Linear):\n",
        "          T.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)\n",
        "\n",
        "      \n",
        "\n",
        "    def forward(self, image,instruction, mask=None):\n",
        "        # Embedding Images\n",
        "        x_image = rearrange(image, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = self.patch_size, p2 = self.patch_size)\n",
        "        x_image = self.patch_to_embedding(x_image)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(image.shape[0], -1, -1)\n",
        "\n",
        "        x_image = T.cat((cls_tokens, x_image), dim=1)\n",
        "        x_image += self.pos_embedding_image\n",
        "        x_image = self.transformer(x_image, mask,data_type=\"vision\")\n",
        "\n",
        "        # Embedding Instruction\n",
        "        #x_instruction = rearrange(image, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = self.patch_size, p2 = self.patch_size)\n",
        "        x_instruction = self.instruction_to_embedding(instruction)\n",
        "        cls_tokens = self.cls_token.expand(instruction.shape[0], -1, -1)\n",
        "\n",
        "        x_instruction = T.cat((cls_tokens,x_instruction ), dim=1)\n",
        "        x_instruction += self.pos_embedding_instruction\n",
        "        x_instruction = self.transformer(x_instruction, mask,data_type=\"language\")\n",
        "        #print(f\" image.shape {x_image.shape} instruction.shape {x_instruction.shape}\")\n",
        "\n",
        "        # Embedding Vision and Language\n",
        "        x_image_instruction = T.cat((x_image, x_instruction ), dim=1)\n",
        "        x_instruction = self.transformer_common(x_image_instruction, mask,data_type=None)\n",
        "        #x = self.to_cls_token(x[:, 0])\n",
        "        x = self.to_cls_token(x_instruction[:, 0])\n",
        "        return self.mlp_head(x)\n"
      ],
      "metadata": {
        "id": "6BMjC1gDvQ_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train One Epoch"
      ],
      "metadata": {
        "id": "GEObLlYmvUDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_VLMo(model,batch_size, num_epochs, Criterion,Optimizer):\n",
        "    train_losses = []\n",
        "    #val_losses = []\n",
        "    cur_step = 0\n",
        "    train_dataloader_custom_dataset = DataLoader(CustomDatasetTrain, shuffle=True, batch_size= batch_size,num_workers=1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        #print(f\"Starting epoch {str(epoch+1)} / {num_epochs}\")\n",
        "        correct_batch_prediction_count = 0\n",
        "        start_time = time.time()\n",
        "        if (epoch) % 10 == 0:\n",
        "            validationAccuracy_custom(model)\n",
        "        for count_idx,data in enumerate(train_dataloader_custom_dataset):\n",
        "          \n",
        "          imgs,instructions,labels = data\n",
        "          Optimizer.zero_grad()\n",
        "\n",
        "          # here we obtain the positive pairs' loss as well as the negative pairs' loss\n",
        "          #print(np.array(img1.shape))\n",
        "          logits = model(imgs.reshape(-1,1,224,224).to(device),instructions.to(device))\n",
        "          new_labels = []\n",
        "          for label in labels:\n",
        "            new_labels.append(label.numpy())\n",
        "          loss_pos = Criterion( logits,T.tensor(np.array(new_labels).reshape(-1,2)).type(T.float32).to(device))\n",
        "          loss_pos.backward()\n",
        "          running_loss += loss_pos.item()\n",
        "          Optimizer.step()\n",
        "\n",
        "          \n",
        "          \n",
        "        avg_train_loss = running_loss / batch_size\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}],Train Loss: {avg_train_loss} Time: {time.time() - start_time}')\n",
        "        \n",
        "    #print(\"Finished Training Saving Weights\") \n",
        "        T.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/vlmo.pth\")\n",
        " \n",
        "    return train_losses"
      ],
      "metadata": {
        "id": "E9c-ed9jvUjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main Method"
      ],
      "metadata": {
        "id": "tz3zs8gVvWvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = VLMo()\n",
        "\n",
        "# model = model.to(device)\n",
        "# pretrained_weight_path = \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/vlmo.pth\"\n",
        "# # if os.path.isfile(pretrained_weight_path):\n",
        "# #model.load_state_dict(T.load(pretrained_weight_path))\n",
        "# params = model.parameters()\n",
        "# loss = nn.MSELoss()#T.nn.functional.nll_loss#ContrastiveLoss()#\n",
        "# optimizer = T.optim.AdamW(params, lr=0.000001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "# train_VLMo(model,20,100,loss,optimizer)"
      ],
      "metadata": {
        "id": "gvJkd7P-vYvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer Reinforcement Learning"
      ],
      "metadata": {
        "id": "m0BTTRrr1K46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "8rlU0OMY1Quj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=8):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.scale = dim ** -0.5\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
        "        self.to_out = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x, mask = None):\n",
        "        b, n, _, h = *x.shape, self.heads\n",
        "        qkv = self.to_qkv(x)\n",
        "        q, k, v = rearrange(qkv, 'b n (qkv h d) -> qkv b h n d', qkv=3, h=h)\n",
        "\n",
        "        dots = T.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = F.pad(mask.flatten(1), (1, 0), value = True)\n",
        "            assert mask.shape[-1] == dots.shape[-1], 'mask has incorrect dimensions'\n",
        "            mask = mask[:, None, :] * mask[:, :, None]\n",
        "            dots.masked_fill_(~mask, float('-inf'))\n",
        "            del mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = T.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
        "        out =  self.to_out(out)\n",
        "        return out\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net_vision = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_language = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_common= nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim)\n",
        "        )\n",
        "        self.net_vision.apply(self.init_weights)\n",
        "        self.net_language.apply(self.init_weights)\n",
        "        self.net_common.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self,m):\n",
        "      if isinstance(m, nn.Linear):\n",
        "          T.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)\n",
        "    def forward(self, x,data_type=None):\n",
        "      if data_type == \"vision\":\n",
        "        return self.net_vision(x)\n",
        "      if data_type == \"language\":\n",
        "        return self.net_language(x)\n",
        "      if data_type == None:\n",
        "        return self.net_common(x)\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, dim, depth, heads, mlp_dim, norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        \n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleList([\n",
        "                Residual(PreNorm(dim, Attention(dim, heads))),\n",
        "                Residual(PreNorm(dim, FeedForward(dim, mlp_dim)))\n",
        "            ]))\n",
        "\n",
        "    def forward(self, x, mask=None,data_type=None):\n",
        "        for attn, ff in self.layers:\n",
        "            x = attn(x, mask=mask)\n",
        "            x = ff(x,data_type=data_type)\n",
        "        return x"
      ],
      "metadata": {
        "id": "EWTpqath1M6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VLMo(nn.Module):\n",
        "    \"\"\" VLMo \"\"\"\n",
        "    def __init__(self, image_size=224, patch_size=8,instruction_size = 4,instruction_dim =100, in_channels=1, num_classes=1, embed_dim=128, depth=4,\n",
        "                 heads=8, mlp_ratio=2, qkv_bias=False, qk_scale=None, norm_layer=nn.LayerNorm, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        #Vision patching\n",
        "        self.num_patches = 512\n",
        "        self.patch_dim = 7  * 7\n",
        "\n",
        "\n",
        "        self.pos_embedding_image = nn.Parameter(T.randn(1, self.num_patches + 1, embed_dim))\n",
        "        self.patch_to_embedding = nn.Linear(self.patch_dim, embed_dim)\n",
        "\n",
        "        #Using pre trained res net for image feature embedding\n",
        "        resnet18 = torchvision_models.resnet18(pretrained=True)\n",
        "        resnet18.conv1 = T.nn.Conv1d(1, 64, (7, 7), (2, 2), (3, 3), bias=False)\n",
        "        resnet18 = T.nn.Sequential(*(list(resnet18.children())[:-2]))\n",
        "        self.renet_layers = nn.Sequential(\n",
        "          \n",
        "          resnet18\n",
        "          )\n",
        "        for param in resnet18.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "        #Instruction Embedding\n",
        "        self.instruction_size = instruction_size\n",
        "        self.instruction_dim = instruction_dim\n",
        "        self.pos_embedding_instruction = nn.Parameter(T.randn(1, self.instruction_size + 1, embed_dim))\n",
        "        self.instruction_to_embedding = nn.Linear(self.instruction_dim, embed_dim)\n",
        "\n",
        "\n",
        "\n",
        "        #Common for vision and language\n",
        "        self.cls_token = nn.Parameter(T.randn(1, 1, embed_dim))\n",
        "        self.transformer = Transformer(embed_dim, depth, heads,embed_dim * mlp_ratio)\n",
        "        self.transformer_common = Transformer(embed_dim, depth, heads,embed_dim * mlp_ratio)\n",
        "        self.to_cls_token = nn.Identity()\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim * mlp_ratio),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(embed_dim * mlp_ratio, num_classes)\n",
        "        )\n",
        "        #.transformer.apply(self.init_weights)\n",
        "        self.mlp_head.apply(self.init_weights)\n",
        "\n",
        "    def init_weights(self,m):\n",
        "      if isinstance(m, nn.Linear):\n",
        "          T.nn.init.xavier_uniform_(m.weight)\n",
        "          m.bias.data.fill_(0.01)\n",
        "\n",
        "      \n",
        "\n",
        "    def forward(self, image,instruction, mask=None):\n",
        "        # Embedding Images\n",
        "        x_image = self.renet_layers(image).reshape(-1,self.num_patches,self.patch_dim )\n",
        "        x_image = self.patch_to_embedding(x_image)\n",
        "\n",
        "        cls_tokens = self.cls_token.expand(image.shape[0], -1, -1)\n",
        "\n",
        "        x_image = T.cat((cls_tokens, x_image), dim=1)\n",
        "        x_image += self.pos_embedding_image\n",
        "        x_image = self.transformer(x_image, mask,data_type=\"vision\")\n",
        "\n",
        "        # Embedding Instruction\n",
        "        #x_instruction = rearrange(image, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = self.patch_size, p2 = self.patch_size)\n",
        "        x_instruction = self.instruction_to_embedding(instruction)\n",
        "        cls_tokens = self.cls_token.expand(instruction.shape[0], -1, -1)\n",
        "\n",
        "        x_instruction = T.cat((cls_tokens,x_instruction ), dim=1)\n",
        "        x_instruction += self.pos_embedding_instruction\n",
        "        x_instruction = self.transformer(x_instruction, mask,data_type=\"language\")\n",
        "        #print(f\" image.shape {x_image.shape} instruction.shape {x_instruction.shape}\")\n",
        "\n",
        "        # Embedding Vision and Language\n",
        "        x_image_instruction = T.cat((x_image, x_instruction ), dim=1)\n",
        "        x_instruction = self.transformer_common(x_image_instruction, mask,data_type=None)\n",
        "        #x = self.to_cls_token(x[:, 0])\n",
        "        x = self.to_cls_token(x_instruction[:, 0])\n",
        "        return self.mlp_head(x)\n"
      ],
      "metadata": {
        "id": "Btq62S4_2LUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent"
      ],
      "metadata": {
        "id": "7Eo1h6_-1SoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent():\n",
        "    def __init__(self,model, state_dims=(1,224,224),instruction_dims=(4,100), batch_size=16, n_actions=4,\n",
        "                 max_mem_size=20000, eps_end=0.01, eps_dec=5e-4,update_target_network_frequency = 250, epsilon=0.01,gamma=0.8):\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_min = eps_end\n",
        "        self.eps_dec = eps_dec\n",
        "        self.action_space = [i for i in range(n_actions)]\n",
        "        self.mem_size = max_mem_size\n",
        "        self.batch_size = batch_size\n",
        "        self.mem_cntr = 0\n",
        "        self.iter_cntr = 0\n",
        "\n",
        "        self.Q_eval = model\n",
        "        self.target_network = copy.deepcopy(self.Q_eval)\n",
        "        self.update_target_network_frequency = update_target_network_frequency\n",
        "        self.state_memory = np.zeros((self.mem_size, *state_dims),\n",
        "                                     dtype=np.float32)\n",
        "        self.instruction_memory = np.zeros((self.mem_size, *instruction_dims),\n",
        "                                     dtype=np.float32)\n",
        "        self.new_state_memory = np.zeros((self.mem_size, *state_dims),\n",
        "                                         dtype=np.float32)\n",
        "        self.new_instruction_memory = np.zeros((self.mem_size, *instruction_dims),\n",
        "                                         dtype=np.float32)\n",
        "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
        "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
        "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
        "\n",
        "    def store_transition(self,state,instruction, action, reward,state_,instruction_, terminal):\n",
        "        index = self.mem_cntr % self.mem_size\n",
        "        self.state_memory[index] = state\n",
        "        self.instruction_memory[index] = instruction\n",
        "        self.new_state_memory[index] = state_\n",
        "        self.new_instruction_memory[index] = instruction_\n",
        "        self.reward_memory[index] = reward\n",
        "        self.action_memory[index] = action\n",
        "        self.terminal_memory[index] = terminal\n",
        "\n",
        "        self.mem_cntr += 1\n",
        "\n",
        "    def choose_action(self, state,instruction):\n",
        "        if np.random.random() > self.epsilon:\n",
        "            #state = T.tensor([observation]).to(device)\n",
        "            actions = self.Q_eval.forward(T.tensor([state], dtype=T.float32).to(device),T.tensor([instruction], dtype=T.float32).to(device))\n",
        "            action = T.argmax(actions).item()\n",
        "        else:\n",
        "            action = np.random.choice(self.action_space)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def learn(self,criterion,optimizer):\n",
        "        if self.mem_cntr < self.batch_size:\n",
        "            return\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        max_mem = min(self.mem_cntr, self.mem_size)\n",
        "\n",
        "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
        "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
        "\n",
        "        state_batch = T.tensor(self.state_memory[batch])\n",
        "        new_state_batch = T.tensor(\n",
        "                self.new_state_memory[batch])\n",
        "        instruction_batch = T.tensor(self.instruction_memory[batch])\n",
        "        new_instruction_batch = T.tensor(\n",
        "                self.new_instruction_memory[batch])\n",
        "        action_batch = self.action_memory[batch]\n",
        "        reward_batch = T.tensor(\n",
        "                self.reward_memory[batch])\n",
        "        terminal_batch = T.tensor(\n",
        "                self.terminal_memory[batch])\n",
        "        \n",
        "        q_eval = self.Q_eval.forward(state_batch.to(device),instruction_batch.to(device))[batch_index, action_batch]\n",
        "        q_next = self.target_network(new_state_batch.to(device),new_instruction_batch.to(device))\n",
        "        q_next[terminal_batch] = 0.0\n",
        "\n",
        "        q_target = reward_batch.to(device) + self.gamma*T.max(q_next, dim=1)[0]\n",
        "        #print(f\"q_target {q_target} q_eval {q_eval}\")\n",
        "        loss = criterion(q_target, q_eval)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if self.iter_cntr % self.update_target_network_frequency == 0:\n",
        "          self.target_network = copy.deepcopy(self.Q_eval)\n",
        "        self.iter_cntr += 1\n",
        "        self.epsilon = self.epsilon - self.eps_dec \\\n",
        "            if self.epsilon > self.eps_min else self.eps_min"
      ],
      "metadata": {
        "id": "O8Ub4sNX1U4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #Random agent driver code\n",
        "# env = CustomEnv()\n",
        "\n",
        "# while reward < 200:\n",
        "#   done = False\n",
        "#   observation = env.reset()\n",
        "#   while not done:\n",
        "#       observation = observation\n",
        "#       action = 0#np.random.choice([0,1,2,3])\n",
        "#       #print(f\"action {action}\")\n",
        "#       observation_, reward, done, info = env.step(action)\n",
        "#       env.render()\n",
        "#   print(\"Episode Done\")\n",
        "#   print(reward)"
      ],
      "metadata": {
        "id": "Ipw3fZ432EPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train One Epoch"
      ],
      "metadata": {
        "id": "hYM4pazL1VEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detach_cropped_area(im,img_width=224,img_height=224):\n",
        "        image = Image.fromarray(im)#.crop((0, 0, 130, 80))\n",
        "        newimage = image.resize((img_width,img_height))\n",
        "        scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        scaler.fit(newimage)\n",
        "        newimage = scaler.transform(newimage)\n",
        "        \n",
        "        return np.array(newimage).reshape(1,img_width,img_height)\n",
        "def tokenize_instruction(instruction):\n",
        "    tokenized_instruction = []\n",
        "    for word in instruction.split():\n",
        "      tokenized_instruction.append(embedding_glove[word.lower()].numpy())\n",
        "    return np.array(tokenized_instruction).reshape(len(instruction.split()),-1)\n",
        "\n",
        "def extract_state_instruction(observation):\n",
        "  state = detach_cropped_area(observation[0])\n",
        "  instruction = np.array(tokenize_instruction(observation[-1]))\n",
        "  return state,instruction\n",
        "def train_cust_env_agent(env,agent,model,episodes,criterion,optimizer):\n",
        "  scores, eps_history = [], []\n",
        "\n",
        "  for i in range(episodes):\n",
        "      score = 0\n",
        "      done = False\n",
        "      observation = env.reset()\n",
        "      time_per_episode = time.time()\n",
        "      while not done:\n",
        "          state,instruction = extract_state_instruction(observation)\n",
        "          action = agent.choose_action(state,instruction)\n",
        "          #print(f\"action {action}\")\n",
        "          observation_, reward, done, info = env.step(action)\n",
        "          state_,instruction_ = extract_state_instruction(observation_)\n",
        "          score += reward\n",
        "          agent.store_transition(state,instruction, action, reward,state_,instruction_, done)\n",
        "          agent.learn(criterion,optimizer)\n",
        "          observation = observation_\n",
        "          if (i + 1) % 1000 == 0:\n",
        "            \n",
        "            env.render()\n",
        "            print(f\"action {action} observation {observation[-1]} \")\n",
        "      scores.append(score)\n",
        "      eps_history.append(agent.epsilon)\n",
        "\n",
        "      avg_score = np.mean(scores[-100:])\n",
        "\n",
        "      print(f\"episode {i} score {score} average score {avg_score} epsilon {agent.epsilon} time {(time.time() - time_per_episode)} seconds\")\n",
        "      T.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/TransformerReinforcement2.pth\")\n",
        "\n",
        "  x = [i+1 for i in range(episodes)]\n",
        "  filename = 'ping_pong.png'\n",
        "  plotLearning(x, scores, eps_history, filename)"
      ],
      "metadata": {
        "id": "ZNrPsFBe1Xp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Method"
      ],
      "metadata": {
        "id": "QLrfvFHW1X_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# env = CustomEnv()\n",
        "# episodes_to_train = 2000\n",
        "# pretrained_weight_path = \"model-2fc.pt\"\n",
        "\n",
        "# model = VLMo(num_classes = 4)\n",
        "# model  = model.to(device)\n",
        "# # if os.path.isfile(pretrained_weight_path):\n",
        "# model.load_state_dict(T.load(\"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/TransformerReinforcement2.pth\"))\n",
        "# optimizer = T.optim.AdamW(model.parameters(), lr=0.00001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "# loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "#agent = Agent(model)\n",
        "# train_cust_env_agent(env,agent,model,episodes_to_train,criterion=loss,optimizer=optimizer)\n"
      ],
      "metadata": {
        "id": "AQQ77Ppd1aEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detach_cropped_area(im,img_width=224,img_height=224):\n",
        "        image = Image.fromarray(im)#.crop((0, 0, 130, 80))\n",
        "        newimage = image.resize((img_width,img_height))\n",
        "        scaler = MinMaxScaler(feature_range=(0,1))\n",
        "        scaler.fit(newimage)\n",
        "        newimage = scaler.transform(newimage)\n",
        "        \n",
        "        return np.array(newimage).reshape(1,img_width,img_height)\n",
        "def tokenize_instruction(instruction):\n",
        "    tokenized_instruction = []\n",
        "    for word in instruction.split():\n",
        "      tokenized_instruction.append(embedding_glove[word.lower()].numpy())\n",
        "    return np.array(tokenized_instruction).reshape(len(instruction.split()),-1)\n",
        "\n",
        "def extract_state_instruction(observation):\n",
        "  state = detach_cropped_area(observation[0])\n",
        "  instruction = np.array(tokenize_instruction(observation[-1]))\n",
        "  return state,instruction\n",
        "def train_cust_env_agent(env,agent,model,episodes):\n",
        "  scores, eps_history = [], []\n",
        "\n",
        "  for i in range(episodes):\n",
        "      score = 0\n",
        "      done = False\n",
        "      observation = env.reset()\n",
        "      time_per_episode = time.time()\n",
        "      while not done:\n",
        "          state,instruction = extract_state_instruction(observation)\n",
        "          action = agent.choose_action(state,instruction)\n",
        "          #print(f\"action {action}\")\n",
        "          observation_, reward, done, info = env.step(action)\n",
        "          #state_,instruction_ = extract_state_instruction(observation_)\n",
        "          score += reward\n",
        "          #agent.store_transition(state,instruction, action, reward,state_,instruction_, done)\n",
        "          #agent.learn(criterion,optimizer)\n",
        "          observation = observation_\n",
        "          #env.render()\n",
        "          #print(f\"action {action} observation {observation[-1]} \")\n",
        "      scores.append(score)\n",
        "      eps_history.append(agent.epsilon)\n",
        "\n",
        "      avg_score = np.mean(scores[-100:])\n",
        "\n",
        "      print(f\"episode {i} score {score} average score {avg_score} epsilon {agent.epsilon} time {(time.time() - time_per_episode)} seconds\")\n",
        "      #T.save(model.state_dict(), \"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/TransformerReinforcement.pth\")\n",
        "    \n",
        "  x = [i+1 for i in range(episodes)]\n",
        "  filename = 'ping_pong.png'\n",
        "  plotLearning(x, scores, eps_history, filename)\n",
        "\n",
        "env = CustomEnv()\n",
        "episodes_to_train = 1000\n",
        "pretrained_weight_path = \"model-2fc.pt\"\n",
        "\n",
        "model = VLMo(num_classes = 4)\n",
        "model  = model.to(device)\n",
        "# if os.path.isfile(pretrained_weight_path):\n",
        "model.load_state_dict(T.load(\"/content/drive/MyDrive/Final Project/siamese network/Pretrained Model/TransformerReinforcement2.pth\"))\n",
        "optimizer = T.optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "\n",
        "agent = Agent(model)\n",
        "train_cust_env_agent(env,agent,model,episodes_to_train)\n"
      ],
      "metadata": {
        "id": "I5DwFzoktfMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9064394d-60ff-4ca3-a4c2-95a12e0be7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 0 score 42.15000000000006 average score 42.15000000000006 epsilon 0.01 time 8.180439233779907 seconds\n",
            "episode 1 score 18.429999999999954 average score 30.290000000000006 epsilon 0.01 time 4.018376111984253 seconds\n",
            "episode 2 score 4.890000000000001 average score 21.823333333333338 epsilon 0.01 time 1.1036632061004639 seconds\n",
            "episode 3 score 0.6799999999999997 average score 16.5375 epsilon 0.01 time 0.8652572631835938 seconds\n",
            "episode 4 score 34.190000000000026 average score 20.068000000000005 epsilon 0.01 time 6.759080171585083 seconds\n",
            "episode 5 score 69.61999999999989 average score 28.326666666666654 epsilon 0.01 time 13.292750120162964 seconds\n",
            "episode 6 score 24.689999999999987 average score 27.807142857142846 epsilon 0.01 time 4.45244026184082 seconds\n",
            "episode 7 score 14.490000000000009 average score 26.142499999999988 epsilon 0.01 time 3.3132731914520264 seconds\n",
            "episode 8 score 20.419999999999945 average score 25.506666666666646 epsilon 0.01 time 4.357925176620483 seconds\n",
            "episode 9 score -1.31 average score 22.82499999999998 epsilon 0.01 time 0.5382699966430664 seconds\n",
            "episode 10 score 2.6500000000000066 average score 20.990909090909074 epsilon 0.01 time 1.2209887504577637 seconds\n",
            "episode 11 score 59.91000000000011 average score 24.234166666666663 epsilon 0.01 time 11.248355865478516 seconds\n",
            "episode 12 score 2.6400000000000063 average score 22.57307692307692 epsilon 0.01 time 1.274653434753418 seconds\n",
            "episode 13 score 46.33000000000001 average score 24.27 epsilon 0.01 time 8.433014869689941 seconds\n",
            "episode 14 score 24.34999999999994 average score 24.27533333333333 epsilon 0.01 time 5.119044303894043 seconds\n",
            "episode 15 score 65.70999999999994 average score 26.864999999999995 epsilon 0.01 time 12.53207802772522 seconds\n",
            "episode 16 score 46.100000000000065 average score 27.996470588235294 epsilon 0.01 time 8.834432601928711 seconds\n",
            "episode 17 score -1.31 average score 26.368333333333332 epsilon 0.01 time 0.5783224105834961 seconds\n",
            "episode 18 score 20.39999999999995 average score 26.05421052631579 epsilon 0.01 time 4.548758506774902 seconds\n",
            "episode 19 score 46.35000000000001 average score 27.069 epsilon 0.01 time 8.479067087173462 seconds\n",
            "episode 20 score 20.409999999999947 average score 26.75190476190476 epsilon 0.01 time 4.3502116203308105 seconds\n",
            "episode 21 score 6.600000000000008 average score 25.83590909090909 epsilon 0.01 time 1.884951114654541 seconds\n",
            "episode 22 score 6.870000000000002 average score 25.011304347826087 epsilon 0.01 time 1.4235742092132568 seconds\n",
            "episode 23 score 48.050000000000075 average score 25.971249999999998 epsilon 0.01 time 9.208820581436157 seconds\n",
            "episode 24 score 6.880000000000002 average score 25.2076 epsilon 0.01 time 1.4296090602874756 seconds\n",
            "episode 25 score 51.99000000000007 average score 26.23769230769231 epsilon 0.01 time 9.913308382034302 seconds\n",
            "episode 26 score 16.75 average score 25.886296296296297 epsilon 0.01 time 3.1143763065338135 seconds\n",
            "episode 27 score 18.449999999999953 average score 25.620714285714286 epsilon 0.01 time 4.00408411026001 seconds\n",
            "episode 28 score 32.50999999999998 average score 25.858275862068965 epsilon 0.01 time 5.976899862289429 seconds\n",
            "episode 29 score 174.2500000000006 average score 30.804666666666684 epsilon 0.01 time 31.52480459213257 seconds\n",
            "episode 30 score -1.03 average score 29.77774193548389 epsilon 0.01 time 0.07123947143554688 seconds\n",
            "episode 31 score 6.610000000000007 average score 29.053750000000015 epsilon 0.01 time 1.8876564502716064 seconds\n",
            "episode 32 score 2.6400000000000063 average score 28.253333333333348 epsilon 0.01 time 1.256683349609375 seconds\n",
            "episode 33 score 16.69 average score 27.913235294117662 epsilon 0.01 time 3.2224180698394775 seconds\n",
            "episode 34 score 22.409999999999943 average score 27.756000000000014 epsilon 0.01 time 4.6785197257995605 seconds\n",
            "episode 35 score 60.16000000000005 average score 28.656111111111127 epsilon 0.01 time 10.752954483032227 seconds\n",
            "episode 36 score 70.03 average score 29.77432432432434 epsilon 0.01 time 12.52347445487976 seconds\n",
            "episode 37 score 42.13000000000006 average score 30.099473684210544 epsilon 0.01 time 8.192087411880493 seconds\n",
            "episode 38 score 26.599999999999977 average score 30.009743589743604 epsilon 0.01 time 4.904781341552734 seconds\n",
            "episode 39 score 18.469999999999953 average score 29.721250000000015 epsilon 0.01 time 3.919768810272217 seconds\n",
            "episode 40 score 73.93999999999997 average score 30.79975609756099 epsilon 0.01 time 13.233878374099731 seconds\n",
            "episode 41 score 31.989999999999995 average score 30.828095238095255 epsilon 0.01 time 6.789126396179199 seconds\n",
            "episode 42 score 4.620000000000007 average score 30.21860465116281 epsilon 0.01 time 1.5297818183898926 seconds\n",
            "episode 43 score 10.800000000000002 average score 29.777272727272745 epsilon 0.01 time 2.1394832134246826 seconds\n",
            "episode 44 score 4.600000000000007 average score 29.21777777777779 epsilon 0.01 time 1.5763020515441895 seconds\n",
            "episode 45 score 6.850000000000001 average score 28.731521739130446 epsilon 0.01 time 1.44480562210083 seconds\n",
            "episode 46 score 59.76000000000013 average score 29.391702127659592 epsilon 0.01 time 11.403080224990845 seconds\n",
            "episode 47 score 0.95 average score 28.79916666666668 epsilon 0.01 time 0.3990058898925781 seconds\n",
            "episode 48 score 22.379999999999942 average score 28.66816326530613 epsilon 0.01 time 4.693921327590942 seconds\n",
            "episode 49 score 113.23999999999958 average score 30.3596 epsilon 0.01 time 20.556580543518066 seconds\n",
            "episode 50 score 6.650000000000007 average score 29.894705882352945 epsilon 0.01 time 1.8011212348937988 seconds\n",
            "episode 51 score 8.850000000000003 average score 29.490000000000002 epsilon 0.01 time 1.7717196941375732 seconds\n",
            "episode 52 score 2.6400000000000063 average score 28.983396226415095 epsilon 0.01 time 1.2468316555023193 seconds\n",
            "episode 53 score 52.220000000000034 average score 29.413703703703707 epsilon 0.01 time 9.57742190361023 seconds\n",
            "episode 54 score 42.06000000000005 average score 29.643636363636364 epsilon 0.01 time 8.74242115020752 seconds\n",
            "episode 55 score -1.31 average score 29.090892857142865 epsilon 0.01 time 0.6246612071990967 seconds\n",
            "episode 56 score 10.840000000000002 average score 28.77070175438597 epsilon 0.01 time 2.168652296066284 seconds\n",
            "episode 57 score 65.78999999999988 average score 29.408965517241384 epsilon 0.01 time 12.940390825271606 seconds\n",
            "episode 58 score 64.11000000000004 average score 29.997118644067804 epsilon 0.01 time 12.08558464050293 seconds\n",
            "episode 59 score 2.6500000000000066 average score 29.54133333333334 epsilon 0.01 time 1.354264497756958 seconds\n",
            "episode 60 score 50.03000000000007 average score 29.877213114754106 epsilon 0.01 time 10.022883892059326 seconds\n",
            "episode 61 score 38.18000000000006 average score 30.011129032258072 epsilon 0.01 time 7.83223295211792 seconds\n",
            "episode 62 score 30.54999999999997 average score 30.019682539682545 epsilon 0.01 time 5.897768020629883 seconds\n",
            "episode 63 score 48.070000000000064 average score 30.301718750000006 epsilon 0.01 time 9.594359636306763 seconds\n",
            "episode 64 score 12.800000000000004 average score 30.032461538461543 epsilon 0.01 time 2.5775980949401855 seconds\n",
            "episode 65 score 36.240000000000045 average score 30.126515151515157 epsilon 0.01 time 7.445003271102905 seconds\n",
            "episode 66 score 50.29000000000002 average score 30.427462686567168 epsilon 0.01 time 9.468857288360596 seconds\n",
            "episode 67 score 2.6500000000000066 average score 30.0189705882353 epsilon 0.01 time 1.320767879486084 seconds\n",
            "episode 68 score 34.250000000000036 average score 30.08028985507247 epsilon 0.01 time 7.076152563095093 seconds\n",
            "episode 69 score 34.26000000000003 average score 30.140000000000008 epsilon 0.01 time 7.084768772125244 seconds\n",
            "episode 70 score 12.520000000000008 average score 29.8918309859155 epsilon 0.01 time 3.1075797080993652 seconds\n",
            "episode 71 score 0.94 average score 29.48972222222223 epsilon 0.01 time 0.4529581069946289 seconds\n",
            "episode 72 score 69.74999999999986 average score 30.04123287671234 epsilon 0.01 time 13.513959646224976 seconds\n",
            "episode 73 score 40.49 average score 30.18243243243244 epsilon 0.01 time 7.502352237701416 seconds\n",
            "episode 74 score 4.920000000000001 average score 29.845600000000008 epsilon 0.01 time 1.0848584175109863 seconds\n",
            "episode 75 score 18.469999999999956 average score 29.695921052631583 epsilon 0.01 time 4.233984470367432 seconds\n",
            "episode 76 score 34.26000000000004 average score 29.75519480519481 epsilon 0.01 time 7.057893991470337 seconds\n",
            "episode 77 score 52.010000000000076 average score 30.04051282051283 epsilon 0.01 time 10.321054220199585 seconds\n",
            "episode 78 score 36.25000000000004 average score 30.11911392405064 epsilon 0.01 time 7.342309236526489 seconds\n",
            "episode 79 score 109.12999999999961 average score 31.106749999999998 epsilon 0.01 time 20.990062952041626 seconds\n",
            "episode 80 score 30.299999999999933 average score 31.096790123456785 epsilon 0.01 time 6.313267946243286 seconds\n",
            "episode 81 score 6.600000000000008 average score 30.7980487804878 epsilon 0.01 time 2.0354228019714355 seconds\n",
            "episode 82 score 28.319999999999936 average score 30.76819277108433 epsilon 0.01 time 5.988855600357056 seconds\n",
            "episode 83 score 38.17000000000004 average score 30.856309523809518 epsilon 0.01 time 7.9045090675354 seconds\n",
            "episode 84 score 2.9300000000000006 average score 30.527764705882344 epsilon 0.01 time 0.7796542644500732 seconds\n",
            "episode 85 score 4.630000000000007 average score 30.226627906976738 epsilon 0.01 time 1.6818790435791016 seconds\n",
            "episode 86 score 42.39000000000001 average score 30.366436781609185 epsilon 0.01 time 7.996174097061157 seconds\n",
            "episode 87 score 0.94 average score 30.03204545454545 epsilon 0.01 time 0.4724130630493164 seconds\n",
            "episode 88 score 2.9100000000000006 average score 29.72730337078651 epsilon 0.01 time 0.8423898220062256 seconds\n",
            "episode 89 score 71.78999999999985 average score 30.194666666666663 epsilon 0.01 time 13.886303901672363 seconds\n",
            "episode 90 score 32.30000000000003 average score 30.217802197802193 epsilon 0.01 time 6.653302907943726 seconds\n",
            "episode 91 score 4.630000000000007 average score 29.939673913043475 epsilon 0.01 time 1.651474952697754 seconds\n",
            "episode 92 score 83.7999999999999 average score 30.51881720430107 epsilon 0.01 time 15.826101064682007 seconds\n",
            "episode 93 score 12.53000000000001 average score 30.327446808510636 epsilon 0.01 time 3.11639142036438 seconds\n",
            "episode 94 score 20.39999999999995 average score 30.22294736842105 epsilon 0.01 time 4.570957660675049 seconds\n",
            "episode 95 score 0.95 average score 29.91802083333333 epsilon 0.01 time 0.4327864646911621 seconds\n",
            "episode 96 score 56.24000000000004 average score 30.189381443298966 epsilon 0.01 time 10.49252438545227 seconds\n",
            "episode 97 score 16.469999999999956 average score 30.04938775510204 epsilon 0.01 time 3.817246913909912 seconds\n",
            "episode 98 score 0.6699999999999997 average score 29.75262626262626 epsilon 0.01 time 0.9502463340759277 seconds\n",
            "episode 99 score 48.00000000000007 average score 29.9351 epsilon 0.01 time 9.783720254898071 seconds\n",
            "episode 100 score 2.6400000000000063 average score 29.539999999999996 epsilon 0.01 time 1.3200080394744873 seconds\n",
            "episode 101 score 22.369999999999944 average score 29.579399999999996 epsilon 0.01 time 4.983134031295776 seconds\n",
            "episode 102 score 42.13000000000006 average score 29.9518 epsilon 0.01 time 8.542011499404907 seconds\n",
            "episode 103 score 28.279999999999934 average score 30.22779999999999 epsilon 0.01 time 6.0520384311676025 seconds\n",
            "episode 104 score 38.15000000000005 average score 30.267399999999995 epsilon 0.01 time 7.873509883880615 seconds\n",
            "episode 105 score 215.89000000000092 average score 31.730100000000007 epsilon 0.01 time 40.094815731048584 seconds\n",
            "episode 106 score 99.40999999999966 average score 32.47730000000001 epsilon 0.01 time 18.842588186264038 seconds\n",
            "episode 107 score 34.26000000000004 average score 32.67500000000001 epsilon 0.01 time 7.023697376251221 seconds\n",
            "episode 108 score 6.610000000000007 average score 32.5369 epsilon 0.01 time 2.0028882026672363 seconds\n",
            "episode 109 score 42.120000000000054 average score 32.97120000000001 epsilon 0.01 time 8.533901453018188 seconds\n",
            "episode 110 score 22.389999999999944 average score 33.168600000000005 epsilon 0.01 time 4.913630962371826 seconds\n",
            "episode 111 score 67.81999999999987 average score 33.2477 epsilon 0.01 time 13.086854457855225 seconds\n",
            "episode 112 score 28.58999999999998 average score 33.5072 epsilon 0.01 time 5.437145709991455 seconds\n",
            "episode 113 score 58.19000000000004 average score 33.625800000000005 epsilon 0.01 time 10.863078832626343 seconds\n",
            "episode 114 score 63.87999999999991 average score 34.021100000000004 epsilon 0.01 time 12.4282386302948 seconds\n",
            "episode 115 score 28.329999999999934 average score 33.64730000000001 epsilon 0.01 time 5.945106744766235 seconds\n",
            "episode 116 score 30.56999999999997 average score 33.492000000000004 epsilon 0.01 time 5.818673133850098 seconds\n",
            "episode 117 score 10.820000000000004 average score 33.61330000000001 epsilon 0.01 time 2.211191177368164 seconds\n",
            "episode 118 score 38.43999999999999 average score 33.79370000000001 epsilon 0.01 time 7.27289080619812 seconds\n",
            "episode 119 score 2.6600000000000064 average score 33.35680000000001 epsilon 0.01 time 1.3125298023223877 seconds\n",
            "episode 120 score 6.610000000000007 average score 33.21880000000001 epsilon 0.01 time 2.0095667839050293 seconds\n",
            "episode 121 score 8.580000000000009 average score 33.238600000000005 epsilon 0.01 time 2.378538131713867 seconds\n",
            "episode 122 score 10.820000000000004 average score 33.2781 epsilon 0.01 time 2.226438283920288 seconds\n",
            "episode 123 score 32.21000000000002 average score 33.1197 epsilon 0.01 time 6.815971374511719 seconds\n",
            "episode 124 score 38.17000000000004 average score 33.43260000000001 epsilon 0.01 time 7.783177614212036 seconds\n",
            "episode 125 score 10.820000000000002 average score 33.020900000000005 epsilon 0.01 time 2.188020706176758 seconds\n",
            "episode 126 score 14.490000000000009 average score 32.99830000000001 epsilon 0.01 time 3.484365224838257 seconds\n",
            "episode 127 score 60.19000000000005 average score 33.4157 epsilon 0.01 time 11.132258415222168 seconds\n",
            "episode 128 score 26.299999999999933 average score 33.35360000000001 epsilon 0.01 time 5.718891143798828 seconds\n",
            "episode 129 score 4.620000000000007 average score 31.657299999999996 epsilon 0.01 time 1.653170108795166 seconds\n",
            "episode 130 score 59.8800000000001 average score 32.2664 epsilon 0.01 time 11.802331447601318 seconds\n",
            "episode 131 score 2.6500000000000066 average score 32.2268 epsilon 0.01 time 1.3067607879638672 seconds\n",
            "episode 132 score 73.70999999999985 average score 32.9375 epsilon 0.01 time 14.246261596679688 seconds\n",
            "episode 133 score 36.499999999999986 average score 33.1356 epsilon 0.01 time 6.8997650146484375 seconds\n",
            "episode 134 score 12.800000000000004 average score 33.039500000000004 epsilon 0.01 time 2.592076301574707 seconds\n",
            "episode 135 score 30.289999999999928 average score 32.7408 epsilon 0.01 time 6.425814628601074 seconds\n",
            "episode 136 score 18.71999999999999 average score 32.2277 epsilon 0.01 time 3.6334450244903564 seconds\n",
            "episode 137 score 14.50000000000001 average score 31.9514 epsilon 0.01 time 3.460026741027832 seconds\n",
            "episode 138 score 10.550000000000008 average score 31.790899999999997 epsilon 0.01 time 2.707714557647705 seconds\n",
            "episode 139 score 20.459999999999948 average score 31.810799999999993 epsilon 0.01 time 4.446881294250488 seconds\n",
            "episode 140 score -1.03 average score 31.061099999999996 epsilon 0.01 time 0.08047986030578613 seconds\n",
            "episode 141 score 2.6400000000000063 average score 30.767599999999995 epsilon 0.01 time 1.3360581398010254 seconds\n",
            "episode 142 score 67.84000000000002 average score 31.399799999999995 epsilon 0.01 time 13.064704656600952 seconds\n",
            "episode 143 score 56.240000000000045 average score 31.854199999999995 epsilon 0.01 time 10.467096090316772 seconds\n",
            "episode 144 score 57.9000000000001 average score 32.3872 epsilon 0.01 time 11.397799491882324 seconds\n",
            "episode 145 score 6.8900000000000015 average score 32.3876 epsilon 0.01 time 1.470360279083252 seconds\n",
            "episode 146 score 36.24000000000004 average score 32.1524 epsilon 0.01 time 7.42980694770813 seconds\n",
            "episode 147 score -1.03 average score 32.1326 epsilon 0.01 time 0.07961416244506836 seconds\n",
            "episode 148 score 12.550000000000008 average score 32.0343 epsilon 0.01 time 3.0231552124023438 seconds\n",
            "episode 149 score 20.699999999999992 average score 31.108900000000002 epsilon 0.01 time 4.0247719287872314 seconds\n",
            "episode 150 score 38.240000000000045 average score 31.424800000000005 epsilon 0.01 time 7.697976350784302 seconds\n",
            "episode 151 score 22.369999999999944 average score 31.560000000000006 epsilon 0.01 time 4.933281183242798 seconds\n",
            "episode 152 score -1.31 average score 31.520500000000002 epsilon 0.01 time 0.6096811294555664 seconds\n",
            "episode 153 score 46.37000000000002 average score 31.462000000000003 epsilon 0.01 time 8.676154851913452 seconds\n",
            "episode 154 score 36.21000000000004 average score 31.403499999999998 epsilon 0.01 time 7.3149027824401855 seconds\n",
            "episode 155 score 26.379999999999942 average score 31.680400000000006 epsilon 0.01 time 5.50615119934082 seconds\n",
            "episode 156 score 20.70999999999999 average score 31.779100000000003 epsilon 0.01 time 3.957836389541626 seconds\n",
            "episode 157 score 4.640000000000007 average score 31.167600000000004 epsilon 0.01 time 1.636937141418457 seconds\n",
            "episode 158 score 26.559999999999974 average score 30.7921 epsilon 0.01 time 5.174682855606079 seconds\n",
            "episode 159 score 18.709999999999994 average score 30.952700000000004 epsilon 0.01 time 3.679152488708496 seconds\n",
            "episode 160 score 105.34999999999964 average score 31.505899999999993 epsilon 0.01 time 19.957123517990112 seconds\n",
            "episode 161 score 22.639999999999986 average score 31.350499999999993 epsilon 0.01 time 4.387736082077026 seconds\n",
            "episode 162 score 18.589999999999975 average score 31.2309 epsilon 0.01 time 3.9033122062683105 seconds\n",
            "episode 163 score 38.23000000000005 average score 31.13249999999999 epsilon 0.01 time 7.705672740936279 seconds\n",
            "episode 164 score 32.41999999999999 average score 31.328699999999998 epsilon 0.01 time 6.365663290023804 seconds\n",
            "episode 165 score 8.580000000000009 average score 31.052099999999996 epsilon 0.01 time 2.3676021099090576 seconds\n",
            "episode 166 score 32.24000000000004 average score 30.871599999999997 epsilon 0.01 time 6.700711727142334 seconds\n",
            "episode 167 score 63.89999999999989 average score 31.484099999999998 epsilon 0.01 time 12.320149898529053 seconds\n",
            "episode 168 score 0.94 average score 31.150999999999996 epsilon 0.01 time 0.44397473335266113 seconds\n",
            "episode 169 score 6.600000000000008 average score 30.874399999999994 epsilon 0.01 time 2.012040615081787 seconds\n",
            "episode 170 score 18.729999999999993 average score 30.936499999999995 epsilon 0.01 time 3.6222379207611084 seconds\n",
            "episode 171 score 26.229999999999936 average score 31.189399999999992 epsilon 0.01 time 5.7860918045043945 seconds\n",
            "episode 172 score 34.27000000000004 average score 30.83459999999999 epsilon 0.01 time 6.937835931777954 seconds\n",
            "episode 173 score 14.490000000000009 average score 30.57459999999999 epsilon 0.01 time 3.4648005962371826 seconds\n",
            "episode 174 score 20.40999999999995 average score 30.729499999999987 epsilon 0.01 time 4.596804857254028 seconds\n",
            "episode 175 score 53.990000000000094 average score 31.084699999999998 epsilon 0.01 time 10.581738948822021 seconds\n",
            "episode 176 score 14.730000000000004 average score 30.889399999999995 epsilon 0.01 time 3.004830837249756 seconds\n",
            "episode 177 score 2.6400000000000063 average score 30.39569999999999 epsilon 0.01 time 1.320801019668579 seconds\n",
            "episode 178 score 14.51000000000001 average score 30.178299999999993 epsilon 0.01 time 3.438842535018921 seconds\n",
            "episode 179 score 83.65999999999977 average score 29.923599999999997 epsilon 0.01 time 15.839242219924927 seconds\n",
            "episode 180 score 44.339999999999996 average score 30.064 epsilon 0.01 time 8.410254955291748 seconds\n",
            "episode 181 score 12.750000000000005 average score 30.125500000000002 epsilon 0.01 time 2.6240735054016113 seconds\n",
            "episode 182 score -1.31 average score 29.8292 epsilon 0.01 time 0.6045761108398438 seconds\n",
            "episode 183 score 20.409999999999947 average score 29.6516 epsilon 0.01 time 4.543093204498291 seconds\n",
            "episode 184 score 53.950000000000095 average score 30.1618 epsilon 0.01 time 10.75674557685852 seconds\n",
            "episode 185 score 52.03000000000008 average score 30.635800000000003 epsilon 0.01 time 10.173494338989258 seconds\n",
            "episode 186 score 14.480000000000011 average score 30.3567 epsilon 0.01 time 3.4824345111846924 seconds\n",
            "episode 187 score 14.760000000000003 average score 30.4949 epsilon 0.01 time 2.930332899093628 seconds\n",
            "episode 188 score 22.649999999999988 average score 30.6923 epsilon 0.01 time 4.43243670463562 seconds\n",
            "episode 189 score 36.42999999999998 average score 30.338700000000003 epsilon 0.01 time 6.996614933013916 seconds\n",
            "episode 190 score 24.35999999999994 average score 30.259300000000003 epsilon 0.01 time 5.295063257217407 seconds\n",
            "episode 191 score 74.05999999999999 average score 30.953599999999998 epsilon 0.01 time 13.507746458053589 seconds\n",
            "episode 192 score 55.96000000000009 average score 30.6752 epsilon 0.01 time 11.014167070388794 seconds\n",
            "episode 193 score 8.580000000000009 average score 30.635699999999996 epsilon 0.01 time 2.347262382507324 seconds\n",
            "episode 194 score 0.6799999999999997 average score 30.438499999999994 epsilon 0.01 time 0.9391536712646484 seconds\n",
            "episode 195 score 87.86999999999989 average score 31.307699999999997 epsilon 0.01 time 16.076399087905884 seconds\n",
            "episode 196 score 18.439999999999955 average score 30.929699999999997 epsilon 0.01 time 4.169592618942261 seconds\n",
            "episode 197 score 10.56000000000001 average score 30.8706 epsilon 0.01 time 2.7036139965057373 seconds\n",
            "episode 198 score 18.459999999999958 average score 31.0485 epsilon 0.01 time 4.153277635574341 seconds\n",
            "episode 199 score 14.49000000000001 average score 30.7134 epsilon 0.01 time 3.454939126968384 seconds\n",
            "episode 200 score 14.50000000000001 average score 30.832000000000004 epsilon 0.01 time 3.4351840019226074 seconds\n",
            "episode 201 score 12.53000000000001 average score 30.733600000000006 epsilon 0.01 time 3.084946870803833 seconds\n",
            "episode 202 score 2.6500000000000066 average score 30.338800000000006 epsilon 0.01 time 1.2946326732635498 seconds\n",
            "episode 203 score 73.74999999999983 average score 30.793500000000005 epsilon 0.01 time 14.18970012664795 seconds\n",
            "episode 204 score 14.510000000000009 average score 30.557100000000005 epsilon 0.01 time 3.4569971561431885 seconds\n",
            "episode 205 score 44.100000000000065 average score 28.83919999999999 epsilon 0.01 time 8.820933103561401 seconds\n",
            "episode 206 score 24.369999999999937 average score 28.088799999999996 epsilon 0.01 time 5.248079061508179 seconds\n",
            "episode 207 score 40.410000000000004 average score 28.150299999999994 epsilon 0.01 time 7.646752119064331 seconds\n",
            "episode 208 score 20.18999999999995 average score 28.286099999999987 epsilon 0.01 time 4.9251673221588135 seconds\n",
            "episode 209 score 34.52999999999999 average score 28.210199999999997 epsilon 0.01 time 6.462047815322876 seconds\n",
            "episode 210 score 6.610000000000007 average score 28.05239999999999 epsilon 0.01 time 1.9891276359558105 seconds\n",
            "episode 211 score 129.01999999999992 average score 28.664399999999997 epsilon 0.01 time 24.23727536201477 seconds\n",
            "episode 212 score 4.640000000000007 average score 28.424899999999994 epsilon 0.01 time 1.6106617450714111 seconds\n",
            "episode 213 score 49.99000000000008 average score 28.342899999999997 epsilon 0.01 time 9.987375020980835 seconds\n",
            "episode 214 score 44.08000000000006 average score 28.14489999999999 epsilon 0.01 time 8.861352682113647 seconds\n",
            "episode 215 score 6.600000000000008 average score 27.927599999999995 epsilon 0.01 time 2.035651206970215 seconds\n",
            "episode 216 score 14.490000000000009 average score 27.766799999999993 epsilon 0.01 time 3.4823782444000244 seconds\n",
            "episode 217 score 22.389999999999947 average score 27.882499999999997 epsilon 0.01 time 4.904022693634033 seconds\n",
            "episode 218 score 40.42 average score 27.90229999999999 epsilon 0.01 time 7.566181659698486 seconds\n",
            "episode 219 score 42.17000000000005 average score 28.297399999999993 epsilon 0.01 time 8.372521877288818 seconds\n",
            "episode 220 score 14.51000000000001 average score 28.3764 epsilon 0.01 time 3.4001424312591553 seconds\n",
            "episode 221 score 2.920000000000001 average score 28.319799999999997 epsilon 0.01 time 0.800260066986084 seconds\n",
            "episode 222 score 67.99000000000001 average score 28.891499999999997 epsilon 0.01 time 12.750401020050049 seconds\n",
            "episode 223 score 28.32999999999994 average score 28.852699999999995 epsilon 0.01 time 5.887650012969971 seconds\n",
            "episode 224 score 18.699999999999996 average score 28.657999999999994 epsilon 0.01 time 3.7176668643951416 seconds\n",
            "episode 225 score 26.58999999999998 average score 28.81569999999999 epsilon 0.01 time 5.155307292938232 seconds\n",
            "episode 226 score 26.589999999999975 average score 28.93669999999999 epsilon 0.01 time 5.158061504364014 seconds\n",
            "episode 227 score 75.70999999999981 average score 29.09189999999999 epsilon 0.01 time 14.559595108032227 seconds\n",
            "episode 228 score 30.58999999999997 average score 29.134799999999995 epsilon 0.01 time 5.7142088413238525 seconds\n",
            "episode 229 score 6.600000000000008 average score 29.154599999999988 epsilon 0.01 time 2.042442560195923 seconds\n",
            "episode 230 score 28.28999999999993 average score 28.838699999999985 epsilon 0.01 time 6.030201196670532 seconds\n",
            "episode 231 score 111.17999999999975 average score 29.92399999999999 epsilon 0.01 time 20.993257522583008 seconds\n",
            "episode 232 score 14.800000000000004 average score 29.33489999999999 epsilon 0.01 time 2.8671212196350098 seconds\n",
            "episode 233 score 6.860000000000001 average score 29.03849999999999 epsilon 0.01 time 1.5382716655731201 seconds\n",
            "episode 234 score 12.54000000000001 average score 29.03589999999999 epsilon 0.01 time 3.048781633377075 seconds\n",
            "episode 235 score 22.369999999999944 average score 28.956699999999987 epsilon 0.01 time 4.9899742603302 seconds\n",
            "episode 236 score 26.64999999999998 average score 29.035999999999987 epsilon 0.01 time 5.017569065093994 seconds\n",
            "episode 237 score 8.830000000000002 average score 28.979299999999984 epsilon 0.01 time 1.9069466590881348 seconds\n",
            "episode 238 score 40.419999999999995 average score 29.277999999999988 epsilon 0.01 time 7.580706357955933 seconds\n",
            "episode 239 score 18.439999999999955 average score 29.25779999999999 epsilon 0.01 time 4.200222730636597 seconds\n",
            "episode 240 score 123.15999999999951 average score 30.49969999999998 epsilon 0.01 time 22.992738962173462 seconds\n",
            "episode 241 score -1.03 average score 30.46299999999998 epsilon 0.01 time 0.08239316940307617 seconds\n",
            "episode 242 score 16.709999999999997 average score 29.951699999999978 epsilon 0.01 time 3.345038652420044 seconds\n",
            "episode 243 score 71.77999999999984 average score 30.107099999999974 epsilon 0.01 time 13.818795204162598 seconds\n",
            "episode 244 score 22.409999999999947 average score 29.752199999999974 epsilon 0.01 time 4.82398533821106 seconds\n",
            "episode 245 score 105.55999999999976 average score 30.738899999999976 epsilon 0.01 time 19.47967839241028 seconds\n",
            "episode 246 score 20.40999999999995 average score 30.580599999999972 epsilon 0.01 time 4.559534549713135 seconds\n",
            "episode 247 score 60.08000000000007 average score 31.191699999999972 epsilon 0.01 time 11.463875532150269 seconds\n",
            "episode 248 score 97.7399999999998 average score 32.04359999999998 epsilon 0.01 time 17.821577072143555 seconds\n",
            "episode 249 score 14.780000000000003 average score 31.984399999999972 epsilon 0.01 time 2.8638689517974854 seconds\n",
            "episode 250 score 6.580000000000007 average score 31.66779999999997 epsilon 0.01 time 2.0960655212402344 seconds\n",
            "episode 251 score 2.920000000000001 average score 31.473299999999977 epsilon 0.01 time 0.7935295104980469 seconds\n",
            "episode 252 score 20.68999999999999 average score 31.693299999999972 epsilon 0.01 time 3.9976646900177 seconds\n",
            "episode 253 score 49.98000000000008 average score 31.729399999999973 epsilon 0.01 time 9.96188235282898 seconds\n",
            "episode 254 score 10.520000000000008 average score 31.47249999999997 epsilon 0.01 time 2.7608275413513184 seconds\n",
            "episode 255 score 4.6100000000000065 average score 31.254799999999978 epsilon 0.01 time 1.673506736755371 seconds\n",
            "episode 256 score 57.9700000000001 average score 31.627399999999977 epsilon 0.01 time 11.22495436668396 seconds\n",
            "episode 257 score 30.259999999999927 average score 31.883599999999973 epsilon 0.01 time 6.384591341018677 seconds\n",
            "episode 258 score 52.25000000000003 average score 32.140499999999975 epsilon 0.01 time 9.78568410873413 seconds\n",
            "episode 259 score 97.38999999999966 average score 32.927299999999974 epsilon 0.01 time 18.573312044143677 seconds\n",
            "episode 260 score 38.17000000000005 average score 32.25549999999998 epsilon 0.01 time 7.787789821624756 seconds\n",
            "episode 261 score 52.03000000000008 average score 32.54939999999998 epsilon 0.01 time 10.181859254837036 seconds\n",
            "episode 262 score 44.410000000000004 average score 32.80759999999997 epsilon 0.01 time 8.24852705001831 seconds\n",
            "episode 263 score 117.36999999999965 average score 33.59899999999997 epsilon 0.01 time 21.66776156425476 seconds\n",
            "episode 264 score 0.96 average score 33.28439999999997 epsilon 0.01 time 0.4076271057128906 seconds\n",
            "episode 265 score 16.69 average score 33.36549999999997 epsilon 0.01 time 3.3905580043792725 seconds\n",
            "episode 266 score 2.6500000000000066 average score 33.069599999999966 epsilon 0.01 time 1.3227307796478271 seconds\n",
            "episode 267 score 20.40999999999995 average score 32.634699999999974 epsilon 0.01 time 4.5429277420043945 seconds\n",
            "episode 268 score 93.4699999999997 average score 33.559999999999974 epsilon 0.01 time 17.750866174697876 seconds\n",
            "episode 269 score 111.19999999999956 average score 34.605999999999966 epsilon 0.01 time 21.08242177963257 seconds\n",
            "episode 270 score 85.82999999999988 average score 35.27699999999996 epsilon 0.01 time 15.881813049316406 seconds\n",
            "episode 271 score 36.15000000000005 average score 35.37619999999997 epsilon 0.01 time 7.544542074203491 seconds\n",
            "episode 272 score 65.8299999999999 average score 35.691799999999965 epsilon 0.01 time 12.746091842651367 seconds\n",
            "episode 273 score 22.399999999999945 average score 35.77089999999996 epsilon 0.01 time 4.87412166595459 seconds\n",
            "episode 274 score 69.79999999999987 average score 36.264799999999966 epsilon 0.01 time 13.499479293823242 seconds\n",
            "episode 275 score -1.31 average score 35.71179999999996 epsilon 0.01 time 0.5974137783050537 seconds\n",
            "episode 276 score 55.9300000000001 average score 36.12379999999997 epsilon 0.01 time 11.030095338821411 seconds\n",
            "episode 277 score 107.32999999999963 average score 37.170699999999954 epsilon 0.01 time 20.145446062088013 seconds\n",
            "episode 278 score 127.0199999999999 average score 38.29579999999996 epsilon 0.01 time 23.99835968017578 seconds\n",
            "episode 279 score 2.7900000000000036 average score 37.48709999999996 epsilon 0.01 time 1.0237407684326172 seconds\n",
            "episode 280 score 34.24000000000004 average score 37.38609999999996 epsilon 0.01 time 7.064360618591309 seconds\n",
            "episode 281 score 26.60999999999998 average score 37.52469999999996 epsilon 0.01 time 5.093982219696045 seconds\n",
            "episode 282 score 10.56000000000001 average score 37.64339999999996 epsilon 0.01 time 2.7012643814086914 seconds\n",
            "episode 283 score -1.31 average score 37.426199999999966 epsilon 0.01 time 0.6014604568481445 seconds\n",
            "episode 284 score 20.439999999999948 average score 37.09109999999996 epsilon 0.01 time 4.517274856567383 seconds\n",
            "episode 285 score 46.37000000000002 average score 37.03449999999996 epsilon 0.01 time 8.706242561340332 seconds\n",
            "episode 286 score 36.43 average score 37.253999999999955 epsilon 0.01 time 6.961339950561523 seconds\n",
            "episode 287 score 146.7600000000001 average score 38.57399999999996 epsilon 0.01 time 27.69130563735962 seconds\n",
            "episode 288 score 42.13000000000006 average score 38.76879999999996 epsilon 0.01 time 8.549897193908691 seconds\n",
            "episode 289 score 8.830000000000004 average score 38.49279999999997 epsilon 0.01 time 1.9096903800964355 seconds\n",
            "episode 290 score 40.150000000000055 average score 38.650699999999965 epsilon 0.01 time 8.196587562561035 seconds\n",
            "episode 291 score 46.350000000000016 average score 38.37359999999996 epsilon 0.01 time 8.778321266174316 seconds\n",
            "episode 292 score -1.31 average score 37.80089999999996 epsilon 0.01 time 0.615178108215332 seconds\n",
            "episode 293 score 14.500000000000009 average score 37.86009999999996 epsilon 0.01 time 3.445021152496338 seconds\n",
            "episode 294 score 0.95 average score 37.862799999999964 epsilon 0.01 time 0.43095970153808594 seconds\n",
            "episode 295 score 14.47000000000001 average score 37.128799999999956 epsilon 0.01 time 3.522700786590576 seconds\n",
            "episode 296 score 0.6799999999999997 average score 36.951199999999965 epsilon 0.01 time 0.9247181415557861 seconds\n",
            "episode 297 score 77.95999999999994 average score 37.62519999999996 epsilon 0.01 time 14.462667226791382 seconds\n",
            "episode 298 score 22.669999999999987 average score 37.66729999999996 epsilon 0.01 time 4.370341062545776 seconds\n",
            "episode 299 score 18.439999999999955 average score 37.706799999999966 epsilon 0.01 time 4.225938558578491 seconds\n",
            "episode 300 score 42.120000000000054 average score 37.98299999999997 epsilon 0.01 time 8.482218265533447 seconds\n",
            "episode 301 score 117.40999999999967 average score 39.03179999999996 epsilon 0.01 time 21.592687606811523 seconds\n",
            "episode 302 score -1.03 average score 38.99499999999996 epsilon 0.01 time 0.08983087539672852 seconds\n",
            "episode 303 score 50.02000000000008 average score 38.757699999999964 epsilon 0.01 time 10.011955976486206 seconds\n",
            "episode 304 score 67.85999999999987 average score 39.29119999999996 epsilon 0.01 time 13.028608083724976 seconds\n",
            "episode 305 score 24.36999999999994 average score 39.093899999999955 epsilon 0.01 time 5.275345087051392 seconds\n",
            "episode 306 score 174.6800000000002 average score 40.59699999999996 epsilon 0.01 time 32.038201332092285 seconds\n",
            "episode 307 score 26.59999999999998 average score 40.45889999999996 epsilon 0.01 time 5.105917930603027 seconds\n",
            "episode 308 score 32.23000000000003 average score 40.57929999999996 epsilon 0.01 time 6.781481981277466 seconds\n",
            "episode 309 score 46.08000000000007 average score 40.694799999999965 epsilon 0.01 time 9.257201194763184 seconds\n",
            "episode 310 score 105.2699999999996 average score 41.68139999999996 epsilon 0.01 time 20.098254442214966 seconds\n",
            "episode 311 score 91.77999999999984 average score 41.30899999999996 epsilon 0.01 time 17.03945255279541 seconds\n",
            "episode 312 score 48.34000000000002 average score 41.74599999999996 epsilon 0.01 time 9.067729234695435 seconds\n",
            "episode 313 score 0.95 average score 41.25559999999996 epsilon 0.01 time 0.4319193363189697 seconds\n",
            "episode 314 score 16.72 average score 40.98199999999995 epsilon 0.01 time 3.3521854877471924 seconds\n",
            "episode 315 score 8.860000000000003 average score 41.004599999999954 epsilon 0.01 time 1.845094919204712 seconds\n",
            "episode 316 score 10.820000000000004 average score 40.96789999999996 epsilon 0.01 time 2.23905086517334 seconds\n",
            "episode 317 score 32.24000000000003 average score 41.06639999999996 epsilon 0.01 time 6.801818370819092 seconds\n",
            "episode 318 score 20.419999999999952 average score 40.86639999999996 epsilon 0.01 time 4.5653204917907715 seconds\n",
            "episode 319 score 44.120000000000054 average score 40.885899999999964 epsilon 0.01 time 8.787957668304443 seconds\n",
            "episode 320 score 180.29000000000053 average score 42.54369999999997 epsilon 0.01 time 33.74422335624695 seconds\n",
            "episode 321 score 91.45999999999971 average score 43.42909999999996 epsilon 0.01 time 17.50894856452942 seconds\n",
            "episode 322 score 60.16000000000005 average score 43.350799999999964 epsilon 0.01 time 11.207542657852173 seconds\n",
            "episode 323 score 4.620000000000007 average score 43.113699999999966 epsilon 0.01 time 1.6763710975646973 seconds\n",
            "episode 324 score 36.52999999999999 average score 43.29199999999996 epsilon 0.01 time 6.802564859390259 seconds\n",
            "episode 325 score 79.92999999999992 average score 43.82539999999995 epsilon 0.01 time 14.85261082649231 seconds\n",
            "episode 326 score 30.259999999999927 average score 43.86209999999996 epsilon 0.01 time 6.408360719680786 seconds\n",
            "episode 327 score 75.65999999999983 average score 43.86159999999996 epsilon 0.01 time 14.669464826583862 seconds\n",
            "episode 328 score 8.840000000000002 average score 43.64409999999996 epsilon 0.01 time 1.8698832988739014 seconds\n",
            "episode 329 score 0.6799999999999997 average score 43.58489999999996 epsilon 0.01 time 0.9406204223632812 seconds\n",
            "episode 330 score 10.810000000000002 average score 43.41009999999997 epsilon 0.01 time 2.2104175090789795 seconds\n",
            "episode 331 score 32.28000000000003 average score 42.62109999999997 epsilon 0.01 time 6.625245809555054 seconds\n",
            "episode 332 score 8.840000000000002 average score 42.56149999999997 epsilon 0.01 time 1.8376574516296387 seconds\n",
            "episode 333 score 10.520000000000008 average score 42.59809999999997 epsilon 0.01 time 2.7453784942626953 seconds\n",
            "episode 334 score -1.03 average score 42.462399999999974 epsilon 0.01 time 0.08381199836730957 seconds\n",
            "episode 335 score 24.619999999999987 average score 42.48489999999998 epsilon 0.01 time 4.703725337982178 seconds\n",
            "episode 336 score 40.16000000000005 average score 42.619999999999976 epsilon 0.01 time 8.12290906906128 seconds\n",
            "episode 337 score 6.580000000000007 average score 42.59749999999996 epsilon 0.01 time 2.023885726928711 seconds\n",
            "episode 338 score 44.070000000000064 average score 42.63399999999996 epsilon 0.01 time 8.833300352096558 seconds\n",
            "episode 339 score 18.439999999999955 average score 42.63399999999995 epsilon 0.01 time 4.1370766162872314 seconds\n",
            "episode 340 score 36.20000000000004 average score 41.76439999999996 epsilon 0.01 time 7.387488603591919 seconds\n",
            "episode 341 score 81.63999999999977 average score 42.59109999999996 epsilon 0.01 time 15.554574728012085 seconds\n",
            "episode 342 score 160.85000000000008 average score 44.03249999999996 epsilon 0.01 time 29.40057110786438 seconds\n",
            "episode 343 score 36.160000000000025 average score 43.67629999999996 epsilon 0.01 time 7.431565284729004 seconds\n",
            "episode 344 score 10.54000000000001 average score 43.557599999999965 epsilon 0.01 time 2.759688138961792 seconds\n",
            "episode 345 score 38.49999999999999 average score 42.88699999999997 epsilon 0.01 time 7.149800062179565 seconds\n",
            "episode 346 score 38.46999999999999 average score 43.06759999999998 epsilon 0.01 time 7.510538816452026 seconds\n",
            "episode 347 score 12.800000000000004 average score 42.59479999999998 epsilon 0.01 time 2.6764259338378906 seconds\n",
            "episode 348 score 62.20000000000006 average score 42.239399999999975 epsilon 0.01 time 11.686442613601685 seconds\n",
            "episode 349 score 14.51000000000001 average score 42.23669999999997 epsilon 0.01 time 3.5740716457366943 seconds\n",
            "episode 350 score 34.51999999999998 average score 42.51609999999999 epsilon 0.01 time 6.666387557983398 seconds\n",
            "episode 351 score 77.92999999999994 average score 43.26619999999997 epsilon 0.01 time 14.398167133331299 seconds\n",
            "episode 352 score 14.770000000000003 average score 43.20699999999999 epsilon 0.01 time 2.944383144378662 seconds\n",
            "episode 353 score 50.010000000000076 average score 43.207299999999975 epsilon 0.01 time 10.03008246421814 seconds\n",
            "episode 354 score 24.39999999999994 average score 43.346099999999986 epsilon 0.01 time 5.1958043575286865 seconds\n",
            "episode 355 score 8.830000000000002 average score 43.38829999999998 epsilon 0.01 time 1.878598690032959 seconds\n",
            "episode 356 score 32.49999999999998 average score 43.13359999999997 epsilon 0.01 time 6.177266359329224 seconds\n",
            "episode 357 score 8.840000000000002 average score 42.919399999999975 epsilon 0.01 time 1.833951473236084 seconds\n",
            "episode 358 score 71.72999999999983 average score 43.114199999999975 epsilon 0.01 time 13.874183177947998 seconds\n",
            "episode 359 score 4.8900000000000015 average score 42.189199999999985 epsilon 0.01 time 1.143052101135254 seconds\n",
            "episode 360 score 20.68999999999999 average score 42.01439999999998 epsilon 0.01 time 4.106468677520752 seconds\n",
            "episode 361 score 48.310000000000024 average score 41.97719999999998 epsilon 0.01 time 9.048428773880005 seconds\n",
            "episode 362 score 4.640000000000007 average score 41.57949999999998 epsilon 0.01 time 1.621675729751587 seconds\n",
            "episode 363 score -1.03 average score 40.39549999999998 epsilon 0.01 time 0.07834339141845703 seconds\n",
            "episode 364 score 22.379999999999946 average score 40.60969999999997 epsilon 0.01 time 5.129534959793091 seconds\n",
            "episode 365 score 2.6500000000000066 average score 40.469299999999976 epsilon 0.01 time 1.2826275825500488 seconds\n",
            "episode 366 score 10.820000000000002 average score 40.55099999999998 epsilon 0.01 time 2.257155418395996 seconds\n",
            "episode 367 score 34.51999999999998 average score 40.69209999999998 epsilon 0.01 time 6.638461351394653 seconds\n",
            "episode 368 score 28.309999999999935 average score 40.04049999999998 epsilon 0.01 time 6.292724847793579 seconds\n",
            "episode 369 score 36.47999999999999 average score 39.29329999999999 epsilon 0.01 time 7.150480508804321 seconds\n",
            "episode 370 score 34.23000000000004 average score 38.77729999999999 epsilon 0.01 time 7.414830923080444 seconds\n",
            "episode 371 score 4.8900000000000015 average score 38.46469999999998 epsilon 0.01 time 1.2237951755523682 seconds\n",
            "episode 372 score 2.920000000000001 average score 37.83559999999998 epsilon 0.01 time 0.8280541896820068 seconds\n",
            "episode 373 score 34.25000000000003 average score 37.95409999999998 epsilon 0.01 time 7.40752911567688 seconds\n",
            "episode 374 score 14.790000000000003 average score 37.40399999999998 epsilon 0.01 time 2.9825985431671143 seconds\n",
            "episode 375 score 47.930000000000085 average score 37.896399999999986 epsilon 0.01 time 9.824370622634888 seconds\n",
            "episode 376 score 55.99000000000009 average score 37.896999999999984 epsilon 0.01 time 10.88974928855896 seconds\n",
            "episode 377 score 26.659999999999986 average score 37.09029999999999 epsilon 0.01 time 4.9932098388671875 seconds\n",
            "episode 378 score 26.359999999999935 average score 36.08369999999999 epsilon 0.01 time 5.64578104019165 seconds\n",
            "episode 379 score 0.6799999999999997 average score 36.06259999999999 epsilon 0.01 time 0.9232175350189209 seconds\n",
            "episode 380 score 40.41 average score 36.124299999999984 epsilon 0.01 time 7.652251243591309 seconds\n",
            "episode 381 score 50.06000000000008 average score 36.358799999999995 epsilon 0.01 time 9.830070734024048 seconds\n",
            "episode 382 score 24.379999999999942 average score 36.49699999999999 epsilon 0.01 time 5.203656196594238 seconds\n",
            "episode 383 score 12.520000000000008 average score 36.63529999999999 epsilon 0.01 time 3.1058921813964844 seconds\n",
            "episode 384 score 22.389999999999947 average score 36.654799999999994 epsilon 0.01 time 4.849513053894043 seconds\n",
            "episode 385 score 20.439999999999948 average score 36.3955 epsilon 0.01 time 4.481903553009033 seconds\n",
            "episode 386 score 10.820000000000002 average score 36.139399999999995 epsilon 0.01 time 2.211538791656494 seconds\n",
            "episode 387 score 64.12000000000003 average score 35.312999999999995 epsilon 0.01 time 11.907241582870483 seconds\n",
            "episode 388 score 20.40999999999995 average score 35.09579999999999 epsilon 0.01 time 4.6002278327941895 seconds\n",
            "episode 389 score 55.85000000000008 average score 35.56599999999999 epsilon 0.01 time 11.177974462509155 seconds\n",
            "episode 390 score 36.48999999999999 average score 35.52939999999998 epsilon 0.01 time 6.899823188781738 seconds\n",
            "episode 391 score 22.399999999999945 average score 35.28989999999999 epsilon 0.01 time 4.945332050323486 seconds\n",
            "episode 392 score 10.810000000000004 average score 35.41109999999998 epsilon 0.01 time 2.278400182723999 seconds\n",
            "episode 393 score 115.13999999999956 average score 36.41749999999998 epsilon 0.01 time 22.211782932281494 seconds\n",
            "episode 394 score -1.31 average score 36.394899999999986 epsilon 0.01 time 0.6180169582366943 seconds\n",
            "episode 395 score 34.19000000000003 average score 36.59209999999998 epsilon 0.01 time 7.384445428848267 seconds\n",
            "episode 396 score 6.860000000000002 average score 36.65389999999998 epsilon 0.01 time 1.5943779945373535 seconds\n",
            "episode 397 score 10.810000000000002 average score 35.98239999999999 epsilon 0.01 time 2.322659969329834 seconds\n",
            "episode 398 score 154.70000000000022 average score 37.30269999999999 epsilon 0.01 time 28.728277683258057 seconds\n",
            "episode 399 score 0.6699999999999997 average score 37.124999999999986 epsilon 0.01 time 0.9319586753845215 seconds\n",
            "episode 400 score 51.93000000000008 average score 37.22309999999999 epsilon 0.01 time 10.444725275039673 seconds\n",
            "episode 401 score 75.98999999999997 average score 36.80889999999999 epsilon 0.01 time 14.054570198059082 seconds\n",
            "episode 402 score 18.709999999999997 average score 37.00629999999999 epsilon 0.01 time 3.674639940261841 seconds\n",
            "episode 403 score 75.70999999999982 average score 37.26319999999999 epsilon 0.01 time 14.484663963317871 seconds\n",
            "episode 404 score 16.439999999999955 average score 36.74899999999999 epsilon 0.01 time 3.8942408561706543 seconds\n",
            "episode 405 score -1.03 average score 36.49499999999999 epsilon 0.01 time 0.07852578163146973 seconds\n",
            "episode 406 score 8.840000000000002 average score 34.83659999999999 epsilon 0.01 time 1.8631153106689453 seconds\n",
            "episode 407 score 38.170000000000044 average score 34.95229999999999 epsilon 0.01 time 7.753684043884277 seconds\n",
            "episode 408 score 63.89999999999989 average score 35.268999999999984 epsilon 0.01 time 12.322725296020508 seconds\n",
            "episode 409 score 12.53000000000001 average score 34.933499999999995 epsilon 0.01 time 3.0735058784484863 seconds\n",
            "episode 410 score 28.509999999999973 average score 34.16589999999999 epsilon 0.01 time 5.582589626312256 seconds\n",
            "episode 411 score 40.17000000000005 average score 33.64979999999999 epsilon 0.01 time 8.096882820129395 seconds\n",
            "episode 412 score 4.890000000000001 average score 33.21529999999999 epsilon 0.01 time 1.1635849475860596 seconds\n",
            "episode 413 score 24.38999999999994 average score 33.449699999999986 epsilon 0.01 time 5.236971139907837 seconds\n",
            "episode 414 score 24.39999999999994 average score 33.52649999999999 epsilon 0.01 time 5.11506986618042 seconds\n",
            "episode 415 score 14.510000000000009 average score 33.58299999999999 epsilon 0.01 time 3.4132096767425537 seconds\n",
            "episode 416 score 113.50999999999969 average score 34.609899999999996 epsilon 0.01 time 20.75579857826233 seconds\n",
            "episode 417 score 28.339999999999932 average score 34.570899999999995 epsilon 0.01 time 5.878992319107056 seconds\n",
            "episode 418 score 22.699999999999992 average score 34.59369999999999 epsilon 0.01 time 4.276677370071411 seconds\n",
            "episode 419 score 26.319999999999933 average score 34.41569999999999 epsilon 0.01 time 5.651433944702148 seconds\n",
            "episode 420 score 16.449999999999957 average score 32.777299999999975 epsilon 0.01 time 3.8374276161193848 seconds\n",
            "episode 421 score 2.6600000000000064 average score 31.88929999999998 epsilon 0.01 time 1.268730878829956 seconds\n",
            "episode 422 score 59.8500000000001 average score 31.886199999999977 epsilon 0.01 time 11.826826333999634 seconds\n",
            "episode 423 score 46.30000000000001 average score 32.30299999999998 epsilon 0.01 time 8.758797883987427 seconds\n",
            "episode 424 score 67.79999999999988 average score 32.615699999999975 epsilon 0.01 time 13.091147422790527 seconds\n",
            "episode 425 score -1.03 average score 31.806099999999983 epsilon 0.01 time 0.07953667640686035 seconds\n",
            "episode 426 score -1.03 average score 31.493199999999984 epsilon 0.01 time 0.08072543144226074 seconds\n",
            "episode 427 score 18.439999999999955 average score 30.920999999999985 epsilon 0.01 time 4.238201379776001 seconds\n",
            "episode 428 score 67.78999999999988 average score 31.51049999999999 epsilon 0.01 time 13.061999320983887 seconds\n",
            "episode 429 score 77.62999999999981 average score 32.27999999999999 epsilon 0.01 time 14.919935703277588 seconds\n",
            "episode 430 score 20.679999999999986 average score 32.37869999999999 epsilon 0.01 time 4.0459747314453125 seconds\n",
            "episode 431 score 46.12000000000007 average score 32.517099999999985 epsilon 0.01 time 9.067872047424316 seconds\n",
            "episode 432 score 2.920000000000001 average score 32.45789999999998 epsilon 0.01 time 0.7641327381134033 seconds\n",
            "episode 433 score 10.540000000000008 average score 32.45809999999998 epsilon 0.01 time 2.719683885574341 seconds\n",
            "episode 434 score 22.389999999999947 average score 32.69229999999998 epsilon 0.01 time 4.894198417663574 seconds\n",
            "episode 435 score 57.9200000000001 average score 33.02529999999999 epsilon 0.01 time 11.34191107749939 seconds\n",
            "episode 436 score 14.480000000000011 average score 32.76849999999999 epsilon 0.01 time 3.480156898498535 seconds\n",
            "episode 437 score 95.33999999999968 average score 33.65609999999998 epsilon 0.01 time 18.23072099685669 seconds\n",
            "episode 438 score 10.820000000000004 average score 33.323599999999985 epsilon 0.01 time 2.1942248344421387 seconds\n",
            "episode 439 score 6.870000000000002 average score 33.20789999999999 epsilon 0.01 time 1.5054786205291748 seconds\n",
            "episode 440 score 22.39999999999994 average score 33.06989999999998 epsilon 0.01 time 4.866900444030762 seconds\n",
            "episode 441 score 26.579999999999977 average score 32.51929999999999 epsilon 0.01 time 5.1183226108551025 seconds\n",
            "episode 442 score 20.39999999999995 average score 31.11479999999998 epsilon 0.01 time 4.540736198425293 seconds\n",
            "episode 443 score 42.17000000000006 average score 31.174899999999983 epsilon 0.01 time 8.338381290435791 seconds\n",
            "episode 444 score 2.6500000000000066 average score 31.095999999999982 epsilon 0.01 time 1.287123680114746 seconds\n",
            "episode 445 score -1.17 average score 30.699299999999983 epsilon 0.01 time 0.3171384334564209 seconds\n",
            "episode 446 score 61.84000000000012 average score 30.932999999999982 epsilon 0.01 time 12.004106998443604 seconds\n",
            "episode 447 score -1.31 average score 30.791899999999988 epsilon 0.01 time 0.5924978256225586 seconds\n",
            "episode 448 score 6.600000000000008 average score 30.235899999999983 epsilon 0.01 time 2.0126030445098877 seconds\n",
            "episode 449 score 81.6799999999998 average score 30.90759999999998 epsilon 0.01 time 15.502585172653198 seconds\n",
            "episode 450 score -1.31 average score 30.549299999999985 epsilon 0.01 time 0.5899395942687988 seconds\n",
            "episode 451 score 2.6600000000000064 average score 29.796599999999984 epsilon 0.01 time 1.2635202407836914 seconds\n",
            "episode 452 score 42.13000000000007 average score 30.070199999999986 epsilon 0.01 time 8.44127893447876 seconds\n",
            "episode 453 score 113.44999999999969 average score 30.704599999999978 epsilon 0.01 time 20.85295295715332 seconds\n",
            "episode 454 score 10.55000000000001 average score 30.566099999999977 epsilon 0.01 time 2.707648515701294 seconds\n",
            "episode 455 score 10.540000000000008 average score 30.583199999999984 epsilon 0.01 time 2.7442069053649902 seconds\n",
            "episode 456 score 20.41999999999995 average score 30.46239999999998 epsilon 0.01 time 4.517431259155273 seconds\n",
            "episode 457 score 12.51000000000001 average score 30.499099999999984 epsilon 0.01 time 3.0666897296905518 seconds\n",
            "episode 458 score 16.449999999999957 average score 29.946299999999983 epsilon 0.01 time 3.831380844116211 seconds\n",
            "episode 459 score 58.22000000000004 average score 30.479599999999987 epsilon 0.01 time 10.73683786392212 seconds\n",
            "episode 460 score 50.090000000000074 average score 30.773599999999984 epsilon 0.01 time 9.798203945159912 seconds\n",
            "episode 461 score 36.489999999999995 average score 30.655399999999982 epsilon 0.01 time 6.861443758010864 seconds\n",
            "episode 462 score 16.469999999999956 average score 30.77369999999998 epsilon 0.01 time 3.8183658123016357 seconds\n",
            "episode 463 score 91.44999999999972 average score 31.69849999999998 epsilon 0.01 time 17.47769546508789 seconds\n",
            "episode 464 score 4.620000000000007 average score 31.520899999999973 epsilon 0.01 time 1.633474349975586 seconds\n",
            "episode 465 score 6.880000000000002 average score 31.563199999999984 epsilon 0.01 time 1.4720337390899658 seconds\n",
            "episode 466 score -1.04 average score 31.444599999999983 epsilon 0.01 time 0.09905600547790527 seconds\n",
            "episode 467 score 67.82999999999988 average score 31.77769999999998 epsilon 0.01 time 13.13966989517212 seconds\n",
            "episode 468 score 18.419999999999952 average score 31.67879999999998 epsilon 0.01 time 4.199814558029175 seconds\n",
            "episode 469 score 10.540000000000008 average score 31.41939999999998 epsilon 0.01 time 2.722233533859253 seconds\n",
            "episode 470 score 75.70999999999982 average score 31.83419999999998 epsilon 0.01 time 14.481416940689087 seconds\n",
            "episode 471 score 18.459999999999955 average score 31.96989999999998 epsilon 0.01 time 4.138803243637085 seconds\n",
            "episode 472 score 6.870000000000002 average score 32.00939999999998 epsilon 0.01 time 1.5024619102478027 seconds\n",
            "episode 473 score 101.36999999999966 average score 32.68059999999998 epsilon 0.01 time 19.178517818450928 seconds\n",
            "episode 474 score 56.01000000000009 average score 33.09279999999998 epsilon 0.01 time 10.81092643737793 seconds\n",
            "episode 475 score 10.530000000000008 average score 32.718799999999966 epsilon 0.01 time 2.777270555496216 seconds\n",
            "episode 476 score 44.360000000000014 average score 32.60249999999997 epsilon 0.01 time 8.322361707687378 seconds\n",
            "episode 477 score 16.479999999999958 average score 32.50069999999997 epsilon 0.01 time 3.831947088241577 seconds\n",
            "episode 478 score 40.300000000000026 average score 32.64009999999998 epsilon 0.01 time 7.796465873718262 seconds\n",
            "episode 479 score 12.760000000000003 average score 32.76089999999997 epsilon 0.01 time 2.609940767288208 seconds\n",
            "episode 480 score 10.530000000000008 average score 32.46209999999998 epsilon 0.01 time 2.7828705310821533 seconds\n",
            "episode 481 score 43.890000000000086 average score 32.40039999999997 epsilon 0.01 time 9.21781611442566 seconds\n",
            "episode 482 score 10.48000000000001 average score 32.26139999999997 epsilon 0.01 time 2.787653923034668 seconds\n",
            "episode 483 score 8.590000000000007 average score 32.222099999999976 epsilon 0.01 time 2.340041399002075 seconds\n",
            "episode 484 score 255.2000000000013 average score 34.55019999999999 epsilon 0.01 time 47.261467933654785 seconds\n",
            "episode 485 score 18.719999999999995 average score 34.53299999999999 epsilon 0.01 time 3.6328892707824707 seconds\n",
            "episode 486 score 4.640000000000007 average score 34.47119999999998 epsilon 0.01 time 1.5925638675689697 seconds\n",
            "episode 487 score 4.630000000000007 average score 33.876299999999986 epsilon 0.01 time 1.6105315685272217 seconds\n",
            "episode 488 score 65.8299999999999 average score 34.33049999999999 epsilon 0.01 time 12.674718856811523 seconds\n",
            "episode 489 score 0.6699999999999997 average score 33.778699999999986 epsilon 0.01 time 0.9387586116790771 seconds\n",
            "episode 490 score 36.21000000000004 average score 33.775899999999986 epsilon 0.01 time 7.3969337940216064 seconds\n",
            "episode 491 score 8.600000000000009 average score 33.63789999999999 epsilon 0.01 time 2.279777765274048 seconds\n",
            "episode 492 score 20.699999999999992 average score 33.73679999999998 epsilon 0.01 time 4.003092527389526 seconds\n",
            "episode 493 score 36.18000000000004 average score 32.94719999999998 epsilon 0.01 time 7.451707124710083 seconds\n",
            "episode 494 score 14.47000000000001 average score 33.10499999999999 epsilon 0.01 time 3.500962495803833 seconds\n",
            "episode 495 score 0.6799999999999997 average score 32.769899999999986 epsilon 0.01 time 0.905526876449585 seconds\n",
            "episode 496 score 71.70999999999985 average score 33.418399999999984 epsilon 0.01 time 13.917765140533447 seconds\n",
            "episode 497 score 16.41999999999996 average score 33.47449999999999 epsilon 0.01 time 3.8144075870513916 seconds\n",
            "episode 498 score 119.35999999999966 average score 33.121099999999984 epsilon 0.01 time 21.851058959960938 seconds\n",
            "episode 499 score -1.03 average score 33.10409999999999 epsilon 0.01 time 0.08471560478210449 seconds\n",
            "episode 500 score 36.16000000000004 average score 32.94639999999998 epsilon 0.01 time 7.41681170463562 seconds\n",
            "episode 501 score 0.6699999999999997 average score 32.19319999999998 epsilon 0.01 time 0.9220812320709229 seconds\n",
            "episode 502 score 0.6799999999999997 average score 32.01289999999998 epsilon 0.01 time 0.9105522632598877 seconds\n",
            "episode 503 score 26.619999999999983 average score 31.521999999999984 epsilon 0.01 time 5.045792102813721 seconds\n",
            "episode 504 score 20.39999999999995 average score 31.561599999999988 epsilon 0.01 time 4.565666437149048 seconds\n",
            "episode 505 score 40.17000000000006 average score 31.973599999999987 epsilon 0.01 time 8.069947004318237 seconds\n",
            "episode 506 score 26.62999999999998 average score 32.15149999999999 epsilon 0.01 time 4.984375238418579 seconds\n",
            "episode 507 score 48.340000000000025 average score 32.25319999999999 epsilon 0.01 time 8.985328912734985 seconds\n",
            "episode 508 score 26.349999999999937 average score 31.87769999999999 epsilon 0.01 time 5.558936834335327 seconds\n",
            "episode 509 score 46.06000000000007 average score 32.21299999999999 epsilon 0.01 time 9.194241046905518 seconds\n",
            "episode 510 score 42.10000000000005 average score 32.348899999999986 epsilon 0.01 time 8.415836572647095 seconds\n",
            "episode 511 score 0.94 average score 31.956599999999984 epsilon 0.01 time 0.4389193058013916 seconds\n",
            "episode 512 score 81.81999999999992 average score 32.72589999999998 epsilon 0.01 time 15.231449365615845 seconds\n",
            "episode 513 score 8.840000000000002 average score 32.570399999999985 epsilon 0.01 time 1.8715465068817139 seconds\n",
            "episode 514 score 10.530000000000008 average score 32.43169999999999 epsilon 0.01 time 2.76884126663208 seconds\n",
            "episode 515 score 6.580000000000007 average score 32.35239999999999 epsilon 0.01 time 2.0196244716644287 seconds\n",
            "episode 516 score 2.8900000000000015 average score 31.246199999999995 epsilon 0.01 time 0.8539669513702393 seconds\n",
            "episode 517 score 4.630000000000007 average score 31.00909999999999 epsilon 0.01 time 1.6424705982208252 seconds\n",
            "episode 518 score 32.270000000000024 average score 31.10479999999999 epsilon 0.01 time 6.653059720993042 seconds\n",
            "episode 519 score 87.15999999999958 average score 31.713199999999983 epsilon 0.01 time 17.44932723045349 seconds\n",
            "episode 520 score 6.610000000000007 average score 31.614799999999992 epsilon 0.01 time 1.9846961498260498 seconds\n",
            "episode 521 score 55.92000000000009 average score 32.14739999999999 epsilon 0.01 time 11.084055423736572 seconds\n",
            "episode 522 score 6.850000000000001 average score 31.617399999999986 epsilon 0.01 time 1.545548439025879 seconds\n",
            "episode 523 score 54.23000000000003 average score 31.696699999999986 epsilon 0.01 time 10.112290859222412 seconds\n",
            "episode 524 score 91.55999999999975 average score 31.93429999999999 epsilon 0.01 time 17.192404985427856 seconds\n",
            "episode 525 score 8.580000000000007 average score 32.030399999999986 epsilon 0.01 time 2.3588101863861084 seconds\n",
            "episode 526 score 38.21000000000004 average score 32.42279999999999 epsilon 0.01 time 7.704608201980591 seconds\n",
            "episode 527 score 28.299999999999937 average score 32.521399999999986 epsilon 0.01 time 6.000141859054565 seconds\n",
            "episode 528 score 16.499999999999957 average score 32.008499999999984 epsilon 0.01 time 3.7214488983154297 seconds\n",
            "episode 529 score -1.31 average score 31.21909999999999 epsilon 0.01 time 0.5894691944122314 seconds\n",
            "episode 530 score 24.36999999999994 average score 31.255999999999986 epsilon 0.01 time 5.1988561153411865 seconds\n",
            "episode 531 score 44.410000000000004 average score 31.238899999999987 epsilon 0.01 time 8.249142408370972 seconds\n",
            "episode 532 score 12.510000000000009 average score 31.334799999999987 epsilon 0.01 time 3.084824562072754 seconds\n",
            "episode 533 score 55.93000000000009 average score 31.78869999999999 epsilon 0.01 time 10.97016453742981 seconds\n",
            "episode 534 score 32.260000000000026 average score 31.887399999999992 epsilon 0.01 time 6.610322713851929 seconds\n",
            "episode 535 score 52.04000000000008 average score 31.828599999999998 epsilon 0.01 time 10.146740198135376 seconds\n",
            "episode 536 score 65.78999999999989 average score 32.34169999999999 epsilon 0.01 time 12.82558298110962 seconds\n",
            "episode 537 score 4.900000000000001 average score 31.43729999999999 epsilon 0.01 time 1.1275155544281006 seconds\n",
            "episode 538 score 2.9300000000000006 average score 31.35839999999999 epsilon 0.01 time 0.7680087089538574 seconds\n",
            "episode 539 score 8.560000000000008 average score 31.375299999999992 epsilon 0.01 time 2.3789422512054443 seconds\n",
            "episode 540 score 44.100000000000065 average score 31.592299999999987 epsilon 0.01 time 8.9068443775177 seconds\n",
            "episode 541 score 52.30000000000003 average score 31.84949999999999 epsilon 0.01 time 9.820120573043823 seconds\n",
            "episode 542 score 8.830000000000002 average score 31.73379999999999 epsilon 0.01 time 1.905050277709961 seconds\n",
            "episode 543 score 42.14000000000005 average score 31.733499999999985 epsilon 0.01 time 8.414714813232422 seconds\n",
            "episode 544 score 30.319999999999933 average score 32.01019999999999 epsilon 0.01 time 6.290245294570923 seconds\n",
            "episode 545 score 69.98999999999998 average score 32.72179999999999 epsilon 0.01 time 13.071534872055054 seconds\n",
            "episode 546 score 22.669999999999987 average score 32.33009999999999 epsilon 0.01 time 4.327912330627441 seconds\n",
            "episode 547 score 42.110000000000056 average score 32.764299999999984 epsilon 0.01 time 8.474774837493896 seconds\n",
            "episode 548 score 61.8800000000001 average score 33.31709999999999 epsilon 0.01 time 12.06249189376831 seconds\n",
            "episode 549 score 20.42999999999995 average score 32.70459999999999 epsilon 0.01 time 4.525181293487549 seconds\n",
            "episode 550 score -1.03 average score 32.70739999999999 epsilon 0.01 time 0.07733011245727539 seconds\n",
            "episode 551 score 6.610000000000007 average score 32.74689999999999 epsilon 0.01 time 1.983156681060791 seconds\n",
            "episode 552 score 12.520000000000008 average score 32.45079999999999 epsilon 0.01 time 3.0411458015441895 seconds\n",
            "episode 553 score 8.56000000000001 average score 31.40189999999999 epsilon 0.01 time 2.394101142883301 seconds\n",
            "episode 554 score 40.449999999999996 average score 31.700899999999997 epsilon 0.01 time 7.545506715774536 seconds\n",
            "episode 555 score 12.52000000000001 average score 31.720699999999994 epsilon 0.01 time 3.1203343868255615 seconds\n",
            "episode 556 score 0.94 average score 31.525899999999996 epsilon 0.01 time 0.44519686698913574 seconds\n",
            "episode 557 score 0.94 average score 31.410199999999996 epsilon 0.01 time 0.4502525329589844 seconds\n",
            "episode 558 score 62.070000000000064 average score 31.8664 epsilon 0.01 time 11.806729555130005 seconds\n",
            "episode 559 score 10.57000000000001 average score 31.389899999999997 epsilon 0.01 time 2.683584213256836 seconds\n",
            "episode 560 score 6.590000000000008 average score 30.954900000000002 epsilon 0.01 time 2.0275261402130127 seconds\n",
            "episode 561 score 59.87000000000011 average score 31.188699999999997 epsilon 0.01 time 11.693955183029175 seconds\n",
            "episode 562 score 0.6699999999999997 average score 31.030700000000003 epsilon 0.01 time 0.9203479290008545 seconds\n",
            "episode 563 score 2.6400000000000063 average score 30.1426 epsilon 0.01 time 1.3148143291473389 seconds\n",
            "episode 564 score 8.550000000000008 average score 30.1819 epsilon 0.01 time 2.3871891498565674 seconds\n",
            "episode 565 score 50.03000000000008 average score 30.613400000000002 epsilon 0.01 time 9.854599237442017 seconds\n",
            "episode 566 score 0.6799999999999997 average score 30.6306 epsilon 0.01 time 0.9025700092315674 seconds\n",
            "episode 567 score 128.9099999999999 average score 31.241400000000002 epsilon 0.01 time 24.166790008544922 seconds\n",
            "episode 568 score 4.890000000000001 average score 31.1061 epsilon 0.01 time 1.1515185832977295 seconds\n",
            "episode 569 score 46.06000000000007 average score 31.461299999999998 epsilon 0.01 time 9.193259239196777 seconds\n",
            "episode 570 score 2.6600000000000064 average score 30.7308 epsilon 0.01 time 1.250652551651001 seconds\n",
            "episode 571 score 28.559999999999977 average score 30.831799999999998 epsilon 0.01 time 5.456333875656128 seconds\n",
            "episode 572 score 38.200000000000045 average score 31.145100000000003 epsilon 0.01 time 7.6677775382995605 seconds\n",
            "episode 573 score 14.490000000000009 average score 30.276300000000003 epsilon 0.01 time 3.466492176055908 seconds\n",
            "episode 574 score 34.26000000000004 average score 30.05880000000001 epsilon 0.01 time 7.00972843170166 seconds\n",
            "episode 575 score 55.960000000000086 average score 30.513100000000005 epsilon 0.01 time 10.878464221954346 seconds\n",
            "episode 576 score 28.299999999999933 average score 30.352500000000006 epsilon 0.01 time 5.943772077560425 seconds\n",
            "episode 577 score 4.8900000000000015 average score 30.236600000000006 epsilon 0.01 time 1.153325080871582 seconds\n",
            "episode 578 score 32.539999999999985 average score 30.159000000000006 epsilon 0.01 time 6.110360860824585 seconds\n",
            "episode 579 score 44.36000000000002 average score 30.475000000000005 epsilon 0.01 time 8.334686994552612 seconds\n",
            "episode 580 score 16.469999999999956 average score 30.534400000000005 epsilon 0.01 time 3.77828311920166 seconds\n",
            "episode 581 score 103.66999999999979 average score 31.1322 epsilon 0.01 time 18.859938859939575 seconds\n",
            "episode 582 score 46.34000000000002 average score 31.490800000000004 epsilon 0.01 time 8.66369080543518 seconds\n",
            "episode 583 score 105.29999999999961 average score 32.4579 epsilon 0.01 time 19.972021102905273 seconds\n",
            "episode 584 score 18.429999999999954 average score 30.090199999999992 epsilon 0.01 time 4.264699220657349 seconds\n",
            "episode 585 score 26.639999999999983 average score 30.169399999999992 epsilon 0.01 time 5.20627498626709 seconds\n",
            "episode 586 score 26.59999999999998 average score 30.38899999999999 epsilon 0.01 time 5.251673221588135 seconds\n",
            "episode 587 score 8.580000000000009 average score 30.428499999999985 epsilon 0.01 time 2.471151351928711 seconds\n",
            "episode 588 score 70.03 average score 30.470499999999987 epsilon 0.01 time 13.52299189567566 seconds\n",
            "episode 589 score 4.780000000000004 average score 30.511599999999994 epsilon 0.01 time 1.417466163635254 seconds\n",
            "episode 590 score 66.10000000000002 average score 30.810499999999987 epsilon 0.01 time 12.435026407241821 seconds\n",
            "episode 591 score 22.399999999999945 average score 30.948499999999996 epsilon 0.01 time 4.873525142669678 seconds\n",
            "episode 592 score 20.65999999999999 average score 30.94809999999999 epsilon 0.01 time 4.154766082763672 seconds\n",
            "episode 593 score 61.8800000000001 average score 31.205099999999995 epsilon 0.01 time 12.119046449661255 seconds\n",
            "episode 594 score 4.890000000000001 average score 31.10929999999999 epsilon 0.01 time 1.1584155559539795 seconds\n",
            "episode 595 score 14.44000000000001 average score 31.246899999999986 epsilon 0.01 time 3.551454544067383 seconds\n",
            "episode 596 score -1.03 average score 30.51949999999999 epsilon 0.01 time 0.08266043663024902 seconds\n",
            "episode 597 score 0.6699999999999997 average score 30.361999999999995 epsilon 0.01 time 0.940279483795166 seconds\n",
            "episode 598 score 2.920000000000001 average score 29.197599999999998 epsilon 0.01 time 0.7942862510681152 seconds\n",
            "episode 599 score 10.540000000000008 average score 29.313299999999995 epsilon 0.01 time 2.7377352714538574 seconds\n",
            "episode 600 score 30.549999999999972 average score 29.2572 epsilon 0.01 time 5.845219612121582 seconds\n",
            "episode 601 score 6.610000000000007 average score 29.316599999999998 epsilon 0.01 time 2.019277811050415 seconds\n",
            "episode 602 score 10.540000000000008 average score 29.4152 epsilon 0.01 time 2.7154862880706787 seconds\n",
            "episode 603 score -1.05 average score 29.1385 epsilon 0.01 time 0.0987555980682373 seconds\n",
            "episode 604 score 12.530000000000008 average score 29.0598 epsilon 0.01 time 3.067267656326294 seconds\n",
            "episode 605 score 10.540000000000008 average score 28.763499999999993 epsilon 0.01 time 2.7535955905914307 seconds\n",
            "episode 606 score 8.860000000000001 average score 28.5858 epsilon 0.01 time 1.8282947540283203 seconds\n",
            "episode 607 score -1.31 average score 28.089299999999998 epsilon 0.01 time 0.6197183132171631 seconds\n",
            "episode 608 score 8.590000000000007 average score 27.9117 epsilon 0.01 time 2.3140740394592285 seconds\n",
            "episode 609 score 2.6500000000000066 average score 27.477600000000002 epsilon 0.01 time 1.2779879570007324 seconds\n",
            "episode 610 score 34.250000000000036 average score 27.399099999999997 epsilon 0.01 time 6.959768772125244 seconds\n",
            "episode 611 score 24.639999999999986 average score 27.636099999999995 epsilon 0.01 time 4.680806398391724 seconds\n",
            "episode 612 score 10.550000000000008 average score 26.923399999999997 epsilon 0.01 time 2.7023537158966064 seconds\n",
            "episode 613 score 2.6400000000000063 average score 26.8614 epsilon 0.01 time 1.2910940647125244 seconds\n",
            "episode 614 score 0.94 average score 26.765499999999996 epsilon 0.01 time 0.44218873977661133 seconds\n",
            "episode 615 score 85.47999999999976 average score 27.554499999999997 epsilon 0.01 time 16.5618314743042 seconds\n",
            "episode 616 score 24.37999999999994 average score 27.76939999999999 epsilon 0.01 time 5.21996808052063 seconds\n",
            "episode 617 score 4.9 average score 27.772100000000002 epsilon 0.01 time 1.1410181522369385 seconds\n",
            "episode 618 score 22.399999999999945 average score 27.673399999999997 epsilon 0.01 time 4.836163282394409 seconds\n",
            "episode 619 score 6.860000000000001 average score 26.870400000000004 epsilon 0.01 time 1.5031030178070068 seconds\n",
            "episode 620 score 83.86999999999992 average score 27.642999999999997 epsilon 0.01 time 15.40779447555542 seconds\n",
            "episode 621 score -1.31 average score 27.070700000000002 epsilon 0.01 time 0.596961498260498 seconds\n",
            "episode 622 score 30.319999999999933 average score 27.305399999999995 epsilon 0.01 time 6.173130035400391 seconds\n",
            "episode 623 score 34.26000000000003 average score 27.1057 epsilon 0.01 time 6.936630487442017 seconds\n",
            "episode 624 score 24.63999999999998 average score 26.436499999999995 epsilon 0.01 time 4.771114349365234 seconds\n",
            "episode 625 score 24.589999999999982 average score 26.596599999999995 epsilon 0.01 time 4.776297569274902 seconds\n",
            "episode 626 score 48.07000000000007 average score 26.6952 epsilon 0.01 time 9.49735689163208 seconds\n",
            "episode 627 score 22.639999999999986 average score 26.638599999999993 epsilon 0.01 time 4.394720077514648 seconds\n",
            "episode 628 score 24.359999999999943 average score 26.7172 epsilon 0.01 time 5.21214747428894 seconds\n",
            "episode 629 score 30.28999999999993 average score 27.033199999999994 epsilon 0.01 time 6.3485188484191895 seconds\n",
            "episode 630 score -1.31 average score 26.7764 epsilon 0.01 time 0.6075775623321533 seconds\n",
            "episode 631 score 0.6799999999999997 average score 26.339099999999995 epsilon 0.01 time 0.9182548522949219 seconds\n",
            "episode 632 score 30.259999999999927 average score 26.516599999999993 epsilon 0.01 time 6.357500076293945 seconds\n",
            "episode 633 score 26.349999999999937 average score 26.220799999999986 epsilon 0.01 time 5.526453256607056 seconds\n",
            "episode 634 score -1.28 average score 25.885399999999983 epsilon 0.01 time 0.5173640251159668 seconds\n",
            "episode 635 score 14.50000000000001 average score 25.509999999999987 epsilon 0.01 time 3.40858793258667 seconds\n",
            "episode 636 score 0.95 average score 24.86159999999999 epsilon 0.01 time 0.4251077175140381 seconds\n",
            "episode 637 score 6.580000000000007 average score 24.87839999999999 epsilon 0.01 time 2.0369975566864014 seconds\n",
            "episode 638 score 52.24000000000002 average score 25.37149999999999 epsilon 0.01 time 9.82071042060852 seconds\n",
            "episode 639 score 32.50999999999997 average score 25.61099999999999 epsilon 0.01 time 6.194939136505127 seconds\n",
            "episode 640 score 0.95 average score 25.17949999999999 epsilon 0.01 time 0.4123528003692627 seconds\n",
            "episode 641 score 2.6500000000000066 average score 24.682999999999993 epsilon 0.01 time 1.2890410423278809 seconds\n",
            "episode 642 score 34.50999999999998 average score 24.939799999999988 epsilon 0.01 time 6.442834377288818 seconds\n",
            "episode 643 score 2.810000000000003 average score 24.54649999999999 epsilon 0.01 time 0.9786543846130371 seconds\n",
            "episode 644 score 42.16000000000006 average score 24.66489999999999 epsilon 0.01 time 8.304030656814575 seconds\n",
            "episode 645 score 2.6500000000000066 average score 23.99149999999999 epsilon 0.01 time 1.2709898948669434 seconds\n",
            "episode 646 score 46.120000000000054 average score 24.22599999999999 epsilon 0.01 time 9.025917291641235 seconds\n",
            "episode 647 score 0.6799999999999997 average score 23.81169999999999 epsilon 0.01 time 0.8943641185760498 seconds\n",
            "episode 648 score 22.349999999999945 average score 23.41639999999999 epsilon 0.01 time 4.88411283493042 seconds\n",
            "episode 649 score 2.6400000000000063 average score 23.23849999999999 epsilon 0.01 time 1.28859281539917 seconds\n",
            "episode 650 score 129.2599999999997 average score 24.541399999999985 epsilon 0.01 time 23.653913497924805 seconds\n",
            "episode 651 score 12.520000000000008 average score 24.60049999999999 epsilon 0.01 time 3.047041416168213 seconds\n",
            "episode 652 score 12.50000000000001 average score 24.60029999999999 epsilon 0.01 time 3.1028707027435303 seconds\n",
            "episode 653 score 2.6600000000000064 average score 24.54129999999999 epsilon 0.01 time 1.267808437347412 seconds\n",
            "episode 654 score 136.95000000000005 average score 25.506299999999992 epsilon 0.01 time 25.334872245788574 seconds\n",
            "episode 655 score 12.520000000000008 average score 25.50629999999999 epsilon 0.01 time 3.051793336868286 seconds\n",
            "episode 656 score 12.510000000000009 average score 25.621999999999993 epsilon 0.01 time 3.052976131439209 seconds\n",
            "episode 657 score -1.31 average score 25.59949999999999 epsilon 0.01 time 0.5723271369934082 seconds\n",
            "episode 658 score 89.3799999999997 average score 25.872599999999988 epsilon 0.01 time 17.154105186462402 seconds\n",
            "episode 659 score -1.03 average score 25.756599999999985 epsilon 0.01 time 0.07695460319519043 seconds\n",
            "episode 660 score 2.6400000000000063 average score 25.71709999999998 epsilon 0.01 time 1.3022630214691162 seconds\n",
            "episode 661 score 26.59999999999998 average score 25.384399999999978 epsilon 0.01 time 5.0847508907318115 seconds\n",
            "episode 662 score 32.53999999999998 average score 25.70309999999998 epsilon 0.01 time 6.108195781707764 seconds\n",
            "episode 663 score 16.7 average score 25.84369999999998 epsilon 0.01 time 3.3235678672790527 seconds\n",
            "episode 664 score 2.6400000000000063 average score 25.784599999999976 epsilon 0.01 time 1.2973077297210693 seconds\n",
            "episode 665 score 30.599999999999977 average score 25.590299999999978 epsilon 0.01 time 5.730839014053345 seconds\n",
            "episode 666 score 30.319999999999933 average score 25.886699999999976 epsilon 0.01 time 6.204491853713989 seconds\n",
            "episode 667 score 16.72 average score 24.764799999999976 epsilon 0.01 time 3.2995057106018066 seconds\n",
            "episode 668 score 40.190000000000055 average score 25.117799999999978 epsilon 0.01 time 7.946789264678955 seconds\n",
            "episode 669 score 79.65999999999978 average score 25.45379999999998 epsilon 0.01 time 15.10050892829895 seconds\n",
            "episode 670 score 28.309999999999935 average score 25.71029999999998 epsilon 0.01 time 5.908056259155273 seconds\n",
            "episode 671 score 0.6799999999999997 average score 25.431499999999982 epsilon 0.01 time 0.9006545543670654 seconds\n",
            "episode 672 score 119.15999999999956 average score 26.241099999999975 epsilon 0.01 time 22.170698404312134 seconds\n",
            "episode 673 score 16.44999999999996 average score 26.260699999999975 epsilon 0.01 time 3.7289223670959473 seconds\n",
            "episode 674 score 81.60999999999979 average score 26.734199999999966 epsilon 0.01 time 15.365144968032837 seconds\n",
            "episode 675 score 70.07000000000001 average score 26.87529999999997 epsilon 0.01 time 12.75418734550476 seconds\n",
            "episode 676 score 0.6699999999999997 average score 26.598999999999975 epsilon 0.01 time 0.8999884128570557 seconds\n",
            "episode 677 score 50.030000000000086 average score 27.05039999999998 epsilon 0.01 time 9.74602484703064 seconds\n",
            "episode 678 score 30.299999999999926 average score 27.027999999999974 epsilon 0.01 time 6.17877721786499 seconds\n",
            "episode 679 score 54.01000000000008 average score 27.124499999999976 epsilon 0.01 time 10.496390104293823 seconds\n",
            "episode 680 score 32.389999999999986 average score 27.283699999999975 epsilon 0.01 time 6.543431520462036 seconds\n",
            "episode 681 score 111.50999999999972 average score 27.362099999999973 epsilon 0.01 time 21.164570569992065 seconds\n",
            "episode 682 score 28.299999999999933 average score 27.181699999999967 epsilon 0.01 time 6.185710906982422 seconds\n",
            "episode 683 score 55.9600000000001 average score 26.688299999999977 epsilon 0.01 time 10.924513578414917 seconds\n",
            "episode 684 score 64.14000000000006 average score 27.145399999999977 epsilon 0.01 time 11.83687138557434 seconds\n",
            "episode 685 score 30.569999999999972 average score 27.184699999999978 epsilon 0.01 time 5.7836387157440186 seconds\n",
            "episode 686 score 0.6799999999999997 average score 26.92549999999998 epsilon 0.01 time 0.9022111892700195 seconds\n",
            "episode 687 score 129.01999999999995 average score 28.129899999999978 epsilon 0.01 time 23.802358627319336 seconds\n",
            "episode 688 score 12.520000000000008 average score 27.55479999999998 epsilon 0.01 time 3.0779600143432617 seconds\n",
            "episode 689 score 26.44999999999998 average score 27.771499999999975 epsilon 0.01 time 5.296693801879883 seconds\n",
            "episode 690 score 14.750000000000004 average score 27.257999999999974 epsilon 0.01 time 2.9611270427703857 seconds\n",
            "episode 691 score 0.94 average score 27.043399999999973 epsilon 0.01 time 0.446765661239624 seconds\n",
            "episode 692 score 10.830000000000004 average score 26.94509999999998 epsilon 0.01 time 2.1931746006011963 seconds\n",
            "episode 693 score 57.930000000000106 average score 26.905599999999982 epsilon 0.01 time 11.242636680603027 seconds\n",
            "episode 694 score 8.640000000000008 average score 26.943099999999976 epsilon 0.01 time 2.2325291633605957 seconds\n",
            "episode 695 score 18.469999999999953 average score 26.983399999999975 epsilon 0.01 time 4.10845160484314 seconds\n",
            "episode 696 score 42.20000000000005 average score 27.41569999999998 epsilon 0.01 time 8.16743540763855 seconds\n",
            "episode 697 score 6.590000000000008 average score 27.47489999999998 epsilon 0.01 time 1.9718549251556396 seconds\n",
            "episode 698 score 57.96000000000009 average score 28.02529999999998 epsilon 0.01 time 11.07353162765503 seconds\n",
            "episode 699 score 24.36999999999994 average score 28.163599999999978 epsilon 0.01 time 5.147419691085815 seconds\n",
            "episode 700 score 8.580000000000009 average score 27.943899999999974 epsilon 0.01 time 2.3676095008850098 seconds\n",
            "episode 701 score 10.830000000000004 average score 27.986099999999976 epsilon 0.01 time 2.1982734203338623 seconds\n",
            "episode 702 score 50.090000000000074 average score 28.38159999999998 epsilon 0.01 time 9.684004783630371 seconds\n",
            "episode 703 score 109.31999999999961 average score 29.485299999999974 epsilon 0.01 time 20.764952659606934 seconds\n",
            "episode 704 score 6.8900000000000015 average score 29.428899999999977 epsilon 0.01 time 1.4665474891662598 seconds\n",
            "episode 705 score 65.70999999999987 average score 29.98059999999997 epsilon 0.01 time 13.06208062171936 seconds\n",
            "episode 706 score 34.54999999999998 average score 30.237499999999976 epsilon 0.01 time 6.40919828414917 seconds\n",
            "episode 707 score -1.31 average score 30.237499999999972 epsilon 0.01 time 0.5648205280303955 seconds\n",
            "episode 708 score 10.800000000000004 average score 30.259599999999978 epsilon 0.01 time 2.2321789264678955 seconds\n",
            "episode 709 score 54.000000000000085 average score 30.773099999999978 epsilon 0.01 time 10.43743634223938 seconds\n",
            "episode 710 score 22.649999999999984 average score 30.65709999999997 epsilon 0.01 time 4.360265731811523 seconds\n",
            "episode 711 score 0.6699999999999997 average score 30.417399999999976 epsilon 0.01 time 0.926415205001831 seconds\n",
            "episode 712 score 30.53999999999997 average score 30.61729999999997 epsilon 0.01 time 5.765424013137817 seconds\n",
            "episode 713 score -1.31 average score 30.577799999999975 epsilon 0.01 time 0.5797584056854248 seconds\n",
            "episode 714 score 36.469999999999985 average score 30.933099999999968 epsilon 0.01 time 6.772396802902222 seconds\n",
            "episode 715 score 14.49000000000001 average score 30.223199999999974 epsilon 0.01 time 3.4983792304992676 seconds\n",
            "episode 716 score 105.06999999999951 average score 31.03009999999997 epsilon 0.01 time 20.163163423538208 seconds\n",
            "episode 717 score 4.8900000000000015 average score 31.029999999999973 epsilon 0.01 time 1.1428756713867188 seconds\n",
            "episode 718 score 34.23000000000003 average score 31.14829999999997 epsilon 0.01 time 6.941884517669678 seconds\n",
            "episode 719 score 81.64999999999978 average score 31.896199999999972 epsilon 0.01 time 15.344168424606323 seconds\n",
            "episode 720 score 38.46 average score 31.442099999999964 epsilon 0.01 time 7.154217004776001 seconds\n",
            "episode 721 score 4.6100000000000065 average score 31.501299999999972 epsilon 0.01 time 1.63151216506958 seconds\n",
            "episode 722 score 0.9299999999999999 average score 31.20739999999997 epsilon 0.01 time 0.4553990364074707 seconds\n",
            "episode 723 score 30.229999999999926 average score 31.16709999999997 epsilon 0.01 time 6.3088788986206055 seconds\n",
            "episode 724 score 40.44 average score 31.325099999999974 epsilon 0.01 time 7.514580726623535 seconds\n",
            "episode 725 score 65.83999999999989 average score 31.737599999999965 epsilon 0.01 time 12.698440313339233 seconds\n",
            "episode 726 score 10.840000000000003 average score 31.36529999999997 epsilon 0.01 time 2.1567118167877197 seconds\n",
            "episode 727 score 4.900000000000001 average score 31.187899999999967 epsilon 0.01 time 1.1361737251281738 seconds\n",
            "episode 728 score 36.19000000000004 average score 31.306199999999972 epsilon 0.01 time 7.420244216918945 seconds\n",
            "episode 729 score 32.53999999999998 average score 31.328699999999973 epsilon 0.01 time 6.106150150299072 seconds\n",
            "episode 730 score 113.16999999999958 average score 32.473499999999966 epsilon 0.01 time 21.138843059539795 seconds\n",
            "episode 731 score 10.540000000000008 average score 32.57209999999996 epsilon 0.01 time 2.732250213623047 seconds\n",
            "episode 732 score 4.620000000000007 average score 32.315699999999964 epsilon 0.01 time 1.6104063987731934 seconds\n",
            "episode 733 score 2.6600000000000064 average score 32.07879999999996 epsilon 0.01 time 1.2456567287445068 seconds\n",
            "episode 734 score 34.250000000000036 average score 32.434099999999965 epsilon 0.01 time 6.900501251220703 seconds\n",
            "episode 735 score 49.98000000000009 average score 32.78889999999997 epsilon 0.01 time 9.798445224761963 seconds\n",
            "episode 736 score 46.10999999999997 average score 33.24049999999997 epsilon 0.01 time 8.984045028686523 seconds\n",
            "episode 737 score 20.379999999999946 average score 33.37849999999997 epsilon 0.01 time 4.5074803829193115 seconds\n",
            "episode 738 score 4.890000000000001 average score 32.904999999999966 epsilon 0.01 time 1.1411173343658447 seconds\n",
            "episode 739 score 26.369999999999937 average score 32.84359999999997 epsilon 0.01 time 5.438139915466309 seconds\n",
            "episode 740 score 115.13999999999956 average score 33.98549999999996 epsilon 0.01 time 21.677115201950073 seconds\n",
            "episode 741 score 4.8900000000000015 average score 34.007899999999964 epsilon 0.01 time 1.1454241275787354 seconds\n",
            "episode 742 score 34.16000000000004 average score 34.004399999999954 epsilon 0.01 time 7.104309797286987 seconds\n",
            "episode 743 score 8.550000000000008 average score 34.06179999999996 epsilon 0.01 time 2.3449854850769043 seconds\n",
            "episode 744 score 87.72999999999988 average score 34.51749999999996 epsilon 0.01 time 16.11096692085266 seconds\n",
            "episode 745 score 14.510000000000009 average score 34.63609999999996 epsilon 0.01 time 3.352299451828003 seconds\n",
            "episode 746 score 36.23000000000003 average score 34.53719999999996 epsilon 0.01 time 7.236426115036011 seconds\n",
            "episode 747 score 22.409999999999943 average score 34.754499999999965 epsilon 0.01 time 4.773375988006592 seconds\n",
            "episode 748 score 105.31999999999967 average score 35.58419999999996 epsilon 0.01 time 19.569371700286865 seconds\n",
            "episode 749 score 36.24000000000004 average score 35.92019999999996 epsilon 0.01 time 7.211552143096924 seconds\n",
            "episode 750 score 6.580000000000008 average score 34.69339999999996 epsilon 0.01 time 1.9634158611297607 seconds\n",
            "episode 751 score 8.570000000000007 average score 34.653899999999965 epsilon 0.01 time 2.3042924404144287 seconds\n",
            "episode 752 score 36.17000000000004 average score 34.890599999999964 epsilon 0.01 time 7.26054048538208 seconds\n",
            "episode 753 score 48.07000000000007 average score 35.34469999999997 epsilon 0.01 time 9.347399711608887 seconds\n",
            "episode 754 score -1.31 average score 33.962099999999964 epsilon 0.01 time 0.5666663646697998 seconds\n",
            "episode 755 score 34.51999999999998 average score 34.18209999999996 epsilon 0.01 time 6.347324371337891 seconds\n",
            "episode 756 score 16.75 average score 34.22449999999996 epsilon 0.01 time 3.227769136428833 seconds\n",
            "episode 757 score 42.150000000000055 average score 34.65909999999997 epsilon 0.01 time 8.273178815841675 seconds\n",
            "episode 758 score 30.519999999999968 average score 34.07049999999997 epsilon 0.01 time 5.722872495651245 seconds\n",
            "episode 759 score 12.540000000000008 average score 34.20619999999996 epsilon 0.01 time 3.0434703826904297 seconds\n",
            "episode 760 score 26.649999999999984 average score 34.446299999999965 epsilon 0.01 time 4.93662428855896 seconds\n",
            "episode 761 score -1.31 average score 34.167199999999966 epsilon 0.01 time 0.5782060623168945 seconds\n",
            "episode 762 score 54.000000000000085 average score 34.38179999999997 epsilon 0.01 time 10.415388822555542 seconds\n",
            "episode 763 score 68.01000000000002 average score 34.89489999999997 epsilon 0.01 time 12.571354389190674 seconds\n",
            "episode 764 score 0.94 average score 34.87789999999997 epsilon 0.01 time 0.4373748302459717 seconds\n",
            "episode 765 score 16.709999999999997 average score 34.73899999999996 epsilon 0.01 time 3.299468755722046 seconds\n",
            "episode 766 score 40.42000000000001 average score 34.83999999999997 epsilon 0.01 time 7.4715800285339355 seconds\n",
            "episode 767 score 50.00000000000007 average score 35.17279999999997 epsilon 0.01 time 9.809688568115234 seconds\n",
            "episode 768 score 26.609999999999978 average score 35.03699999999996 epsilon 0.01 time 5.007402420043945 seconds\n",
            "episode 769 score 69.71999999999986 average score 34.93759999999997 epsilon 0.01 time 13.412006855010986 seconds\n",
            "episode 770 score 38.18000000000005 average score 35.03629999999997 epsilon 0.01 time 7.554520606994629 seconds\n",
            "episode 771 score 57.980000000000096 average score 35.60929999999997 epsilon 0.01 time 11.040054082870483 seconds\n",
            "episode 772 score 26.639999999999983 average score 34.68409999999997 epsilon 0.01 time 5.001596450805664 seconds\n",
            "episode 773 score 28.269999999999925 average score 34.80229999999997 epsilon 0.01 time 5.9880406856536865 seconds\n",
            "episode 774 score 6.600000000000008 average score 34.05219999999998 epsilon 0.01 time 1.9597899913787842 seconds\n",
            "episode 775 score 81.89999999999992 average score 34.170499999999976 epsilon 0.01 time 14.879076719284058 seconds\n",
            "episode 776 score 75.91999999999994 average score 34.92299999999997 epsilon 0.01 time 13.974163293838501 seconds\n",
            "episode 777 score 53.93000000000009 average score 34.96199999999998 epsilon 0.01 time 10.481989622116089 seconds\n",
            "episode 778 score 2.920000000000001 average score 34.68819999999998 epsilon 0.01 time 0.7686567306518555 seconds\n",
            "episode 779 score 42.43 average score 34.57239999999997 epsilon 0.01 time 7.827318906784058 seconds\n",
            "episode 780 score 6.610000000000007 average score 34.31459999999997 epsilon 0.01 time 1.9763000011444092 seconds\n",
            "episode 781 score 12.760000000000003 average score 33.32709999999998 epsilon 0.01 time 2.6127612590789795 seconds\n",
            "episode 782 score 121.1099999999995 average score 34.255199999999974 epsilon 0.01 time 22.389264822006226 seconds\n",
            "episode 783 score 2.6400000000000063 average score 33.72199999999998 epsilon 0.01 time 1.276587963104248 seconds\n",
            "episode 784 score 0.94 average score 33.089999999999975 epsilon 0.01 time 0.43775367736816406 seconds\n",
            "episode 785 score 22.389999999999947 average score 33.008199999999974 epsilon 0.01 time 4.811035633087158 seconds\n",
            "episode 786 score 16.489999999999956 average score 33.16629999999997 epsilon 0.01 time 3.6904213428497314 seconds\n",
            "episode 787 score 26.339999999999936 average score 32.13949999999997 epsilon 0.01 time 5.436293601989746 seconds\n",
            "episode 788 score 30.29999999999993 average score 32.31729999999997 epsilon 0.01 time 6.102077484130859 seconds\n",
            "episode 789 score 115.24999999999957 average score 33.20529999999996 epsilon 0.01 time 21.06848168373108 seconds\n",
            "episode 790 score 10.580000000000009 average score 33.16359999999997 epsilon 0.01 time 2.584397315979004 seconds\n",
            "episode 791 score 18.739999999999995 average score 33.34159999999996 epsilon 0.01 time 3.5450289249420166 seconds\n",
            "episode 792 score -1.31 average score 33.220199999999956 epsilon 0.01 time 0.5690345764160156 seconds\n",
            "episode 793 score 105.65999999999976 average score 33.69749999999996 epsilon 0.01 time 18.92620825767517 seconds\n",
            "episode 794 score 18.399999999999952 average score 33.79509999999996 epsilon 0.01 time 4.142324447631836 seconds\n",
            "episode 795 score 40.16000000000005 average score 34.011999999999965 epsilon 0.01 time 7.948094129562378 seconds\n",
            "episode 796 score 30.289999999999925 average score 33.89289999999996 epsilon 0.01 time 6.195967435836792 seconds\n",
            "episode 797 score 6.710000000000005 average score 33.89409999999996 epsilon 0.01 time 1.7269270420074463 seconds\n",
            "episode 798 score 10.810000000000004 average score 33.42259999999996 epsilon 0.01 time 2.184093475341797 seconds\n",
            "episode 799 score 85.79999999999987 average score 34.03689999999996 epsilon 0.01 time 15.642699956893921 seconds\n",
            "episode 800 score 30.30999999999993 average score 34.25419999999996 epsilon 0.01 time 6.106969356536865 seconds\n",
            "episode 801 score 22.409999999999947 average score 34.369999999999955 epsilon 0.01 time 4.714169263839722 seconds\n",
            "episode 802 score 2.6500000000000066 average score 33.89559999999996 epsilon 0.01 time 1.2410051822662354 seconds\n",
            "episode 803 score 12.790000000000003 average score 32.93029999999996 epsilon 0.01 time 2.5113608837127686 seconds\n",
            "episode 804 score 77.6699999999998 average score 33.63809999999996 epsilon 0.01 time 14.58802843093872 seconds\n",
            "episode 805 score 10.550000000000008 average score 33.08649999999996 epsilon 0.01 time 2.6320040225982666 seconds\n",
            "episode 806 score 0.95 average score 32.75049999999996 epsilon 0.01 time 0.4221527576446533 seconds\n",
            "episode 807 score 22.659999999999986 average score 32.99019999999996 epsilon 0.01 time 4.281878471374512 seconds\n",
            "episode 808 score -1.03 average score 32.87189999999996 epsilon 0.01 time 0.08005976676940918 seconds\n",
            "episode 809 score 2.6500000000000066 average score 32.35839999999995 epsilon 0.01 time 1.2541749477386475 seconds\n",
            "episode 810 score 24.36999999999994 average score 32.375599999999956 epsilon 0.01 time 5.08154296875 seconds\n",
            "episode 811 score 20.239999999999952 average score 32.57129999999996 epsilon 0.01 time 4.790834426879883 seconds\n",
            "episode 812 score 83.60999999999979 average score 33.101999999999954 epsilon 0.01 time 15.697017192840576 seconds\n",
            "episode 813 score 6.730000000000004 average score 33.18239999999996 epsilon 0.01 time 1.7151720523834229 seconds\n",
            "episode 814 score 38.170000000000044 average score 33.19939999999996 epsilon 0.01 time 7.611967086791992 seconds\n",
            "episode 815 score 6.860000000000001 average score 33.123099999999965 epsilon 0.01 time 1.5273199081420898 seconds\n",
            "episode 816 score 18.479999999999954 average score 32.25719999999997 epsilon 0.01 time 4.003493309020996 seconds\n",
            "episode 817 score 14.790000000000003 average score 32.35619999999997 epsilon 0.01 time 2.8137903213500977 seconds\n",
            "episode 818 score 6.850000000000001 average score 32.082399999999964 epsilon 0.01 time 1.5160715579986572 seconds\n",
            "episode 819 score 35.980000000000054 average score 31.625699999999966 epsilon 0.01 time 7.580980062484741 seconds\n",
            "episode 820 score 154.63000000000022 average score 32.78739999999997 epsilon 0.01 time 28.29965114593506 seconds\n",
            "episode 821 score 20.719999999999995 average score 32.94849999999997 epsilon 0.01 time 3.8717100620269775 seconds\n",
            "episode 822 score 2.860000000000002 average score 32.96779999999997 epsilon 0.01 time 0.8985249996185303 seconds\n",
            "episode 823 score 14.740000000000004 average score 32.81289999999996 epsilon 0.01 time 2.9409377574920654 seconds\n",
            "episode 824 score 4.630000000000007 average score 32.45479999999997 epsilon 0.01 time 1.6047914028167725 seconds\n",
            "episode 825 score 91.70999999999982 average score 32.713499999999975 epsilon 0.01 time 16.638325691223145 seconds\n",
            "episode 826 score 20.419999999999952 average score 32.80929999999997 epsilon 0.01 time 4.433733940124512 seconds\n",
            "episode 827 score 26.609999999999978 average score 33.026399999999974 epsilon 0.01 time 5.007623672485352 seconds\n",
            "episode 828 score 8.840000000000002 average score 32.752899999999975 epsilon 0.01 time 1.842832326889038 seconds\n",
            "episode 829 score 32.05000000000003 average score 32.747999999999976 epsilon 0.01 time 6.920861005783081 seconds\n",
            "episode 830 score 77.68999999999981 average score 32.39319999999997 epsilon 0.01 time 14.51551079750061 seconds\n",
            "episode 831 score 57.910000000000096 average score 32.86689999999997 epsilon 0.01 time 11.113600015640259 seconds\n",
            "episode 832 score 46.00000000000007 average score 33.280699999999975 epsilon 0.01 time 9.206126689910889 seconds\n",
            "episode 833 score 8.580000000000009 average score 33.33989999999997 epsilon 0.01 time 2.28713321685791 seconds\n",
            "episode 834 score 52.02000000000008 average score 33.51759999999997 epsilon 0.01 time 10.003632545471191 seconds\n",
            "episode 835 score 46.37000000000001 average score 33.48149999999997 epsilon 0.01 time 8.49336314201355 seconds\n",
            "episode 836 score 48.07000000000007 average score 33.50109999999997 epsilon 0.01 time 9.306126594543457 seconds\n",
            "episode 837 score 109.21999999999963 average score 34.38949999999997 epsilon 0.01 time 20.17981481552124 seconds\n",
            "episode 838 score 54.26000000000003 average score 34.883199999999974 epsilon 0.01 time 9.853289127349854 seconds\n",
            "episode 839 score 8.860000000000001 average score 34.70809999999997 epsilon 0.01 time 1.8168447017669678 seconds\n",
            "episode 840 score 6.590000000000008 average score 33.622599999999984 epsilon 0.01 time 1.969162940979004 seconds\n",
            "episode 841 score 6.880000000000002 average score 33.642499999999984 epsilon 0.01 time 1.444162368774414 seconds\n",
            "episode 842 score 0.95 average score 33.31039999999998 epsilon 0.01 time 0.4185774326324463 seconds\n",
            "episode 843 score 26.60999999999998 average score 33.49099999999998 epsilon 0.01 time 4.975169897079468 seconds\n",
            "episode 844 score 30.289999999999925 average score 32.916599999999974 epsilon 0.01 time 6.153045177459717 seconds\n",
            "episode 845 score 48.130000000000074 average score 33.25279999999997 epsilon 0.01 time 9.180442810058594 seconds\n",
            "episode 846 score 113.1499999999996 average score 34.02199999999998 epsilon 0.01 time 20.858930349349976 seconds\n",
            "episode 847 score 8.580000000000009 average score 33.88369999999997 epsilon 0.01 time 2.2703053951263428 seconds\n",
            "episode 848 score 28.289999999999935 average score 33.11339999999998 epsilon 0.01 time 5.867592811584473 seconds\n",
            "episode 849 score 0.6799999999999997 average score 32.757799999999975 epsilon 0.01 time 0.8747701644897461 seconds\n",
            "episode 850 score 42.150000000000055 average score 33.11349999999997 epsilon 0.01 time 8.210947513580322 seconds\n",
            "episode 851 score 8.550000000000008 average score 33.113299999999974 epsilon 0.01 time 2.3248848915100098 seconds\n",
            "episode 852 score 22.409999999999947 average score 32.975699999999975 epsilon 0.01 time 4.685784339904785 seconds\n",
            "episode 853 score 22.359999999999943 average score 32.718599999999974 epsilon 0.01 time 4.808724403381348 seconds\n",
            "episode 854 score 162.54000000000036 average score 34.357099999999974 epsilon 0.01 time 29.67610216140747 seconds\n",
            "episode 855 score 22.639999999999986 average score 34.238299999999974 epsilon 0.01 time 4.346789836883545 seconds\n",
            "episode 856 score 73.71999999999984 average score 34.80799999999997 epsilon 0.01 time 13.887013912200928 seconds\n",
            "episode 857 score 61.92000000000011 average score 35.00569999999997 epsilon 0.01 time 11.663840770721436 seconds\n",
            "episode 858 score 34.23000000000003 average score 35.04279999999997 epsilon 0.01 time 6.851504802703857 seconds\n",
            "episode 859 score 32.28000000000003 average score 35.24019999999997 epsilon 0.01 time 6.489635705947876 seconds\n",
            "episode 860 score 44.10000000000007 average score 35.414699999999975 epsilon 0.01 time 8.604415893554688 seconds\n",
            "episode 861 score 30.30999999999993 average score 35.73089999999998 epsilon 0.01 time 6.1240763664245605 seconds\n",
            "episode 862 score 67.78999999999986 average score 35.86879999999997 epsilon 0.01 time 12.867809534072876 seconds\n",
            "episode 863 score 40.44 average score 35.59309999999997 epsilon 0.01 time 7.43051290512085 seconds\n",
            "episode 864 score 28.349999999999937 average score 35.86719999999997 epsilon 0.01 time 5.762696027755737 seconds\n",
            "episode 865 score -1.03 average score 35.68979999999997 epsilon 0.01 time 0.07846570014953613 seconds\n",
            "episode 866 score 4.910000000000001 average score 35.33469999999997 epsilon 0.01 time 1.0936524868011475 seconds\n",
            "episode 867 score 64.07 average score 35.475399999999965 epsilon 0.01 time 11.865751266479492 seconds\n",
            "episode 868 score 38.43999999999999 average score 35.59369999999997 epsilon 0.01 time 7.217828273773193 seconds\n",
            "episode 869 score 42.110000000000056 average score 35.31759999999998 epsilon 0.01 time 8.327739715576172 seconds\n",
            "episode 870 score 16.469999999999956 average score 35.100499999999975 epsilon 0.01 time 3.7541818618774414 seconds\n",
            "episode 871 score 22.39999999999994 average score 34.74469999999997 epsilon 0.01 time 4.78940749168396 seconds\n",
            "episode 872 score 22.409999999999943 average score 34.70239999999997 epsilon 0.01 time 4.754971265792847 seconds\n",
            "episode 873 score 99.57999999999977 average score 35.41549999999997 epsilon 0.01 time 18.345943689346313 seconds\n",
            "episode 874 score 28.49999999999997 average score 35.634499999999974 epsilon 0.01 time 5.538512468338013 seconds\n",
            "episode 875 score 50.06000000000008 average score 35.31609999999998 epsilon 0.01 time 9.690292835235596 seconds\n",
            "episode 876 score 2.920000000000001 average score 34.58609999999997 epsilon 0.01 time 0.7641887664794922 seconds\n",
            "episode 877 score 10.540000000000008 average score 34.15219999999997 epsilon 0.01 time 2.6594221591949463 seconds\n",
            "episode 878 score 26.579999999999977 average score 34.38879999999997 epsilon 0.01 time 5.01626443862915 seconds\n",
            "episode 879 score 83.54999999999976 average score 34.79999999999997 epsilon 0.01 time 15.752235889434814 seconds\n",
            "episode 880 score 14.490000000000009 average score 34.87879999999996 epsilon 0.01 time 3.397909164428711 seconds\n",
            "episode 881 score 28.27999999999993 average score 35.03399999999997 epsilon 0.01 time 5.9135582447052 seconds\n",
            "episode 882 score 24.38999999999994 average score 34.06679999999997 epsilon 0.01 time 5.065400838851929 seconds\n",
            "episode 883 score 62.150000000000055 average score 34.66189999999997 epsilon 0.01 time 11.41244888305664 seconds\n",
            "episode 884 score 48.20000000000004 average score 35.13449999999997 epsilon 0.01 time 9.186271667480469 seconds\n",
            "episode 885 score -1.03 average score 34.900299999999966 epsilon 0.01 time 0.08166623115539551 seconds\n",
            "episode 886 score 73.99999999999997 average score 35.475399999999965 epsilon 0.01 time 13.710634231567383 seconds\n",
            "episode 887 score 4.630000000000007 average score 35.25829999999997 epsilon 0.01 time 1.637267827987671 seconds\n",
            "episode 888 score -1.03 average score 34.94499999999997 epsilon 0.01 time 0.07821393013000488 seconds\n",
            "episode 889 score 4.6100000000000065 average score 33.83859999999998 epsilon 0.01 time 1.6430082321166992 seconds\n",
            "episode 890 score 22.419999999999945 average score 33.95699999999998 epsilon 0.01 time 4.753288507461548 seconds\n",
            "episode 891 score 4.630000000000007 average score 33.81589999999998 epsilon 0.01 time 1.5689153671264648 seconds\n",
            "episode 892 score -1.03 average score 33.81869999999998 epsilon 0.01 time 0.07948660850524902 seconds\n",
            "episode 893 score 2.9100000000000006 average score 32.791199999999975 epsilon 0.01 time 0.7975010871887207 seconds\n",
            "episode 894 score 10.810000000000002 average score 32.71529999999998 epsilon 0.01 time 2.1987640857696533 seconds\n",
            "episode 895 score 40.200000000000045 average score 32.71569999999998 epsilon 0.01 time 7.918684005737305 seconds\n",
            "episode 896 score -1.31 average score 32.39969999999998 epsilon 0.01 time 0.5469269752502441 seconds\n",
            "episode 897 score 28.369999999999937 average score 32.61629999999999 epsilon 0.01 time 5.840774059295654 seconds\n",
            "episode 898 score 145.07999999999987 average score 33.95899999999998 epsilon 0.01 time 26.29501509666443 seconds\n",
            "episode 899 score 20.39999999999995 average score 33.30499999999998 epsilon 0.01 time 4.479200601577759 seconds\n",
            "episode 900 score 4.8900000000000015 average score 33.05079999999998 epsilon 0.01 time 1.1280148029327393 seconds\n",
            "episode 901 score 16.479999999999954 average score 32.99149999999998 epsilon 0.01 time 3.727959156036377 seconds\n",
            "episode 902 score 48.010000000000076 average score 33.44509999999998 epsilon 0.01 time 9.418578147888184 seconds\n",
            "episode 903 score 24.539999999999967 average score 33.56259999999998 epsilon 0.01 time 4.856281518936157 seconds\n",
            "episode 904 score 40.15000000000005 average score 33.18739999999999 epsilon 0.01 time 8.032566547393799 seconds\n",
            "episode 905 score 69.78999999999986 average score 33.77979999999998 epsilon 0.01 time 13.149409294128418 seconds\n",
            "episode 906 score -1.31 average score 33.75719999999998 epsilon 0.01 time 0.552931547164917 seconds\n",
            "episode 907 score 8.570000000000007 average score 33.61629999999999 epsilon 0.01 time 2.3109092712402344 seconds\n",
            "episode 908 score 42.14000000000006 average score 34.04799999999998 epsilon 0.01 time 8.315323114395142 seconds\n",
            "episode 909 score 24.36999999999994 average score 34.26519999999998 epsilon 0.01 time 5.113354682922363 seconds\n",
            "episode 910 score 6.590000000000007 average score 34.08739999999998 epsilon 0.01 time 1.9604175090789795 seconds\n",
            "episode 911 score -1.31 average score 33.87189999999999 epsilon 0.01 time 0.5675568580627441 seconds\n",
            "episode 912 score 95.44999999999968 average score 33.99029999999998 epsilon 0.01 time 17.748465061187744 seconds\n",
            "episode 913 score 71.80999999999983 average score 34.64109999999999 epsilon 0.01 time 13.463306188583374 seconds\n",
            "episode 914 score 24.639999999999983 average score 34.50579999999999 epsilon 0.01 time 4.6788413524627686 seconds\n",
            "episode 915 score 10.530000000000008 average score 34.54249999999999 epsilon 0.01 time 2.7483389377593994 seconds\n",
            "episode 916 score 0.6699999999999997 average score 34.36439999999998 epsilon 0.01 time 0.918698787689209 seconds\n",
            "episode 917 score 30.509999999999962 average score 34.521599999999985 epsilon 0.01 time 5.944324970245361 seconds\n",
            "episode 918 score 91.71999999999984 average score 35.37029999999998 epsilon 0.01 time 16.74773931503296 seconds\n",
            "episode 919 score 10.520000000000008 average score 35.115699999999975 epsilon 0.01 time 2.7475383281707764 seconds\n",
            "episode 920 score 34.48 average score 33.91419999999997 epsilon 0.01 time 6.4748215675354 seconds\n",
            "episode 921 score 12.800000000000002 average score 33.83499999999998 epsilon 0.01 time 2.5972659587860107 seconds\n",
            "episode 922 score 38.5 average score 34.19139999999998 epsilon 0.01 time 7.128423690795898 seconds\n",
            "episode 923 score 2.9300000000000006 average score 34.07329999999998 epsilon 0.01 time 0.762434720993042 seconds\n",
            "episode 924 score 26.31999999999994 average score 34.290199999999984 epsilon 0.01 time 5.507282257080078 seconds\n",
            "episode 925 score 34.24000000000004 average score 33.715499999999984 epsilon 0.01 time 6.857522964477539 seconds\n",
            "episode 926 score 14.50000000000001 average score 33.65629999999999 epsilon 0.01 time 3.383577346801758 seconds\n",
            "episode 927 score 10.810000000000002 average score 33.498299999999986 epsilon 0.01 time 2.2176411151885986 seconds\n",
            "episode 928 score 44.38 average score 33.85369999999998 epsilon 0.01 time 8.244968175888062 seconds\n",
            "episode 929 score 42.13000000000006 average score 33.95449999999998 epsilon 0.01 time 8.440261125564575 seconds\n",
            "episode 930 score 115.42999999999965 average score 34.331899999999976 epsilon 0.01 time 21.0854709148407 seconds\n",
            "episode 931 score 18.40999999999995 average score 33.93689999999998 epsilon 0.01 time 4.124741077423096 seconds\n",
            "episode 932 score 8.640000000000006 average score 33.56329999999997 epsilon 0.01 time 2.1828553676605225 seconds\n",
            "episode 933 score 111.55999999999976 average score 34.59309999999998 epsilon 0.01 time 20.14685368537903 seconds\n",
            "episode 934 score 24.399999999999945 average score 34.316899999999976 epsilon 0.01 time 5.117945194244385 seconds\n",
            "episode 935 score 2.6400000000000063 average score 33.879599999999975 epsilon 0.01 time 1.3151774406433105 seconds\n",
            "episode 936 score 59.920000000000094 average score 33.99809999999997 epsilon 0.01 time 11.67337417602539 seconds\n",
            "episode 937 score 24.35999999999994 average score 33.14949999999998 epsilon 0.01 time 5.130619764328003 seconds\n",
            "episode 938 score 6.600000000000008 average score 32.67289999999998 epsilon 0.01 time 1.9420232772827148 seconds\n",
            "episode 939 score 8.550000000000008 average score 32.66979999999998 epsilon 0.01 time 2.362476110458374 seconds\n",
            "episode 940 score 26.61999999999998 average score 32.87009999999997 epsilon 0.01 time 5.022973299026489 seconds\n",
            "episode 941 score 14.740000000000004 average score 32.948699999999974 epsilon 0.01 time 2.9561216831207275 seconds\n",
            "episode 942 score 48.36000000000002 average score 33.422799999999974 epsilon 0.01 time 8.819093942642212 seconds\n",
            "episode 943 score -1.02 average score 33.146499999999975 epsilon 0.01 time 0.05932903289794922 seconds\n",
            "episode 944 score 24.37999999999994 average score 33.087399999999974 epsilon 0.01 time 5.063413858413696 seconds\n",
            "episode 945 score 2.6500000000000066 average score 32.63259999999998 epsilon 0.01 time 1.2352499961853027 seconds\n",
            "episode 946 score -1.03 average score 31.490799999999975 epsilon 0.01 time 0.07493185997009277 seconds\n",
            "episode 947 score 2.6600000000000064 average score 31.43159999999998 epsilon 0.01 time 1.22501540184021 seconds\n",
            "episode 948 score 10.840000000000002 average score 31.257099999999976 epsilon 0.01 time 2.1201252937316895 seconds\n",
            "episode 949 score 14.730000000000004 average score 31.39759999999998 epsilon 0.01 time 2.9383254051208496 seconds\n",
            "episode 950 score 2.9000000000000004 average score 31.005099999999985 epsilon 0.01 time 0.8252229690551758 seconds\n",
            "episode 951 score 20.70999999999999 average score 31.126699999999982 epsilon 0.01 time 3.937314987182617 seconds\n",
            "episode 952 score -1.04 average score 30.892199999999985 epsilon 0.01 time 0.07935428619384766 seconds\n",
            "episode 953 score 63.8599999999999 average score 31.307199999999984 epsilon 0.01 time 12.14461612701416 seconds\n",
            "episode 954 score 38.19000000000004 average score 30.063699999999976 epsilon 0.01 time 7.627211809158325 seconds\n",
            "episode 955 score 62.13000000000006 average score 30.458599999999976 epsilon 0.01 time 11.45116901397705 seconds\n",
            "episode 956 score 50.040000000000084 average score 30.22179999999998 epsilon 0.01 time 9.678589344024658 seconds\n",
            "episode 957 score 8.870000000000003 average score 29.691299999999973 epsilon 0.01 time 1.7873029708862305 seconds\n",
            "episode 958 score 26.329999999999934 average score 29.612299999999976 epsilon 0.01 time 5.5000574588775635 seconds\n",
            "episode 959 score 14.500000000000009 average score 29.434499999999975 epsilon 0.01 time 3.3469583988189697 seconds\n",
            "episode 960 score -1.31 average score 28.980399999999978 epsilon 0.01 time 0.5840704441070557 seconds\n",
            "episode 961 score 2.920000000000001 average score 28.706499999999973 epsilon 0.01 time 0.777651309967041 seconds\n",
            "episode 962 score 2.6400000000000063 average score 28.05499999999998 epsilon 0.01 time 1.3154175281524658 seconds\n",
            "episode 963 score 24.38999999999994 average score 27.894499999999976 epsilon 0.01 time 5.09343147277832 seconds\n",
            "episode 964 score 26.299999999999933 average score 27.873999999999974 epsilon 0.01 time 5.544289588928223 seconds\n",
            "episode 965 score 50.340000000000025 average score 28.387699999999974 epsilon 0.01 time 9.14616584777832 seconds\n",
            "episode 966 score 22.379999999999946 average score 28.562399999999975 epsilon 0.01 time 4.741726398468018 seconds\n",
            "episode 967 score 103.07999999999963 average score 28.952499999999972 epsilon 0.01 time 19.70315980911255 seconds\n",
            "episode 968 score 54.26000000000004 average score 29.110699999999973 epsilon 0.01 time 9.905648231506348 seconds\n",
            "episode 969 score 12.810000000000004 average score 28.817699999999977 epsilon 0.01 time 2.501791477203369 seconds\n",
            "episode 970 score -1.31 average score 28.63989999999997 epsilon 0.01 time 0.5921556949615479 seconds\n",
            "episode 971 score 124.96999999999949 average score 29.66559999999997 epsilon 0.01 time 23.22353196144104 seconds\n",
            "episode 972 score 14.48000000000001 average score 29.586299999999966 epsilon 0.01 time 3.3632006645202637 seconds\n",
            "episode 973 score 30.559999999999974 average score 28.896099999999976 epsilon 0.01 time 5.823498249053955 seconds\n",
            "episode 974 score 12.800000000000004 average score 28.739099999999972 epsilon 0.01 time 2.5337367057800293 seconds\n",
            "episode 975 score 16.749999999999996 average score 28.405999999999977 epsilon 0.01 time 3.2001700401306152 seconds\n",
            "episode 976 score 8.820000000000002 average score 28.46499999999997 epsilon 0.01 time 1.8551998138427734 seconds\n",
            "episode 977 score 73.97999999999996 average score 29.099399999999978 epsilon 0.01 time 13.363394498825073 seconds\n",
            "episode 978 score -1.31 average score 28.82049999999997 epsilon 0.01 time 0.549339771270752 seconds\n",
            "episode 979 score 0.6699999999999997 average score 27.991699999999977 epsilon 0.01 time 0.8795907497406006 seconds\n",
            "episode 980 score 6.880000000000002 average score 27.915599999999976 epsilon 0.01 time 1.4465150833129883 seconds\n",
            "episode 981 score 4.8900000000000015 average score 27.681699999999974 epsilon 0.01 time 1.138157844543457 seconds\n",
            "episode 982 score 6.600000000000008 average score 27.503799999999973 epsilon 0.01 time 1.9375228881835938 seconds\n",
            "episode 983 score 36.45999999999999 average score 27.246899999999968 epsilon 0.01 time 6.761869430541992 seconds\n",
            "episode 984 score 24.64999999999998 average score 27.01139999999997 epsilon 0.01 time 4.572040796279907 seconds\n",
            "episode 985 score -1.31 average score 27.008599999999973 epsilon 0.01 time 0.5680551528930664 seconds\n",
            "episode 986 score 10.55000000000001 average score 26.37409999999998 epsilon 0.01 time 2.6103689670562744 seconds\n",
            "episode 987 score 0.6799999999999997 average score 26.334599999999977 epsilon 0.01 time 0.8622076511383057 seconds\n",
            "episode 988 score 95.3999999999997 average score 27.298899999999968 epsilon 0.01 time 17.74788498878479 seconds\n",
            "episode 989 score 30.30999999999993 average score 27.55589999999997 epsilon 0.01 time 6.068485498428345 seconds\n",
            "episode 990 score 14.52000000000001 average score 27.476899999999965 epsilon 0.01 time 3.2551846504211426 seconds\n",
            "episode 991 score 8.570000000000007 average score 27.51629999999997 epsilon 0.01 time 2.3313097953796387 seconds\n",
            "episode 992 score 0.94 average score 27.535999999999973 epsilon 0.01 time 0.43740344047546387 seconds\n",
            "episode 993 score 52.310000000000024 average score 28.029999999999973 epsilon 0.01 time 9.415401935577393 seconds\n",
            "episode 994 score 24.34999999999994 average score 28.165399999999966 epsilon 0.01 time 5.154273986816406 seconds\n",
            "episode 995 score 6.600000000000008 average score 27.829399999999968 epsilon 0.01 time 1.9257261753082275 seconds\n",
            "episode 996 score -1.31 average score 27.829399999999968 epsilon 0.01 time 0.5734250545501709 seconds\n",
            "episode 997 score 14.50000000000001 average score 27.69069999999997 epsilon 0.01 time 3.285344362258911 seconds\n",
            "episode 998 score 0.6699999999999997 average score 26.246599999999972 epsilon 0.01 time 0.8960139751434326 seconds\n",
            "episode 999 score 50.000000000000085 average score 26.54259999999997 epsilon 0.01 time 9.631840467453003 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "INSTRUCTIONS\n",
        "1. Create a file with the following code\n",
        "2. Put the file you want to convert into the same folder as it, and rename it to \"file.py\"\n",
        "3. Add a \"#F\" comment to any lines in the code which have a function call that doesn't assign anything (so no =),\n",
        "as the program cannot handle these convincingly\n",
        "4. Run the converter file\n",
        "'''\n",
        "\n",
        "import re\n",
        "\n",
        "python_file = 'file.py'\n",
        "work_file = None\n",
        "\n",
        "basic_conversion_rules = {\"for\": \"FOR\", \"=\": \"TO\", \"if\": \"IF\", \"==\": \"EQUALS\", \"while\": \"WHILE\", \"until\": \"UNTIL\", \"import\": \"IMPORT\", \"class\": \"DEFINE CLASS\", \"def\": \"DEFINE FUNCTION\", \"else:\": \"ELSE:\", \"elif\": \"ELSEIF\", \"except:\": \"EXCEPT:\", \"try:\": \"TRY:\", \"pass\": \"PASS\", \"in\": \"IN\"}\n",
        "prefix_conversion_rules = {\"=\": \"SET \", \"#F\": \"CALL \"}\n",
        "advanced_conversion_rules = {\"print\": \"OUTPUT\", \"return\": \"RETURN\", \"input\": \"INPUT\"}\n",
        "\n",
        "def f2list(to_list):\n",
        "    return to_list.readlines()\n",
        "\n",
        "def l2pseudo(to_pseudo):\n",
        "    for line in to_pseudo:\n",
        "        line_index = to_pseudo.index(line)\n",
        "        line = str(line)\n",
        "        line = re.split(r'(\\s+)', line)\n",
        "        for key, value in prefix_conversion_rules.items():\n",
        "            if key in line:\n",
        "                if not str(line[0]) == '':\n",
        "                    line[0] = value + line[0]\n",
        "                else:\n",
        "                    line[2] = value + line[2]\n",
        "        for key, value in basic_conversion_rules.items():\n",
        "            for word in line:\n",
        "                if key == str(word):\n",
        "                    line[line.index(word)] = value\n",
        "        for key, value in advanced_conversion_rules.items():\n",
        "            for word in line:\n",
        "                line[line.index(word)] = word.replace(key, value)\n",
        "        for key, value in prefix_conversion_rules.items():\n",
        "            for word in line:\n",
        "                if word == key:\n",
        "                    del line[line.index(word)]\n",
        "        to_pseudo[line_index]= \"\".join(line)\n",
        "    return(to_pseudo)\n",
        "\n",
        "def p2file(to_file):\n",
        "    file = open(python_file + '_pseudo.txt', 'w')\n",
        "    for line in to_file:\n",
        "        print(line, file=file)\n",
        "\n",
        "def main():\n",
        "    main_file = open(python_file, 'r+')\n",
        "    work_file = f2list(main_file)\n",
        "    work_file = l2pseudo(work_file)\n",
        "    p2file(work_file)\n",
        "    \n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "iT1jKNLcX62w"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}